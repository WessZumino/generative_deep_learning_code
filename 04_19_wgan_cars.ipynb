{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WGAN Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from models.WGAN import WGAN\n",
    "from utils.loaders import load_safari, load_cifar\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "RUN_ID = '0039'\n",
    "RUN_FOLDER = os.path.join(\"./run\", RUN_ID)\n",
    "\n",
    "IMAGE_SIZE = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = 0\n",
    "(x_train, y_train) = load_cifar(label, 10)\n",
    "# (x_train, y_train) = load_safari('elephant')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x17f6a35f8>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow((x_train[100,:,:,:]+1)/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.0\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print(np.min(x_train))\n",
    "print(np.max(x_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6000, 32, 32, 3)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#works\n",
    "\n",
    "gan = WGAN(input_dim = (IMAGE_SIZE,IMAGE_SIZE,3)\n",
    "        , critic_conv_filters = [32,64,128,256]\n",
    "        , critic_conv_kernel_size = [5,5,5,5]\n",
    "        , critic_conv_strides = [2,2,2,1]\n",
    "        , critic_conv_padding = 'same'\n",
    "        , critic_batch_norm_momentum = 0.8\n",
    "        , critic_activation = 'leaky_relu'\n",
    "        , critic_dropout_rate = None\n",
    "        , critic_learning_rate = 0.00005\n",
    "        , generator_initial_dense_layer_size = (4,4,256)\n",
    "        , generator_upsample = [1,1,1,1]\n",
    "        , generator_conv_filters = [128,64,32,3]\n",
    "        , generator_conv_kernel_size = [5,5,5,5]\n",
    "        , generator_conv_strides = [2,2,2,1]\n",
    "        , generator_conv_padding = 'same'\n",
    "        , generator_batch_norm_momentum = 0.8\n",
    "        , generator_activation = 'leaky_relu'\n",
    "        , generator_dropout_rate = None\n",
    "        , generator_learning_rate = 0.00005\n",
    "        , optimiser = 'rmsprop'\n",
    "        , z_dim = 100\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# gan = WGAN(input_dim = (IMAGE_SIZE,IMAGE_SIZE,3)\n",
    "#         , critic_conv_filters = [32,64,128,128]\n",
    "#         , critic_conv_kernel_size = [5,5,5,5]\n",
    "#         , critic_conv_strides = [2,2,2,1]\n",
    "#         , critic_conv_padding = 'same'\n",
    "#         , critic_batch_norm_momentum = None\n",
    "#         , critic_activation = 'leaky_relu'\n",
    "#         , critic_dropout_rate = None\n",
    "#         , critic_learning_rate = 0.00005\n",
    "#         , generator_initial_dense_layer_size = (4, 4, 128)\n",
    "#         , generator_upsample = [2,2, 2,1]\n",
    "#         , generator_conv_filters = [128,64,32,3]\n",
    "#         , generator_conv_kernel_size = [5,5,5,5]\n",
    "#         , generator_conv_strides = [1,1, 1,1]\n",
    "#         , generator_conv_padding = 'same'\n",
    "#         , generator_batch_norm_momentum = 0.8\n",
    "#         , generator_activation = 'leaky_relu'\n",
    "#         , generator_dropout_rate = None\n",
    "#         , generator_learning_rate = 0.00005\n",
    "#         , optimiser = 'rmsprop'\n",
    "#         , z_dim = 100\n",
    "#         )\n",
    "\n",
    "gan.save(RUN_FOLDER)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gan.load_weights(os.path.join(RUN_FOLDER, 'weights/weights.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "critic_input (InputLayer)    (None, 32, 32, 3)         0         \n",
      "_________________________________________________________________\n",
      "critic_conv_0 (Conv2D)       (None, 16, 16, 32)        2432      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_16 (LeakyReLU)   (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "critic_conv_1 (Conv2D)       (None, 8, 8, 64)          51264     \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 8, 8, 64)          256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_17 (LeakyReLU)   (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "critic_conv_2 (Conv2D)       (None, 4, 4, 128)         204928    \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 4, 4, 128)         512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_18 (LeakyReLU)   (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "critic_conv_3 (Conv2D)       (None, 4, 4, 256)         819456    \n",
      "_________________________________________________________________\n",
      "batch_normalization_16 (Batc (None, 4, 4, 256)         1024      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_19 (LeakyReLU)   (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 4097      \n",
      "=================================================================\n",
      "Total params: 1,083,969\n",
      "Trainable params: 1,083,073\n",
      "Non-trainable params: 896\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "gan.critic.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "generator_input (InputLayer) (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 4096)              413696    \n",
      "_________________________________________________________________\n",
      "batch_normalization_17 (Batc (None, 4096)              16384     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_20 (LeakyReLU)   (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "reshape_3 (Reshape)          (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "generator_conv_0 (Conv2DTran (None, 8, 8, 128)         819328    \n",
      "_________________________________________________________________\n",
      "batch_normalization_18 (Batc (None, 8, 8, 128)         512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_21 (LeakyReLU)   (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "generator_conv_1 (Conv2DTran (None, 16, 16, 64)        204864    \n",
      "_________________________________________________________________\n",
      "batch_normalization_19 (Batc (None, 16, 16, 64)        256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_22 (LeakyReLU)   (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "generator_conv_2 (Conv2DTran (None, 32, 32, 32)        51232     \n",
      "_________________________________________________________________\n",
      "batch_normalization_20 (Batc (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_23 (LeakyReLU)   (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "generator_conv_3 (Conv2DTran (None, 32, 32, 3)         2403      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 32, 32, 3)         0         \n",
      "=================================================================\n",
      "Total params: 1,508,803\n",
      "Trainable params: 1,500,163\n",
      "Non-trainable params: 8,640\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "gan.generator.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3728 (5, 1) [D loss: (-0.009)(R -0.014, F -0.003)]  [G loss: 0.011] \n",
      "3729 (5, 1) [D loss: (-0.003)(R -0.003, F -0.004)]  [G loss: 0.014] \n",
      "3730 (5, 1) [D loss: (-0.006)(R -0.002, F -0.010)]  [G loss: 0.021] \n",
      "3731 (5, 1) [D loss: (-0.005)(R -0.001, F -0.010)]  [G loss: 0.015] \n",
      "3732 (5, 1) [D loss: (-0.006)(R -0.004, F -0.007)]  [G loss: 0.013] \n",
      "3733 (5, 1) [D loss: (-0.004)(R -0.004, F -0.004)]  [G loss: 0.020] \n",
      "3734 (5, 1) [D loss: (-0.005)(R -0.000, F -0.009)]  [G loss: 0.018] \n",
      "3735 (5, 1) [D loss: (-0.005)(R -0.003, F -0.006)]  [G loss: 0.018] \n",
      "3736 (5, 1) [D loss: (-0.006)(R 0.000, F -0.012)]  [G loss: 0.024] \n",
      "3737 (5, 1) [D loss: (-0.008)(R -0.004, F -0.013)]  [G loss: 0.021] \n",
      "3738 (5, 1) [D loss: (-0.004)(R -0.001, F -0.007)]  [G loss: 0.020] \n",
      "3739 (5, 1) [D loss: (-0.007)(R -0.000, F -0.013)]  [G loss: 0.019] \n",
      "3740 (5, 1) [D loss: (-0.005)(R -0.003, F -0.007)]  [G loss: 0.021] \n",
      "3741 (5, 1) [D loss: (-0.005)(R -0.002, F -0.009)]  [G loss: 0.016] \n",
      "3742 (5, 1) [D loss: (-0.004)(R -0.001, F -0.007)]  [G loss: 0.013] \n",
      "3743 (5, 1) [D loss: (-0.005)(R -0.002, F -0.008)]  [G loss: 0.017] \n",
      "3744 (5, 1) [D loss: (-0.005)(R 0.002, F -0.012)]  [G loss: 0.023] \n",
      "3745 (5, 1) [D loss: (-0.006)(R -0.003, F -0.010)]  [G loss: 0.018] \n",
      "3746 (5, 1) [D loss: (-0.001)(R 0.002, F -0.005)]  [G loss: 0.016] \n",
      "3747 (5, 1) [D loss: (-0.004)(R -0.004, F -0.004)]  [G loss: 0.015] \n",
      "3748 (5, 1) [D loss: (-0.006)(R -0.003, F -0.009)]  [G loss: 0.017] \n",
      "3749 (5, 1) [D loss: (-0.005)(R -0.006, F -0.004)]  [G loss: 0.012] \n",
      "3750 (5, 1) [D loss: (-0.006)(R -0.006, F -0.005)]  [G loss: 0.015] \n",
      "3751 (5, 1) [D loss: (-0.004)(R -0.003, F -0.005)]  [G loss: 0.016] \n",
      "3752 (5, 1) [D loss: (-0.004)(R -0.004, F -0.004)]  [G loss: 0.015] \n",
      "3753 (5, 1) [D loss: (-0.001)(R -0.000, F -0.001)]  [G loss: 0.015] \n",
      "3754 (5, 1) [D loss: (-0.002)(R 0.002, F -0.007)]  [G loss: 0.017] \n",
      "3755 (5, 1) [D loss: (-0.007)(R -0.006, F -0.009)]  [G loss: 0.017] \n",
      "3756 (5, 1) [D loss: (-0.007)(R -0.003, F -0.010)]  [G loss: 0.016] \n",
      "3757 (5, 1) [D loss: (-0.005)(R -0.005, F -0.005)]  [G loss: 0.017] \n",
      "3758 (5, 1) [D loss: (-0.003)(R -0.001, F -0.004)]  [G loss: 0.014] \n",
      "3759 (5, 1) [D loss: (-0.004)(R -0.000, F -0.008)]  [G loss: 0.013] \n",
      "3760 (5, 1) [D loss: (-0.002)(R 0.000, F -0.005)]  [G loss: 0.016] \n",
      "3761 (5, 1) [D loss: (-0.008)(R -0.008, F -0.008)]  [G loss: 0.012] \n",
      "3762 (5, 1) [D loss: (-0.005)(R -0.004, F -0.007)]  [G loss: 0.012] \n",
      "3763 (5, 1) [D loss: (-0.007)(R -0.004, F -0.009)]  [G loss: 0.010] \n",
      "3764 (5, 1) [D loss: (-0.009)(R -0.010, F -0.008)]  [G loss: 0.014] \n",
      "3765 (5, 1) [D loss: (-0.003)(R -0.005, F -0.001)]  [G loss: 0.018] \n",
      "3766 (5, 1) [D loss: (-0.004)(R -0.005, F -0.002)]  [G loss: 0.015] \n",
      "3767 (5, 1) [D loss: (-0.005)(R -0.005, F -0.005)]  [G loss: 0.015] \n",
      "3768 (5, 1) [D loss: (-0.004)(R -0.004, F -0.004)]  [G loss: 0.016] \n",
      "3769 (5, 1) [D loss: (-0.007)(R -0.004, F -0.010)]  [G loss: 0.019] \n",
      "3770 (5, 1) [D loss: (-0.006)(R -0.003, F -0.008)]  [G loss: 0.019] \n",
      "3771 (5, 1) [D loss: (-0.002)(R 0.005, F -0.008)]  [G loss: 0.021] \n",
      "3772 (5, 1) [D loss: (-0.004)(R 0.004, F -0.012)]  [G loss: 0.023] \n",
      "3773 (5, 1) [D loss: (-0.006)(R 0.005, F -0.017)]  [G loss: 0.023] \n",
      "3774 (5, 1) [D loss: (-0.002)(R 0.008, F -0.012)]  [G loss: 0.027] \n",
      "3775 (5, 1) [D loss: (-0.004)(R 0.004, F -0.011)]  [G loss: 0.019] \n",
      "3776 (5, 1) [D loss: (-0.003)(R 0.006, F -0.011)]  [G loss: 0.022] \n",
      "3777 (5, 1) [D loss: (-0.005)(R 0.000, F -0.011)]  [G loss: 0.021] \n",
      "3778 (5, 1) [D loss: (-0.004)(R 0.001, F -0.008)]  [G loss: 0.018] \n",
      "3779 (5, 1) [D loss: (-0.003)(R 0.003, F -0.008)]  [G loss: 0.022] \n",
      "3780 (5, 1) [D loss: (-0.004)(R 0.001, F -0.010)]  [G loss: 0.022] \n",
      "3781 (5, 1) [D loss: (-0.004)(R -0.001, F -0.007)]  [G loss: 0.016] \n",
      "3782 (5, 1) [D loss: (0.000)(R 0.004, F -0.004)]  [G loss: 0.014] \n",
      "3783 (5, 1) [D loss: (-0.012)(R -0.006, F -0.017)]  [G loss: 0.022] \n",
      "3784 (5, 1) [D loss: (-0.007)(R -0.002, F -0.012)]  [G loss: 0.021] \n",
      "3785 (5, 1) [D loss: (-0.002)(R 0.001, F -0.006)]  [G loss: 0.018] \n",
      "3786 (5, 1) [D loss: (-0.005)(R -0.006, F -0.004)]  [G loss: 0.012] \n",
      "3787 (5, 1) [D loss: (-0.008)(R -0.008, F -0.008)]  [G loss: 0.017] \n",
      "3788 (5, 1) [D loss: (-0.005)(R -0.004, F -0.006)]  [G loss: 0.016] \n",
      "3789 (5, 1) [D loss: (-0.003)(R -0.003, F -0.004)]  [G loss: 0.018] \n",
      "3790 (5, 1) [D loss: (-0.000)(R -0.001, F 0.001)]  [G loss: 0.012] \n",
      "3791 (5, 1) [D loss: (-0.004)(R -0.003, F -0.005)]  [G loss: 0.013] \n",
      "3792 (5, 1) [D loss: (-0.006)(R -0.003, F -0.008)]  [G loss: 0.015] \n",
      "3793 (5, 1) [D loss: (-0.002)(R -0.000, F -0.003)]  [G loss: 0.013] \n",
      "3794 (5, 1) [D loss: (-0.008)(R -0.004, F -0.011)]  [G loss: 0.016] \n",
      "3795 (5, 1) [D loss: (-0.002)(R 0.003, F -0.008)]  [G loss: 0.018] \n",
      "3796 (5, 1) [D loss: (-0.005)(R -0.001, F -0.009)]  [G loss: 0.017] \n",
      "3797 (5, 1) [D loss: (-0.003)(R 0.001, F -0.008)]  [G loss: 0.018] \n",
      "3798 (5, 1) [D loss: (-0.005)(R 0.000, F -0.010)]  [G loss: 0.014] \n",
      "3799 (5, 1) [D loss: (-0.003)(R 0.002, F -0.009)]  [G loss: 0.017] \n",
      "3800 (5, 1) [D loss: (-0.004)(R 0.001, F -0.010)]  [G loss: 0.019] \n",
      "3801 (5, 1) [D loss: (-0.003)(R 0.001, F -0.007)]  [G loss: 0.017] \n",
      "3802 (5, 1) [D loss: (-0.007)(R 0.000, F -0.013)]  [G loss: 0.016] \n",
      "3803 (5, 1) [D loss: (-0.002)(R 0.004, F -0.009)]  [G loss: 0.019] \n",
      "3804 (5, 1) [D loss: (-0.006)(R -0.004, F -0.008)]  [G loss: 0.017] \n",
      "3805 (5, 1) [D loss: (-0.004)(R -0.000, F -0.007)]  [G loss: 0.014] \n",
      "3806 (5, 1) [D loss: (-0.003)(R 0.001, F -0.008)]  [G loss: 0.016] \n",
      "3807 (5, 1) [D loss: (-0.005)(R -0.002, F -0.008)]  [G loss: 0.017] \n",
      "3808 (5, 1) [D loss: (-0.007)(R -0.004, F -0.010)]  [G loss: 0.016] \n",
      "3809 (5, 1) [D loss: (-0.005)(R -0.003, F -0.006)]  [G loss: 0.015] \n",
      "3810 (5, 1) [D loss: (-0.006)(R -0.005, F -0.008)]  [G loss: 0.016] \n",
      "3811 (5, 1) [D loss: (-0.006)(R -0.005, F -0.008)]  [G loss: 0.014] \n",
      "3812 (5, 1) [D loss: (-0.004)(R -0.002, F -0.006)]  [G loss: 0.015] \n",
      "3813 (5, 1) [D loss: (-0.007)(R -0.006, F -0.007)]  [G loss: 0.016] \n",
      "3814 (5, 1) [D loss: (-0.006)(R -0.002, F -0.010)]  [G loss: 0.016] \n",
      "3815 (5, 1) [D loss: (-0.005)(R -0.002, F -0.007)]  [G loss: 0.012] \n",
      "3816 (5, 1) [D loss: (-0.000)(R -0.000, F -0.000)]  [G loss: 0.014] \n",
      "3817 (5, 1) [D loss: (-0.003)(R 0.002, F -0.007)]  [G loss: 0.020] \n",
      "3818 (5, 1) [D loss: (-0.006)(R -0.003, F -0.009)]  [G loss: 0.015] \n",
      "3819 (5, 1) [D loss: (-0.006)(R -0.002, F -0.010)]  [G loss: 0.015] \n",
      "3820 (5, 1) [D loss: (-0.002)(R 0.001, F -0.005)]  [G loss: 0.016] \n",
      "3821 (5, 1) [D loss: (-0.006)(R 0.000, F -0.013)]  [G loss: 0.018] \n",
      "3822 (5, 1) [D loss: (-0.005)(R -0.007, F -0.003)]  [G loss: 0.016] \n",
      "3823 (5, 1) [D loss: (-0.006)(R -0.001, F -0.010)]  [G loss: 0.019] \n",
      "3824 (5, 1) [D loss: (-0.006)(R 0.002, F -0.015)]  [G loss: 0.015] \n",
      "3825 (5, 1) [D loss: (-0.004)(R 0.002, F -0.009)]  [G loss: 0.013] \n",
      "3826 (5, 1) [D loss: (-0.005)(R -0.005, F -0.004)]  [G loss: 0.010] \n",
      "3827 (5, 1) [D loss: (-0.004)(R -0.003, F -0.005)]  [G loss: 0.015] \n",
      "3828 (5, 1) [D loss: (-0.007)(R -0.004, F -0.010)]  [G loss: 0.015] \n",
      "3829 (5, 1) [D loss: (-0.003)(R -0.004, F -0.003)]  [G loss: 0.013] \n",
      "3830 (5, 1) [D loss: (-0.006)(R -0.005, F -0.008)]  [G loss: 0.013] \n",
      "3831 (5, 1) [D loss: (-0.005)(R -0.005, F -0.005)]  [G loss: 0.009] \n",
      "3832 (5, 1) [D loss: (-0.006)(R -0.007, F -0.005)]  [G loss: 0.016] \n",
      "3833 (5, 1) [D loss: (-0.005)(R -0.005, F -0.006)]  [G loss: 0.013] \n",
      "3834 (5, 1) [D loss: (-0.003)(R -0.000, F -0.006)]  [G loss: 0.014] \n",
      "3835 (5, 1) [D loss: (-0.002)(R 0.002, F -0.006)]  [G loss: 0.011] \n",
      "3836 (5, 1) [D loss: (-0.006)(R -0.004, F -0.008)]  [G loss: 0.014] \n",
      "3837 (5, 1) [D loss: (-0.002)(R 0.002, F -0.006)]  [G loss: 0.016] \n",
      "3838 (5, 1) [D loss: (-0.005)(R 0.001, F -0.010)]  [G loss: 0.023] \n",
      "3839 (5, 1) [D loss: (-0.005)(R 0.000, F -0.009)]  [G loss: 0.022] \n",
      "3840 (5, 1) [D loss: (-0.005)(R 0.004, F -0.013)]  [G loss: 0.021] \n",
      "3841 (5, 1) [D loss: (-0.004)(R 0.003, F -0.012)]  [G loss: 0.018] \n",
      "3842 (5, 1) [D loss: (-0.006)(R -0.003, F -0.008)]  [G loss: 0.015] \n",
      "3843 (5, 1) [D loss: (0.001)(R -0.001, F 0.004)]  [G loss: 0.014] \n",
      "3844 (5, 1) [D loss: (-0.001)(R 0.000, F -0.003)]  [G loss: 0.018] \n",
      "3845 (5, 1) [D loss: (-0.003)(R 0.002, F -0.008)]  [G loss: 0.018] \n",
      "3846 (5, 1) [D loss: (-0.007)(R -0.001, F -0.012)]  [G loss: 0.020] \n",
      "3847 (5, 1) [D loss: (-0.005)(R 0.001, F -0.011)]  [G loss: 0.019] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3848 (5, 1) [D loss: (-0.005)(R 0.002, F -0.012)]  [G loss: 0.020] \n",
      "3849 (5, 1) [D loss: (-0.005)(R -0.000, F -0.010)]  [G loss: 0.020] \n",
      "3850 (5, 1) [D loss: (-0.003)(R 0.004, F -0.011)]  [G loss: 0.018] \n",
      "3851 (5, 1) [D loss: (-0.004)(R 0.001, F -0.009)]  [G loss: 0.019] \n",
      "3852 (5, 1) [D loss: (-0.002)(R -0.001, F -0.003)]  [G loss: 0.018] \n",
      "3853 (5, 1) [D loss: (-0.003)(R 0.004, F -0.010)]  [G loss: 0.019] \n",
      "3854 (5, 1) [D loss: (-0.008)(R -0.000, F -0.015)]  [G loss: 0.026] \n",
      "3855 (5, 1) [D loss: (-0.004)(R 0.005, F -0.013)]  [G loss: 0.019] \n",
      "3856 (5, 1) [D loss: (-0.001)(R 0.004, F -0.005)]  [G loss: 0.019] \n",
      "3857 (5, 1) [D loss: (-0.006)(R -0.004, F -0.007)]  [G loss: 0.018] \n",
      "3858 (5, 1) [D loss: (-0.002)(R 0.001, F -0.005)]  [G loss: 0.015] \n",
      "3859 (5, 1) [D loss: (-0.004)(R -0.003, F -0.006)]  [G loss: 0.014] \n",
      "3860 (5, 1) [D loss: (-0.005)(R -0.001, F -0.009)]  [G loss: 0.016] \n",
      "3861 (5, 1) [D loss: (-0.003)(R 0.002, F -0.008)]  [G loss: 0.015] \n",
      "3862 (5, 1) [D loss: (-0.004)(R 0.002, F -0.010)]  [G loss: 0.021] \n",
      "3863 (5, 1) [D loss: (-0.002)(R 0.002, F -0.006)]  [G loss: 0.018] \n",
      "3864 (5, 1) [D loss: (-0.007)(R -0.002, F -0.011)]  [G loss: 0.014] \n",
      "3865 (5, 1) [D loss: (-0.002)(R -0.000, F -0.003)]  [G loss: 0.016] \n",
      "3866 (5, 1) [D loss: (-0.005)(R -0.001, F -0.008)]  [G loss: 0.015] \n",
      "3867 (5, 1) [D loss: (-0.007)(R -0.002, F -0.011)]  [G loss: 0.020] \n",
      "3868 (5, 1) [D loss: (-0.006)(R -0.000, F -0.011)]  [G loss: 0.019] \n",
      "3869 (5, 1) [D loss: (-0.005)(R -0.005, F -0.005)]  [G loss: 0.017] \n",
      "3870 (5, 1) [D loss: (-0.005)(R -0.004, F -0.007)]  [G loss: 0.018] \n",
      "3871 (5, 1) [D loss: (-0.004)(R 0.002, F -0.011)]  [G loss: 0.017] \n",
      "3872 (5, 1) [D loss: (-0.007)(R 0.001, F -0.016)]  [G loss: 0.022] \n",
      "3873 (5, 1) [D loss: (-0.005)(R -0.000, F -0.009)]  [G loss: 0.018] \n",
      "3874 (5, 1) [D loss: (-0.004)(R -0.002, F -0.007)]  [G loss: 0.020] \n",
      "3875 (5, 1) [D loss: (-0.004)(R -0.003, F -0.004)]  [G loss: 0.015] \n",
      "3876 (5, 1) [D loss: (-0.009)(R 0.001, F -0.018)]  [G loss: 0.011] \n",
      "3877 (5, 1) [D loss: (-0.004)(R -0.007, F 0.000)]  [G loss: 0.015] \n",
      "3878 (5, 1) [D loss: (-0.007)(R -0.000, F -0.014)]  [G loss: 0.020] \n",
      "3879 (5, 1) [D loss: (-0.007)(R -0.005, F -0.009)]  [G loss: 0.016] \n",
      "3880 (5, 1) [D loss: (-0.006)(R -0.005, F -0.008)]  [G loss: 0.018] \n",
      "3881 (5, 1) [D loss: (-0.004)(R -0.001, F -0.006)]  [G loss: 0.014] \n",
      "3882 (5, 1) [D loss: (-0.007)(R -0.005, F -0.009)]  [G loss: 0.012] \n",
      "3883 (5, 1) [D loss: (-0.006)(R -0.005, F -0.007)]  [G loss: 0.010] \n",
      "3884 (5, 1) [D loss: (-0.002)(R -0.002, F -0.001)]  [G loss: 0.013] \n",
      "3885 (5, 1) [D loss: (-0.005)(R -0.006, F -0.005)]  [G loss: 0.015] \n",
      "3886 (5, 1) [D loss: (-0.003)(R -0.001, F -0.005)]  [G loss: 0.015] \n",
      "3887 (5, 1) [D loss: (-0.003)(R -0.002, F -0.004)]  [G loss: 0.017] \n",
      "3888 (5, 1) [D loss: (-0.003)(R 0.001, F -0.006)]  [G loss: 0.017] \n",
      "3889 (5, 1) [D loss: (-0.002)(R -0.004, F -0.001)]  [G loss: 0.015] \n",
      "3890 (5, 1) [D loss: (-0.003)(R -0.002, F -0.004)]  [G loss: 0.012] \n",
      "3891 (5, 1) [D loss: (-0.004)(R -0.002, F -0.006)]  [G loss: 0.015] \n",
      "3892 (5, 1) [D loss: (-0.005)(R 0.000, F -0.010)]  [G loss: 0.017] \n",
      "3893 (5, 1) [D loss: (-0.005)(R 0.001, F -0.010)]  [G loss: 0.016] \n",
      "3894 (5, 1) [D loss: (-0.006)(R -0.001, F -0.012)]  [G loss: 0.015] \n",
      "3895 (5, 1) [D loss: (-0.005)(R 0.002, F -0.011)]  [G loss: 0.014] \n",
      "3896 (5, 1) [D loss: (-0.006)(R -0.005, F -0.007)]  [G loss: 0.012] \n",
      "3897 (5, 1) [D loss: (-0.003)(R -0.005, F -0.001)]  [G loss: 0.010] \n",
      "3898 (5, 1) [D loss: (-0.001)(R 0.003, F -0.004)]  [G loss: 0.013] \n",
      "3899 (5, 1) [D loss: (-0.002)(R 0.003, F -0.007)]  [G loss: 0.016] \n",
      "3900 (5, 1) [D loss: (-0.006)(R -0.001, F -0.011)]  [G loss: 0.016] \n",
      "3901 (5, 1) [D loss: (-0.005)(R -0.006, F -0.005)]  [G loss: 0.018] \n",
      "3902 (5, 1) [D loss: (-0.002)(R 0.001, F -0.005)]  [G loss: 0.016] \n",
      "3903 (5, 1) [D loss: (-0.001)(R 0.003, F -0.004)]  [G loss: 0.018] \n",
      "3904 (5, 1) [D loss: (-0.004)(R 0.002, F -0.009)]  [G loss: 0.016] \n",
      "3905 (5, 1) [D loss: (-0.003)(R 0.002, F -0.008)]  [G loss: 0.013] \n",
      "3906 (5, 1) [D loss: (-0.003)(R -0.001, F -0.006)]  [G loss: 0.015] \n",
      "3907 (5, 1) [D loss: (-0.009)(R -0.006, F -0.012)]  [G loss: 0.017] \n",
      "3908 (5, 1) [D loss: (-0.004)(R -0.002, F -0.005)]  [G loss: 0.017] \n",
      "3909 (5, 1) [D loss: (-0.006)(R -0.003, F -0.008)]  [G loss: 0.011] \n",
      "3910 (5, 1) [D loss: (-0.002)(R -0.002, F -0.002)]  [G loss: 0.008] \n",
      "3911 (5, 1) [D loss: (-0.006)(R -0.009, F -0.003)]  [G loss: 0.010] \n",
      "3912 (5, 1) [D loss: (-0.001)(R -0.002, F 0.000)]  [G loss: 0.014] \n",
      "3913 (5, 1) [D loss: (-0.002)(R -0.000, F -0.004)]  [G loss: 0.014] \n",
      "3914 (5, 1) [D loss: (-0.006)(R -0.005, F -0.007)]  [G loss: 0.016] \n",
      "3915 (5, 1) [D loss: (-0.005)(R -0.001, F -0.009)]  [G loss: 0.013] \n",
      "3916 (5, 1) [D loss: (-0.003)(R -0.006, F -0.001)]  [G loss: 0.011] \n",
      "3917 (5, 1) [D loss: (-0.002)(R -0.001, F -0.003)]  [G loss: 0.013] \n",
      "3918 (5, 1) [D loss: (-0.003)(R 0.001, F -0.007)]  [G loss: 0.013] \n",
      "3919 (5, 1) [D loss: (-0.007)(R -0.004, F -0.009)]  [G loss: 0.018] \n",
      "3920 (5, 1) [D loss: (-0.007)(R -0.005, F -0.010)]  [G loss: 0.016] \n",
      "3921 (5, 1) [D loss: (-0.003)(R 0.003, F -0.010)]  [G loss: 0.015] \n",
      "3922 (5, 1) [D loss: (-0.001)(R 0.006, F -0.007)]  [G loss: 0.013] \n",
      "3923 (5, 1) [D loss: (-0.010)(R -0.004, F -0.016)]  [G loss: 0.016] \n",
      "3924 (5, 1) [D loss: (-0.006)(R -0.008, F -0.005)]  [G loss: 0.016] \n",
      "3925 (5, 1) [D loss: (-0.005)(R -0.008, F -0.003)]  [G loss: 0.015] \n",
      "3926 (5, 1) [D loss: (-0.004)(R -0.005, F -0.004)]  [G loss: 0.016] \n",
      "3927 (5, 1) [D loss: (-0.003)(R 0.001, F -0.007)]  [G loss: 0.016] \n",
      "3928 (5, 1) [D loss: (-0.004)(R -0.002, F -0.005)]  [G loss: 0.013] \n",
      "3929 (5, 1) [D loss: (-0.002)(R -0.000, F -0.005)]  [G loss: 0.012] \n",
      "3930 (5, 1) [D loss: (-0.008)(R -0.007, F -0.009)]  [G loss: 0.013] \n",
      "3931 (5, 1) [D loss: (-0.004)(R -0.001, F -0.006)]  [G loss: 0.004] \n",
      "3932 (5, 1) [D loss: (-0.004)(R -0.008, F -0.001)]  [G loss: 0.004] \n",
      "3933 (5, 1) [D loss: (-0.004)(R -0.005, F -0.004)]  [G loss: 0.017] \n",
      "3934 (5, 1) [D loss: (-0.014)(R -0.018, F -0.010)]  [G loss: 0.019] \n",
      "3935 (5, 1) [D loss: (-0.004)(R -0.000, F -0.007)]  [G loss: 0.017] \n",
      "3936 (5, 1) [D loss: (-0.009)(R -0.006, F -0.012)]  [G loss: 0.017] \n",
      "3937 (5, 1) [D loss: (-0.000)(R 0.002, F -0.003)]  [G loss: 0.010] \n",
      "3938 (5, 1) [D loss: (-0.001)(R -0.002, F 0.001)]  [G loss: 0.012] \n",
      "3939 (5, 1) [D loss: (-0.002)(R -0.002, F -0.003)]  [G loss: 0.010] \n",
      "3940 (5, 1) [D loss: (-0.005)(R -0.006, F -0.004)]  [G loss: 0.015] \n",
      "3941 (5, 1) [D loss: (-0.008)(R -0.003, F -0.014)]  [G loss: 0.018] \n",
      "3942 (5, 1) [D loss: (-0.005)(R -0.006, F -0.004)]  [G loss: 0.011] \n",
      "3943 (5, 1) [D loss: (-0.003)(R -0.010, F 0.003)]  [G loss: 0.007] \n",
      "3944 (5, 1) [D loss: (-0.003)(R -0.003, F -0.003)]  [G loss: 0.010] \n",
      "3945 (5, 1) [D loss: (0.000)(R -0.002, F 0.003)]  [G loss: 0.014] \n",
      "3946 (5, 1) [D loss: (-0.007)(R 0.000, F -0.014)]  [G loss: 0.013] \n",
      "3947 (5, 1) [D loss: (-0.008)(R -0.008, F -0.009)]  [G loss: 0.012] \n",
      "3948 (5, 1) [D loss: (-0.001)(R 0.002, F -0.003)]  [G loss: 0.016] \n",
      "3949 (5, 1) [D loss: (-0.009)(R -0.002, F -0.016)]  [G loss: 0.014] \n",
      "3950 (5, 1) [D loss: (-0.002)(R 0.003, F -0.006)]  [G loss: 0.014] \n",
      "3951 (5, 1) [D loss: (0.001)(R 0.004, F -0.002)]  [G loss: 0.012] \n",
      "3952 (5, 1) [D loss: (-0.004)(R -0.002, F -0.006)]  [G loss: 0.016] \n",
      "3953 (5, 1) [D loss: (-0.007)(R -0.005, F -0.009)]  [G loss: 0.016] \n",
      "3954 (5, 1) [D loss: (-0.008)(R -0.008, F -0.009)]  [G loss: 0.018] \n",
      "3955 (5, 1) [D loss: (-0.005)(R -0.008, F -0.001)]  [G loss: 0.013] \n",
      "3956 (5, 1) [D loss: (-0.003)(R -0.003, F -0.002)]  [G loss: 0.012] \n",
      "3957 (5, 1) [D loss: (-0.002)(R -0.002, F -0.002)]  [G loss: 0.015] \n",
      "3958 (5, 1) [D loss: (-0.004)(R -0.001, F -0.006)]  [G loss: 0.013] \n",
      "3959 (5, 1) [D loss: (-0.003)(R 0.005, F -0.011)]  [G loss: 0.017] \n",
      "3960 (5, 1) [D loss: (-0.010)(R -0.007, F -0.013)]  [G loss: 0.012] \n",
      "3961 (5, 1) [D loss: (-0.001)(R -0.004, F 0.003)]  [G loss: 0.009] \n",
      "3962 (5, 1) [D loss: (-0.002)(R -0.011, F 0.006)]  [G loss: 0.006] \n",
      "3963 (5, 1) [D loss: (-0.004)(R -0.008, F 0.001)]  [G loss: 0.004] \n",
      "3964 (5, 1) [D loss: (-0.002)(R -0.012, F 0.008)]  [G loss: 0.008] \n",
      "3965 (5, 1) [D loss: (-0.003)(R -0.010, F 0.003)]  [G loss: 0.007] \n",
      "3966 (5, 1) [D loss: (0.000)(R -0.008, F 0.008)]  [G loss: 0.010] \n",
      "3967 (5, 1) [D loss: (-0.006)(R -0.009, F -0.002)]  [G loss: 0.014] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3968 (5, 1) [D loss: (-0.003)(R -0.002, F -0.005)]  [G loss: 0.014] \n",
      "3969 (5, 1) [D loss: (-0.004)(R -0.003, F -0.005)]  [G loss: 0.010] \n",
      "3970 (5, 1) [D loss: (-0.004)(R -0.003, F -0.005)]  [G loss: 0.013] \n",
      "3971 (5, 1) [D loss: (-0.005)(R -0.002, F -0.008)]  [G loss: 0.017] \n",
      "3972 (5, 1) [D loss: (-0.001)(R 0.002, F -0.003)]  [G loss: 0.013] \n",
      "3973 (5, 1) [D loss: (-0.004)(R 0.001, F -0.009)]  [G loss: 0.015] \n",
      "3974 (5, 1) [D loss: (-0.004)(R -0.001, F -0.007)]  [G loss: 0.014] \n",
      "3975 (5, 1) [D loss: (-0.003)(R -0.000, F -0.005)]  [G loss: 0.017] \n",
      "3976 (5, 1) [D loss: (-0.004)(R -0.002, F -0.005)]  [G loss: 0.012] \n",
      "3977 (5, 1) [D loss: (-0.003)(R -0.003, F -0.004)]  [G loss: 0.014] \n",
      "3978 (5, 1) [D loss: (-0.008)(R -0.006, F -0.010)]  [G loss: 0.017] \n",
      "3979 (5, 1) [D loss: (-0.004)(R -0.006, F -0.001)]  [G loss: 0.013] \n",
      "3980 (5, 1) [D loss: (-0.006)(R -0.004, F -0.008)]  [G loss: 0.014] \n",
      "3981 (5, 1) [D loss: (-0.004)(R -0.003, F -0.005)]  [G loss: 0.013] \n",
      "3982 (5, 1) [D loss: (0.000)(R -0.001, F 0.001)]  [G loss: 0.014] \n",
      "3983 (5, 1) [D loss: (-0.001)(R -0.000, F -0.002)]  [G loss: 0.015] \n",
      "3984 (5, 1) [D loss: (-0.003)(R -0.003, F -0.003)]  [G loss: 0.011] \n",
      "3985 (5, 1) [D loss: (-0.002)(R 0.001, F -0.005)]  [G loss: 0.014] \n",
      "3986 (5, 1) [D loss: (-0.004)(R -0.004, F -0.004)]  [G loss: 0.013] \n",
      "3987 (5, 1) [D loss: (-0.008)(R -0.010, F -0.005)]  [G loss: 0.008] \n",
      "3988 (5, 1) [D loss: (-0.003)(R -0.005, F -0.001)]  [G loss: 0.011] \n",
      "3989 (5, 1) [D loss: (-0.004)(R 0.001, F -0.009)]  [G loss: 0.016] \n",
      "3990 (5, 1) [D loss: (-0.004)(R -0.003, F -0.006)]  [G loss: 0.012] \n",
      "3991 (5, 1) [D loss: (-0.007)(R -0.002, F -0.013)]  [G loss: 0.014] \n",
      "3992 (5, 1) [D loss: (-0.001)(R 0.003, F -0.005)]  [G loss: 0.012] \n",
      "3993 (5, 1) [D loss: (-0.004)(R -0.001, F -0.007)]  [G loss: 0.019] \n",
      "3994 (5, 1) [D loss: (-0.012)(R -0.009, F -0.015)]  [G loss: 0.018] \n",
      "3995 (5, 1) [D loss: (-0.004)(R -0.007, F -0.001)]  [G loss: 0.013] \n",
      "3996 (5, 1) [D loss: (-0.004)(R -0.004, F -0.003)]  [G loss: 0.011] \n",
      "3997 (5, 1) [D loss: (-0.003)(R -0.001, F -0.005)]  [G loss: 0.013] \n",
      "3998 (5, 1) [D loss: (-0.002)(R -0.001, F -0.003)]  [G loss: 0.019] \n",
      "3999 (5, 1) [D loss: (-0.005)(R 0.000, F -0.010)]  [G loss: 0.016] \n",
      "4000 (5, 1) [D loss: (-0.002)(R -0.000, F -0.003)]  [G loss: 0.014] \n",
      "4001 (5, 1) [D loss: (-0.003)(R 0.003, F -0.010)]  [G loss: 0.016] \n",
      "4002 (5, 1) [D loss: (-0.005)(R -0.004, F -0.007)]  [G loss: 0.016] \n",
      "4003 (5, 1) [D loss: (-0.004)(R -0.000, F -0.007)]  [G loss: 0.017] \n",
      "4004 (5, 1) [D loss: (-0.002)(R -0.000, F -0.004)]  [G loss: 0.014] \n",
      "4005 (5, 1) [D loss: (-0.005)(R -0.002, F -0.008)]  [G loss: 0.013] \n",
      "4006 (5, 1) [D loss: (-0.003)(R -0.000, F -0.006)]  [G loss: 0.017] \n",
      "4007 (5, 1) [D loss: (-0.006)(R -0.005, F -0.007)]  [G loss: 0.013] \n",
      "4008 (5, 1) [D loss: (-0.007)(R -0.004, F -0.009)]  [G loss: 0.018] \n",
      "4009 (5, 1) [D loss: (-0.005)(R 0.000, F -0.010)]  [G loss: 0.020] \n",
      "4010 (5, 1) [D loss: (-0.006)(R -0.000, F -0.012)]  [G loss: 0.018] \n",
      "4011 (5, 1) [D loss: (-0.004)(R 0.004, F -0.012)]  [G loss: 0.018] \n",
      "4012 (5, 1) [D loss: (-0.004)(R 0.004, F -0.011)]  [G loss: 0.018] \n",
      "4013 (5, 1) [D loss: (-0.002)(R 0.002, F -0.006)]  [G loss: 0.015] \n",
      "4014 (5, 1) [D loss: (-0.006)(R -0.000, F -0.011)]  [G loss: 0.017] \n",
      "4015 (5, 1) [D loss: (-0.005)(R -0.004, F -0.006)]  [G loss: 0.012] \n",
      "4016 (5, 1) [D loss: (-0.000)(R 0.003, F -0.004)]  [G loss: 0.016] \n",
      "4017 (5, 1) [D loss: (-0.003)(R 0.001, F -0.007)]  [G loss: 0.018] \n",
      "4018 (5, 1) [D loss: (-0.004)(R -0.001, F -0.007)]  [G loss: 0.016] \n",
      "4019 (5, 1) [D loss: (-0.002)(R 0.001, F -0.004)]  [G loss: 0.015] \n",
      "4020 (5, 1) [D loss: (-0.004)(R -0.001, F -0.007)]  [G loss: 0.013] \n",
      "4021 (5, 1) [D loss: (-0.002)(R -0.002, F -0.002)]  [G loss: 0.013] \n",
      "4022 (5, 1) [D loss: (-0.003)(R 0.000, F -0.007)]  [G loss: 0.013] \n",
      "4023 (5, 1) [D loss: (-0.001)(R -0.001, F -0.002)]  [G loss: 0.011] \n",
      "4024 (5, 1) [D loss: (-0.002)(R -0.004, F -0.001)]  [G loss: 0.011] \n",
      "4025 (5, 1) [D loss: (-0.003)(R -0.000, F -0.006)]  [G loss: 0.012] \n",
      "4026 (5, 1) [D loss: (-0.004)(R 0.002, F -0.010)]  [G loss: 0.017] \n",
      "4027 (5, 1) [D loss: (-0.007)(R -0.003, F -0.011)]  [G loss: 0.018] \n",
      "4028 (5, 1) [D loss: (-0.002)(R 0.002, F -0.006)]  [G loss: 0.015] \n",
      "4029 (5, 1) [D loss: (-0.007)(R -0.007, F -0.006)]  [G loss: 0.013] \n",
      "4030 (5, 1) [D loss: (-0.003)(R 0.002, F -0.007)]  [G loss: 0.017] \n",
      "4031 (5, 1) [D loss: (0.001)(R 0.005, F -0.004)]  [G loss: 0.019] \n",
      "4032 (5, 1) [D loss: (-0.009)(R -0.006, F -0.012)]  [G loss: 0.015] \n",
      "4033 (5, 1) [D loss: (-0.000)(R -0.005, F 0.005)]  [G loss: 0.011] \n",
      "4034 (5, 1) [D loss: (-0.004)(R -0.002, F -0.007)]  [G loss: 0.006] \n",
      "4035 (5, 1) [D loss: (-0.000)(R -0.003, F 0.003)]  [G loss: 0.008] \n",
      "4036 (5, 1) [D loss: (-0.003)(R -0.002, F -0.005)]  [G loss: 0.015] \n",
      "4037 (5, 1) [D loss: (-0.005)(R 0.001, F -0.010)]  [G loss: 0.016] \n",
      "4038 (5, 1) [D loss: (-0.006)(R -0.001, F -0.012)]  [G loss: 0.023] \n",
      "4039 (5, 1) [D loss: (-0.003)(R -0.000, F -0.005)]  [G loss: 0.015] \n",
      "4040 (5, 1) [D loss: (0.000)(R 0.008, F -0.007)]  [G loss: 0.017] \n",
      "4041 (5, 1) [D loss: (-0.004)(R -0.003, F -0.006)]  [G loss: 0.017] \n",
      "4042 (5, 1) [D loss: (-0.005)(R -0.007, F -0.004)]  [G loss: 0.012] \n",
      "4043 (5, 1) [D loss: (-0.005)(R -0.004, F -0.006)]  [G loss: 0.011] \n",
      "4044 (5, 1) [D loss: (-0.001)(R -0.001, F -0.002)]  [G loss: 0.014] \n",
      "4045 (5, 1) [D loss: (-0.004)(R -0.003, F -0.006)]  [G loss: 0.015] \n",
      "4046 (5, 1) [D loss: (-0.004)(R 0.001, F -0.009)]  [G loss: 0.011] \n",
      "4047 (5, 1) [D loss: (-0.007)(R -0.006, F -0.007)]  [G loss: 0.012] \n",
      "4048 (5, 1) [D loss: (-0.001)(R -0.006, F 0.005)]  [G loss: 0.010] \n",
      "4049 (5, 1) [D loss: (-0.002)(R -0.002, F -0.001)]  [G loss: 0.008] \n",
      "4050 (5, 1) [D loss: (-0.005)(R -0.003, F -0.008)]  [G loss: 0.015] \n",
      "4051 (5, 1) [D loss: (-0.003)(R -0.001, F -0.004)]  [G loss: 0.018] \n",
      "4052 (5, 1) [D loss: (-0.003)(R 0.003, F -0.009)]  [G loss: 0.015] \n",
      "4053 (5, 1) [D loss: (-0.003)(R -0.004, F -0.003)]  [G loss: 0.015] \n",
      "4054 (5, 1) [D loss: (-0.006)(R -0.004, F -0.008)]  [G loss: 0.008] \n",
      "4055 (5, 1) [D loss: (-0.004)(R -0.004, F -0.003)]  [G loss: 0.007] \n",
      "4056 (5, 1) [D loss: (-0.003)(R -0.002, F -0.004)]  [G loss: 0.011] \n",
      "4057 (5, 1) [D loss: (-0.007)(R -0.004, F -0.010)]  [G loss: 0.013] \n",
      "4058 (5, 1) [D loss: (-0.004)(R -0.002, F -0.007)]  [G loss: 0.020] \n",
      "4059 (5, 1) [D loss: (-0.006)(R -0.002, F -0.010)]  [G loss: 0.019] \n",
      "4060 (5, 1) [D loss: (-0.003)(R 0.001, F -0.007)]  [G loss: 0.017] \n",
      "4061 (5, 1) [D loss: (-0.001)(R 0.004, F -0.005)]  [G loss: 0.018] \n",
      "4062 (5, 1) [D loss: (-0.006)(R 0.000, F -0.013)]  [G loss: 0.020] \n",
      "4063 (5, 1) [D loss: (-0.006)(R 0.001, F -0.013)]  [G loss: 0.017] \n",
      "4064 (5, 1) [D loss: (-0.002)(R 0.001, F -0.006)]  [G loss: 0.015] \n",
      "4065 (5, 1) [D loss: (-0.004)(R 0.001, F -0.008)]  [G loss: 0.010] \n",
      "4066 (5, 1) [D loss: (-0.001)(R -0.000, F -0.001)]  [G loss: 0.012] \n",
      "4067 (5, 1) [D loss: (-0.003)(R -0.006, F 0.000)]  [G loss: 0.013] \n",
      "4068 (5, 1) [D loss: (-0.003)(R -0.004, F -0.002)]  [G loss: 0.011] \n",
      "4069 (5, 1) [D loss: (0.001)(R -0.008, F 0.009)]  [G loss: 0.006] \n",
      "4070 (5, 1) [D loss: (-0.004)(R -0.005, F -0.003)]  [G loss: 0.014] \n",
      "4071 (5, 1) [D loss: (-0.003)(R 0.002, F -0.008)]  [G loss: 0.015] \n",
      "4072 (5, 1) [D loss: (-0.006)(R 0.001, F -0.013)]  [G loss: 0.016] \n",
      "4073 (5, 1) [D loss: (-0.002)(R 0.001, F -0.005)]  [G loss: 0.013] \n",
      "4074 (5, 1) [D loss: (-0.001)(R -0.000, F -0.002)]  [G loss: 0.009] \n",
      "4075 (5, 1) [D loss: (-0.001)(R -0.004, F 0.003)]  [G loss: 0.014] \n",
      "4076 (5, 1) [D loss: (-0.012)(R -0.010, F -0.014)]  [G loss: 0.011] \n",
      "4077 (5, 1) [D loss: (-0.002)(R -0.001, F -0.002)]  [G loss: 0.012] \n",
      "4078 (5, 1) [D loss: (-0.002)(R -0.009, F 0.005)]  [G loss: 0.011] \n",
      "4079 (5, 1) [D loss: (-0.001)(R -0.003, F 0.002)]  [G loss: 0.006] \n",
      "4080 (5, 1) [D loss: (-0.003)(R -0.006, F -0.001)]  [G loss: 0.009] \n",
      "4081 (5, 1) [D loss: (-0.004)(R -0.004, F -0.004)]  [G loss: 0.014] \n",
      "4082 (5, 1) [D loss: (-0.005)(R -0.007, F -0.003)]  [G loss: 0.017] \n",
      "4083 (5, 1) [D loss: (-0.002)(R 0.002, F -0.006)]  [G loss: 0.014] \n",
      "4084 (5, 1) [D loss: (-0.003)(R 0.000, F -0.006)]  [G loss: 0.012] \n",
      "4085 (5, 1) [D loss: (-0.002)(R -0.002, F -0.002)]  [G loss: 0.009] \n",
      "4086 (5, 1) [D loss: (-0.003)(R -0.003, F -0.003)]  [G loss: 0.011] \n",
      "4087 (5, 1) [D loss: (-0.004)(R -0.003, F -0.004)]  [G loss: 0.012] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4088 (5, 1) [D loss: (-0.006)(R -0.003, F -0.008)]  [G loss: 0.017] \n",
      "4089 (5, 1) [D loss: (-0.007)(R -0.007, F -0.008)]  [G loss: 0.009] \n",
      "4090 (5, 1) [D loss: (-0.007)(R -0.012, F -0.003)]  [G loss: 0.001] \n",
      "4091 (5, 1) [D loss: (-0.002)(R -0.001, F -0.003)]  [G loss: 0.012] \n",
      "4092 (5, 1) [D loss: (-0.007)(R -0.002, F -0.013)]  [G loss: 0.020] \n",
      "4093 (5, 1) [D loss: (-0.003)(R 0.001, F -0.008)]  [G loss: 0.019] \n",
      "4094 (5, 1) [D loss: (-0.006)(R -0.004, F -0.009)]  [G loss: 0.016] \n",
      "4095 (5, 1) [D loss: (-0.002)(R -0.000, F -0.004)]  [G loss: 0.011] \n",
      "4096 (5, 1) [D loss: (0.001)(R 0.005, F -0.003)]  [G loss: 0.016] \n",
      "4097 (5, 1) [D loss: (-0.006)(R -0.001, F -0.011)]  [G loss: 0.016] \n",
      "4098 (5, 1) [D loss: (-0.005)(R -0.003, F -0.007)]  [G loss: 0.015] \n",
      "4099 (5, 1) [D loss: (-0.005)(R -0.006, F -0.005)]  [G loss: 0.015] \n",
      "4100 (5, 1) [D loss: (-0.005)(R -0.003, F -0.008)]  [G loss: 0.015] \n",
      "4101 (5, 1) [D loss: (-0.004)(R -0.004, F -0.005)]  [G loss: 0.014] \n",
      "4102 (5, 1) [D loss: (-0.006)(R -0.005, F -0.007)]  [G loss: 0.017] \n",
      "4103 (5, 1) [D loss: (-0.008)(R -0.002, F -0.015)]  [G loss: 0.020] \n",
      "4104 (5, 1) [D loss: (-0.005)(R -0.002, F -0.009)]  [G loss: 0.014] \n",
      "4105 (5, 1) [D loss: (-0.010)(R -0.012, F -0.008)]  [G loss: 0.008] \n",
      "4106 (5, 1) [D loss: (-0.003)(R 0.003, F -0.009)]  [G loss: 0.007] \n",
      "4107 (5, 1) [D loss: (-0.003)(R 0.002, F -0.008)]  [G loss: 0.013] \n",
      "4108 (5, 1) [D loss: (0.000)(R 0.007, F -0.006)]  [G loss: 0.015] \n",
      "4109 (5, 1) [D loss: (-0.001)(R 0.001, F -0.003)]  [G loss: 0.015] \n",
      "4110 (5, 1) [D loss: (-0.004)(R 0.002, F -0.010)]  [G loss: 0.022] \n",
      "4111 (5, 1) [D loss: (-0.004)(R -0.005, F -0.004)]  [G loss: 0.013] \n",
      "4112 (5, 1) [D loss: (-0.002)(R -0.005, F -0.000)]  [G loss: 0.007] \n",
      "4113 (5, 1) [D loss: (-0.003)(R -0.004, F -0.001)]  [G loss: 0.006] \n",
      "4114 (5, 1) [D loss: (-0.001)(R -0.005, F 0.002)]  [G loss: 0.005] \n",
      "4115 (5, 1) [D loss: (-0.001)(R -0.003, F 0.001)]  [G loss: 0.011] \n",
      "4116 (5, 1) [D loss: (-0.006)(R -0.007, F -0.006)]  [G loss: 0.016] \n",
      "4117 (5, 1) [D loss: (-0.003)(R -0.001, F -0.006)]  [G loss: 0.019] \n",
      "4118 (5, 1) [D loss: (-0.003)(R -0.003, F -0.002)]  [G loss: 0.021] \n",
      "4119 (5, 1) [D loss: (-0.007)(R -0.003, F -0.012)]  [G loss: 0.011] \n",
      "4120 (5, 1) [D loss: (-0.002)(R -0.001, F -0.003)]  [G loss: 0.012] \n",
      "4121 (5, 1) [D loss: (-0.002)(R -0.001, F -0.002)]  [G loss: 0.010] \n",
      "4122 (5, 1) [D loss: (-0.008)(R -0.005, F -0.010)]  [G loss: 0.011] \n",
      "4123 (5, 1) [D loss: (-0.003)(R 0.001, F -0.007)]  [G loss: 0.017] \n",
      "4124 (5, 1) [D loss: (-0.003)(R 0.002, F -0.008)]  [G loss: 0.016] \n",
      "4125 (5, 1) [D loss: (-0.000)(R -0.006, F 0.006)]  [G loss: 0.016] \n",
      "4126 (5, 1) [D loss: (-0.004)(R -0.005, F -0.003)]  [G loss: 0.010] \n",
      "4127 (5, 1) [D loss: (-0.002)(R -0.002, F -0.003)]  [G loss: 0.009] \n",
      "4128 (5, 1) [D loss: (-0.002)(R -0.000, F -0.004)]  [G loss: 0.015] \n",
      "4129 (5, 1) [D loss: (-0.006)(R -0.000, F -0.012)]  [G loss: 0.019] \n",
      "4130 (5, 1) [D loss: (-0.006)(R 0.004, F -0.015)]  [G loss: 0.024] \n",
      "4131 (5, 1) [D loss: (-0.006)(R 0.002, F -0.013)]  [G loss: 0.026] \n",
      "4132 (5, 1) [D loss: (-0.007)(R -0.001, F -0.013)]  [G loss: 0.021] \n",
      "4133 (5, 1) [D loss: (-0.005)(R -0.001, F -0.009)]  [G loss: 0.015] \n",
      "4134 (5, 1) [D loss: (-0.003)(R 0.002, F -0.007)]  [G loss: 0.012] \n",
      "4135 (5, 1) [D loss: (-0.004)(R -0.006, F -0.001)]  [G loss: 0.012] \n",
      "4136 (5, 1) [D loss: (-0.005)(R -0.007, F -0.003)]  [G loss: 0.013] \n",
      "4137 (5, 1) [D loss: (-0.003)(R -0.006, F -0.000)]  [G loss: 0.014] \n",
      "4138 (5, 1) [D loss: (-0.004)(R -0.001, F -0.007)]  [G loss: 0.014] \n",
      "4139 (5, 1) [D loss: (0.001)(R -0.000, F 0.002)]  [G loss: 0.015] \n",
      "4140 (5, 1) [D loss: (-0.003)(R 0.001, F -0.007)]  [G loss: 0.016] \n",
      "4141 (5, 1) [D loss: (-0.002)(R -0.003, F -0.001)]  [G loss: 0.011] \n",
      "4142 (5, 1) [D loss: (-0.005)(R -0.003, F -0.006)]  [G loss: 0.013] \n",
      "4143 (5, 1) [D loss: (-0.005)(R 0.001, F -0.011)]  [G loss: 0.011] \n",
      "4144 (5, 1) [D loss: (-0.004)(R -0.001, F -0.007)]  [G loss: 0.009] \n",
      "4145 (5, 1) [D loss: (-0.002)(R -0.000, F -0.005)]  [G loss: 0.009] \n",
      "4146 (5, 1) [D loss: (0.001)(R -0.004, F 0.005)]  [G loss: 0.006] \n",
      "4147 (5, 1) [D loss: (-0.004)(R -0.004, F -0.004)]  [G loss: 0.010] \n",
      "4148 (5, 1) [D loss: (-0.006)(R -0.006, F -0.007)]  [G loss: 0.017] \n",
      "4149 (5, 1) [D loss: (-0.003)(R 0.002, F -0.009)]  [G loss: 0.011] \n",
      "4150 (5, 1) [D loss: (-0.004)(R -0.002, F -0.005)]  [G loss: 0.012] \n",
      "4151 (5, 1) [D loss: (-0.003)(R -0.001, F -0.004)]  [G loss: 0.008] \n",
      "4152 (5, 1) [D loss: (-0.000)(R -0.002, F 0.002)]  [G loss: 0.008] \n",
      "4153 (5, 1) [D loss: (-0.007)(R -0.010, F -0.005)]  [G loss: 0.012] \n",
      "4154 (5, 1) [D loss: (-0.005)(R -0.007, F -0.003)]  [G loss: 0.009] \n",
      "4155 (5, 1) [D loss: (-0.004)(R -0.012, F 0.003)]  [G loss: 0.011] \n",
      "4156 (5, 1) [D loss: (-0.005)(R -0.009, F -0.002)]  [G loss: 0.009] \n",
      "4157 (5, 1) [D loss: (-0.002)(R -0.002, F -0.001)]  [G loss: 0.010] \n",
      "4158 (5, 1) [D loss: (-0.005)(R -0.006, F -0.004)]  [G loss: 0.009] \n",
      "4159 (5, 1) [D loss: (-0.009)(R -0.005, F -0.012)]  [G loss: 0.014] \n",
      "4160 (5, 1) [D loss: (-0.002)(R -0.000, F -0.003)]  [G loss: 0.013] \n",
      "4161 (5, 1) [D loss: (-0.003)(R -0.002, F -0.005)]  [G loss: 0.014] \n",
      "4162 (5, 1) [D loss: (-0.003)(R 0.002, F -0.007)]  [G loss: 0.016] \n",
      "4163 (5, 1) [D loss: (-0.004)(R -0.004, F -0.004)]  [G loss: 0.018] \n",
      "4164 (5, 1) [D loss: (-0.005)(R -0.003, F -0.008)]  [G loss: 0.016] \n",
      "4165 (5, 1) [D loss: (-0.001)(R 0.004, F -0.006)]  [G loss: 0.018] \n",
      "4166 (5, 1) [D loss: (-0.004)(R -0.000, F -0.008)]  [G loss: 0.014] \n",
      "4167 (5, 1) [D loss: (0.000)(R 0.003, F -0.002)]  [G loss: 0.012] \n",
      "4168 (5, 1) [D loss: (-0.004)(R 0.003, F -0.012)]  [G loss: 0.016] \n",
      "4169 (5, 1) [D loss: (-0.006)(R -0.001, F -0.011)]  [G loss: 0.018] \n",
      "4170 (5, 1) [D loss: (-0.005)(R -0.001, F -0.009)]  [G loss: 0.019] \n",
      "4171 (5, 1) [D loss: (-0.004)(R -0.001, F -0.007)]  [G loss: 0.016] \n",
      "4172 (5, 1) [D loss: (-0.004)(R -0.000, F -0.009)]  [G loss: 0.013] \n",
      "4173 (5, 1) [D loss: (-0.004)(R -0.002, F -0.006)]  [G loss: 0.015] \n",
      "4174 (5, 1) [D loss: (-0.004)(R 0.002, F -0.010)]  [G loss: 0.016] \n",
      "4175 (5, 1) [D loss: (-0.003)(R 0.002, F -0.007)]  [G loss: 0.014] \n",
      "4176 (5, 1) [D loss: (-0.004)(R -0.001, F -0.006)]  [G loss: 0.016] \n",
      "4177 (5, 1) [D loss: (-0.004)(R -0.004, F -0.005)]  [G loss: 0.012] \n",
      "4178 (5, 1) [D loss: (-0.003)(R -0.002, F -0.005)]  [G loss: 0.014] \n",
      "4179 (5, 1) [D loss: (-0.004)(R -0.004, F -0.004)]  [G loss: 0.012] \n",
      "4180 (5, 1) [D loss: (-0.004)(R -0.005, F -0.002)]  [G loss: 0.009] \n",
      "4181 (5, 1) [D loss: (-0.001)(R -0.001, F -0.001)]  [G loss: 0.012] \n",
      "4182 (5, 1) [D loss: (-0.002)(R -0.001, F -0.003)]  [G loss: 0.011] \n",
      "4183 (5, 1) [D loss: (-0.005)(R -0.003, F -0.006)]  [G loss: 0.010] \n",
      "4184 (5, 1) [D loss: (-0.002)(R -0.002, F -0.002)]  [G loss: 0.015] \n",
      "4185 (5, 1) [D loss: (-0.004)(R -0.002, F -0.005)]  [G loss: 0.013] \n",
      "4186 (5, 1) [D loss: (-0.002)(R -0.003, F -0.002)]  [G loss: 0.011] \n",
      "4187 (5, 1) [D loss: (-0.006)(R -0.008, F -0.003)]  [G loss: 0.013] \n",
      "4188 (5, 1) [D loss: (-0.008)(R -0.008, F -0.008)]  [G loss: 0.007] \n",
      "4189 (5, 1) [D loss: (-0.004)(R -0.008, F -0.000)]  [G loss: 0.008] \n",
      "4190 (5, 1) [D loss: (-0.003)(R -0.006, F -0.000)]  [G loss: 0.011] \n",
      "4191 (5, 1) [D loss: (-0.004)(R -0.005, F -0.003)]  [G loss: 0.009] \n",
      "4192 (5, 1) [D loss: (-0.003)(R -0.004, F -0.002)]  [G loss: 0.011] \n",
      "4193 (5, 1) [D loss: (-0.006)(R -0.001, F -0.010)]  [G loss: 0.016] \n",
      "4194 (5, 1) [D loss: (-0.003)(R -0.004, F -0.002)]  [G loss: 0.018] \n",
      "4195 (5, 1) [D loss: (-0.005)(R -0.004, F -0.005)]  [G loss: 0.011] \n",
      "4196 (5, 1) [D loss: (-0.004)(R -0.003, F -0.005)]  [G loss: 0.014] \n",
      "4197 (5, 1) [D loss: (-0.004)(R -0.000, F -0.008)]  [G loss: 0.016] \n",
      "4198 (5, 1) [D loss: (-0.006)(R -0.004, F -0.008)]  [G loss: 0.016] \n",
      "4199 (5, 1) [D loss: (-0.005)(R 0.003, F -0.012)]  [G loss: 0.010] \n",
      "4200 (5, 1) [D loss: (-0.001)(R -0.001, F -0.001)]  [G loss: 0.011] \n",
      "4201 (5, 1) [D loss: (-0.003)(R -0.003, F -0.002)]  [G loss: 0.011] \n",
      "4202 (5, 1) [D loss: (-0.003)(R -0.000, F -0.006)]  [G loss: 0.016] \n",
      "4203 (5, 1) [D loss: (-0.002)(R 0.001, F -0.005)]  [G loss: 0.018] \n",
      "4204 (5, 1) [D loss: (-0.003)(R 0.007, F -0.013)]  [G loss: 0.016] \n",
      "4205 (5, 1) [D loss: (-0.002)(R 0.002, F -0.006)]  [G loss: 0.016] \n",
      "4206 (5, 1) [D loss: (-0.004)(R -0.000, F -0.008)]  [G loss: 0.015] \n",
      "4207 (5, 1) [D loss: (-0.003)(R 0.003, F -0.008)]  [G loss: 0.014] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4208 (5, 1) [D loss: (-0.003)(R 0.003, F -0.010)]  [G loss: 0.016] \n",
      "4209 (5, 1) [D loss: (-0.002)(R 0.004, F -0.008)]  [G loss: 0.018] \n",
      "4210 (5, 1) [D loss: (-0.002)(R 0.004, F -0.008)]  [G loss: 0.015] \n",
      "4211 (5, 1) [D loss: (-0.002)(R -0.003, F -0.002)]  [G loss: 0.013] \n",
      "4212 (5, 1) [D loss: (-0.004)(R -0.002, F -0.005)]  [G loss: 0.012] \n",
      "4213 (5, 1) [D loss: (-0.004)(R 0.000, F -0.007)]  [G loss: 0.016] \n",
      "4214 (5, 1) [D loss: (-0.004)(R 0.000, F -0.008)]  [G loss: 0.013] \n",
      "4215 (5, 1) [D loss: (-0.004)(R -0.003, F -0.004)]  [G loss: 0.012] \n",
      "4216 (5, 1) [D loss: (-0.003)(R -0.004, F -0.003)]  [G loss: 0.013] \n",
      "4217 (5, 1) [D loss: (-0.002)(R 0.001, F -0.006)]  [G loss: 0.012] \n",
      "4218 (5, 1) [D loss: (-0.003)(R -0.001, F -0.004)]  [G loss: 0.013] \n",
      "4219 (5, 1) [D loss: (-0.003)(R -0.000, F -0.006)]  [G loss: 0.013] \n",
      "4220 (5, 1) [D loss: (-0.008)(R -0.004, F -0.012)]  [G loss: 0.012] \n",
      "4221 (5, 1) [D loss: (-0.003)(R -0.002, F -0.004)]  [G loss: 0.011] \n",
      "4222 (5, 1) [D loss: (-0.004)(R -0.005, F -0.003)]  [G loss: 0.011] \n",
      "4223 (5, 1) [D loss: (-0.002)(R 0.001, F -0.004)]  [G loss: 0.015] \n",
      "4224 (5, 1) [D loss: (-0.002)(R 0.002, F -0.006)]  [G loss: 0.012] \n",
      "4225 (5, 1) [D loss: (-0.004)(R -0.002, F -0.005)]  [G loss: 0.015] \n",
      "4226 (5, 1) [D loss: (-0.004)(R -0.002, F -0.006)]  [G loss: 0.013] \n",
      "4227 (5, 1) [D loss: (-0.003)(R -0.002, F -0.004)]  [G loss: 0.011] \n",
      "4228 (5, 1) [D loss: (-0.006)(R -0.002, F -0.011)]  [G loss: 0.015] \n",
      "4229 (5, 1) [D loss: (-0.006)(R -0.006, F -0.006)]  [G loss: 0.017] \n",
      "4230 (5, 1) [D loss: (-0.005)(R -0.002, F -0.008)]  [G loss: 0.013] \n",
      "4231 (5, 1) [D loss: (-0.004)(R -0.005, F -0.003)]  [G loss: 0.010] \n",
      "4232 (5, 1) [D loss: (-0.002)(R 0.000, F -0.005)]  [G loss: 0.009] \n",
      "4233 (5, 1) [D loss: (-0.006)(R -0.007, F -0.005)]  [G loss: 0.011] \n",
      "4234 (5, 1) [D loss: (-0.003)(R 0.002, F -0.008)]  [G loss: 0.021] \n",
      "4235 (5, 1) [D loss: (-0.008)(R -0.001, F -0.016)]  [G loss: 0.021] \n",
      "4236 (5, 1) [D loss: (-0.009)(R -0.007, F -0.012)]  [G loss: 0.015] \n",
      "4237 (5, 1) [D loss: (-0.006)(R -0.001, F -0.010)]  [G loss: 0.014] \n",
      "4238 (5, 1) [D loss: (-0.004)(R -0.004, F -0.005)]  [G loss: 0.005] \n",
      "4239 (5, 1) [D loss: (-0.002)(R -0.005, F 0.000)]  [G loss: 0.005] \n",
      "4240 (5, 1) [D loss: (-0.005)(R -0.004, F -0.005)]  [G loss: 0.008] \n",
      "4241 (5, 1) [D loss: (-0.005)(R -0.005, F -0.004)]  [G loss: 0.008] \n",
      "4242 (5, 1) [D loss: (-0.002)(R -0.005, F 0.002)]  [G loss: 0.007] \n",
      "4243 (5, 1) [D loss: (-0.003)(R -0.009, F 0.002)]  [G loss: 0.007] \n",
      "4244 (5, 1) [D loss: (-0.002)(R -0.007, F 0.003)]  [G loss: 0.007] \n",
      "4245 (5, 1) [D loss: (-0.001)(R -0.004, F 0.002)]  [G loss: 0.009] \n",
      "4246 (5, 1) [D loss: (-0.003)(R -0.006, F -0.000)]  [G loss: 0.012] \n",
      "4247 (5, 1) [D loss: (-0.005)(R -0.005, F -0.005)]  [G loss: 0.013] \n",
      "4248 (5, 1) [D loss: (-0.003)(R -0.004, F -0.002)]  [G loss: 0.010] \n",
      "4249 (5, 1) [D loss: (-0.005)(R -0.003, F -0.006)]  [G loss: 0.014] \n",
      "4250 (5, 1) [D loss: (-0.002)(R -0.003, F -0.001)]  [G loss: 0.016] \n",
      "4251 (5, 1) [D loss: (-0.004)(R -0.003, F -0.005)]  [G loss: 0.013] \n",
      "4252 (5, 1) [D loss: (-0.004)(R -0.000, F -0.008)]  [G loss: 0.014] \n",
      "4253 (5, 1) [D loss: (-0.005)(R -0.000, F -0.010)]  [G loss: 0.016] \n",
      "4254 (5, 1) [D loss: (-0.001)(R -0.000, F -0.002)]  [G loss: 0.016] \n",
      "4255 (5, 1) [D loss: (-0.003)(R 0.001, F -0.007)]  [G loss: 0.017] \n",
      "4256 (5, 1) [D loss: (-0.002)(R 0.004, F -0.008)]  [G loss: 0.016] \n",
      "4257 (5, 1) [D loss: (-0.002)(R 0.002, F -0.007)]  [G loss: 0.016] \n",
      "4258 (5, 1) [D loss: (-0.004)(R -0.003, F -0.006)]  [G loss: 0.016] \n",
      "4259 (5, 1) [D loss: (-0.002)(R 0.003, F -0.007)]  [G loss: 0.016] \n",
      "4260 (5, 1) [D loss: (-0.002)(R 0.003, F -0.007)]  [G loss: 0.014] \n",
      "4261 (5, 1) [D loss: (-0.005)(R -0.006, F -0.004)]  [G loss: 0.011] \n",
      "4262 (5, 1) [D loss: (-0.004)(R -0.003, F -0.004)]  [G loss: 0.009] \n",
      "4263 (5, 1) [D loss: (-0.004)(R -0.004, F -0.004)]  [G loss: 0.015] \n",
      "4264 (5, 1) [D loss: (-0.001)(R -0.002, F 0.001)]  [G loss: 0.014] \n",
      "4265 (5, 1) [D loss: (-0.008)(R -0.001, F -0.014)]  [G loss: 0.014] \n",
      "4266 (5, 1) [D loss: (-0.004)(R -0.003, F -0.005)]  [G loss: 0.011] \n",
      "4267 (5, 1) [D loss: (-0.002)(R 0.001, F -0.005)]  [G loss: 0.009] \n",
      "4268 (5, 1) [D loss: (-0.005)(R -0.004, F -0.007)]  [G loss: 0.010] \n",
      "4269 (5, 1) [D loss: (-0.003)(R -0.000, F -0.006)]  [G loss: 0.017] \n",
      "4270 (5, 1) [D loss: (-0.005)(R 0.001, F -0.011)]  [G loss: 0.018] \n",
      "4271 (5, 1) [D loss: (-0.004)(R 0.002, F -0.010)]  [G loss: 0.017] \n",
      "4272 (5, 1) [D loss: (-0.003)(R 0.006, F -0.011)]  [G loss: 0.017] \n",
      "4273 (5, 1) [D loss: (-0.004)(R -0.001, F -0.007)]  [G loss: 0.018] \n",
      "4274 (5, 1) [D loss: (-0.004)(R 0.002, F -0.009)]  [G loss: 0.016] \n",
      "4275 (5, 1) [D loss: (-0.002)(R 0.009, F -0.012)]  [G loss: 0.020] \n",
      "4276 (5, 1) [D loss: (-0.003)(R 0.002, F -0.009)]  [G loss: 0.017] \n",
      "4277 (5, 1) [D loss: (-0.005)(R 0.000, F -0.010)]  [G loss: 0.013] \n",
      "4278 (5, 1) [D loss: (-0.002)(R 0.001, F -0.005)]  [G loss: 0.012] \n",
      "4279 (5, 1) [D loss: (-0.009)(R -0.005, F -0.012)]  [G loss: 0.018] \n",
      "4280 (5, 1) [D loss: (-0.008)(R -0.005, F -0.011)]  [G loss: 0.014] \n",
      "4281 (5, 1) [D loss: (-0.003)(R -0.004, F -0.001)]  [G loss: 0.008] \n",
      "4282 (5, 1) [D loss: (-0.005)(R -0.008, F -0.002)]  [G loss: 0.010] \n",
      "4283 (5, 1) [D loss: (-0.003)(R -0.003, F -0.004)]  [G loss: 0.015] \n",
      "4284 (5, 1) [D loss: (-0.004)(R -0.000, F -0.008)]  [G loss: 0.023] \n",
      "4285 (5, 1) [D loss: (-0.007)(R 0.003, F -0.016)]  [G loss: 0.019] \n",
      "4286 (5, 1) [D loss: (-0.005)(R 0.005, F -0.016)]  [G loss: 0.019] \n",
      "4287 (5, 1) [D loss: (0.001)(R 0.007, F -0.005)]  [G loss: 0.016] \n",
      "4288 (5, 1) [D loss: (-0.001)(R 0.005, F -0.007)]  [G loss: 0.013] \n",
      "4289 (5, 1) [D loss: (-0.004)(R -0.001, F -0.006)]  [G loss: 0.012] \n",
      "4290 (5, 1) [D loss: (-0.002)(R 0.003, F -0.007)]  [G loss: 0.013] \n",
      "4291 (5, 1) [D loss: (-0.003)(R 0.001, F -0.006)]  [G loss: 0.014] \n",
      "4292 (5, 1) [D loss: (-0.001)(R 0.003, F -0.004)]  [G loss: 0.015] \n",
      "4293 (5, 1) [D loss: (-0.007)(R -0.004, F -0.010)]  [G loss: 0.012] \n",
      "4294 (5, 1) [D loss: (-0.003)(R -0.007, F 0.001)]  [G loss: 0.010] \n",
      "4295 (5, 1) [D loss: (0.002)(R 0.001, F 0.002)]  [G loss: 0.006] \n",
      "4296 (5, 1) [D loss: (-0.004)(R -0.003, F -0.005)]  [G loss: 0.013] \n",
      "4297 (5, 1) [D loss: (-0.006)(R -0.007, F -0.004)]  [G loss: 0.011] \n",
      "4298 (5, 1) [D loss: (-0.004)(R -0.005, F -0.003)]  [G loss: 0.013] \n",
      "4299 (5, 1) [D loss: (-0.005)(R -0.006, F -0.004)]  [G loss: 0.009] \n",
      "4300 (5, 1) [D loss: (-0.004)(R -0.007, F -0.002)]  [G loss: 0.010] \n",
      "4301 (5, 1) [D loss: (-0.004)(R -0.001, F -0.006)]  [G loss: 0.013] \n",
      "4302 (5, 1) [D loss: (-0.005)(R -0.005, F -0.004)]  [G loss: 0.012] \n",
      "4303 (5, 1) [D loss: (-0.002)(R -0.005, F 0.000)]  [G loss: 0.010] \n",
      "4304 (5, 1) [D loss: (-0.003)(R -0.003, F -0.003)]  [G loss: 0.011] \n",
      "4305 (5, 1) [D loss: (-0.005)(R -0.005, F -0.005)]  [G loss: 0.012] \n",
      "4306 (5, 1) [D loss: (-0.005)(R -0.003, F -0.006)]  [G loss: 0.004] \n",
      "4307 (5, 1) [D loss: (-0.010)(R -0.010, F -0.011)]  [G loss: 0.004] \n",
      "4308 (5, 1) [D loss: (-0.003)(R -0.007, F 0.002)]  [G loss: 0.007] \n",
      "4309 (5, 1) [D loss: (-0.003)(R -0.006, F -0.001)]  [G loss: 0.013] \n",
      "4310 (5, 1) [D loss: (-0.003)(R -0.002, F -0.005)]  [G loss: 0.012] \n",
      "4311 (5, 1) [D loss: (-0.003)(R -0.005, F -0.002)]  [G loss: 0.007] \n",
      "4312 (5, 1) [D loss: (-0.000)(R -0.003, F 0.002)]  [G loss: 0.007] \n",
      "4313 (5, 1) [D loss: (-0.005)(R -0.005, F -0.004)]  [G loss: 0.011] \n",
      "4314 (5, 1) [D loss: (-0.005)(R -0.013, F 0.002)]  [G loss: 0.006] \n",
      "4315 (5, 1) [D loss: (0.001)(R -0.004, F 0.006)]  [G loss: 0.007] \n",
      "4316 (5, 1) [D loss: (-0.005)(R -0.006, F -0.005)]  [G loss: 0.008] \n",
      "4317 (5, 1) [D loss: (-0.003)(R -0.007, F 0.002)]  [G loss: 0.009] \n",
      "4318 (5, 1) [D loss: (-0.002)(R -0.004, F -0.000)]  [G loss: 0.008] \n",
      "4319 (5, 1) [D loss: (-0.003)(R -0.007, F 0.001)]  [G loss: 0.004] \n",
      "4320 (5, 1) [D loss: (-0.000)(R -0.005, F 0.005)]  [G loss: 0.011] \n",
      "4321 (5, 1) [D loss: (-0.001)(R 0.001, F -0.002)]  [G loss: 0.010] \n",
      "4322 (5, 1) [D loss: (-0.002)(R -0.004, F -0.001)]  [G loss: 0.009] \n",
      "4323 (5, 1) [D loss: (-0.004)(R -0.001, F -0.008)]  [G loss: 0.018] \n",
      "4324 (5, 1) [D loss: (-0.006)(R -0.005, F -0.007)]  [G loss: 0.015] \n",
      "4325 (5, 1) [D loss: (-0.002)(R 0.001, F -0.005)]  [G loss: 0.012] \n",
      "4326 (5, 1) [D loss: (-0.002)(R -0.003, F -0.001)]  [G loss: 0.009] \n",
      "4327 (5, 1) [D loss: (-0.006)(R -0.011, F -0.002)]  [G loss: 0.010] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4328 (5, 1) [D loss: (-0.002)(R -0.004, F -0.000)]  [G loss: 0.010] \n",
      "4329 (5, 1) [D loss: (-0.003)(R -0.004, F -0.001)]  [G loss: 0.010] \n",
      "4330 (5, 1) [D loss: (-0.003)(R -0.003, F -0.002)]  [G loss: 0.011] \n",
      "4331 (5, 1) [D loss: (-0.002)(R -0.002, F -0.001)]  [G loss: 0.011] \n",
      "4332 (5, 1) [D loss: (-0.002)(R 0.001, F -0.006)]  [G loss: 0.014] \n",
      "4333 (5, 1) [D loss: (-0.002)(R -0.002, F -0.002)]  [G loss: 0.011] \n",
      "4334 (5, 1) [D loss: (-0.002)(R -0.002, F -0.003)]  [G loss: 0.012] \n",
      "4335 (5, 1) [D loss: (-0.004)(R -0.004, F -0.005)]  [G loss: 0.007] \n",
      "4336 (5, 1) [D loss: (-0.003)(R -0.004, F -0.003)]  [G loss: 0.009] \n",
      "4337 (5, 1) [D loss: (-0.003)(R -0.003, F -0.004)]  [G loss: 0.010] \n",
      "4338 (5, 1) [D loss: (-0.004)(R 0.001, F -0.009)]  [G loss: 0.013] \n",
      "4339 (5, 1) [D loss: (-0.004)(R 0.000, F -0.007)]  [G loss: 0.013] \n",
      "4340 (5, 1) [D loss: (-0.000)(R 0.000, F -0.001)]  [G loss: 0.012] \n",
      "4341 (5, 1) [D loss: (-0.002)(R 0.001, F -0.005)]  [G loss: 0.013] \n",
      "4342 (5, 1) [D loss: (-0.005)(R -0.002, F -0.008)]  [G loss: 0.014] \n",
      "4343 (5, 1) [D loss: (-0.001)(R 0.003, F -0.005)]  [G loss: 0.015] \n",
      "4344 (5, 1) [D loss: (-0.005)(R -0.000, F -0.009)]  [G loss: 0.014] \n",
      "4345 (5, 1) [D loss: (-0.004)(R -0.006, F -0.002)]  [G loss: 0.014] \n",
      "4346 (5, 1) [D loss: (-0.005)(R -0.005, F -0.006)]  [G loss: 0.013] \n",
      "4347 (5, 1) [D loss: (-0.003)(R 0.002, F -0.008)]  [G loss: 0.015] \n",
      "4348 (5, 1) [D loss: (-0.003)(R 0.003, F -0.009)]  [G loss: 0.014] \n",
      "4349 (5, 1) [D loss: (-0.004)(R -0.001, F -0.006)]  [G loss: 0.013] \n",
      "4350 (5, 1) [D loss: (-0.002)(R 0.002, F -0.005)]  [G loss: 0.012] \n",
      "4351 (5, 1) [D loss: (-0.002)(R -0.000, F -0.004)]  [G loss: 0.014] \n",
      "4352 (5, 1) [D loss: (-0.004)(R -0.002, F -0.005)]  [G loss: 0.012] \n",
      "4353 (5, 1) [D loss: (-0.002)(R -0.000, F -0.004)]  [G loss: 0.011] \n",
      "4354 (5, 1) [D loss: (-0.004)(R -0.002, F -0.005)]  [G loss: 0.010] \n",
      "4355 (5, 1) [D loss: (-0.004)(R -0.002, F -0.005)]  [G loss: 0.007] \n",
      "4356 (5, 1) [D loss: (-0.001)(R 0.001, F -0.002)]  [G loss: 0.011] \n",
      "4357 (5, 1) [D loss: (-0.002)(R -0.002, F -0.003)]  [G loss: 0.018] \n",
      "4358 (5, 1) [D loss: (-0.005)(R -0.002, F -0.008)]  [G loss: 0.013] \n",
      "4359 (5, 1) [D loss: (-0.006)(R -0.005, F -0.008)]  [G loss: 0.015] \n",
      "4360 (5, 1) [D loss: (-0.002)(R -0.002, F -0.002)]  [G loss: 0.014] \n",
      "4361 (5, 1) [D loss: (-0.001)(R -0.003, F 0.000)]  [G loss: 0.010] \n",
      "4362 (5, 1) [D loss: (-0.004)(R -0.004, F -0.003)]  [G loss: 0.008] \n",
      "4363 (5, 1) [D loss: (-0.008)(R -0.014, F -0.002)]  [G loss: 0.007] \n",
      "4364 (5, 1) [D loss: (-0.000)(R 0.001, F -0.001)]  [G loss: 0.010] \n",
      "4365 (5, 1) [D loss: (-0.001)(R 0.001, F -0.003)]  [G loss: 0.009] \n",
      "4366 (5, 1) [D loss: (-0.001)(R 0.001, F -0.003)]  [G loss: 0.011] \n",
      "4367 (5, 1) [D loss: (-0.001)(R 0.001, F -0.004)]  [G loss: 0.008] \n",
      "4368 (5, 1) [D loss: (-0.002)(R -0.000, F -0.003)]  [G loss: 0.012] \n",
      "4369 (5, 1) [D loss: (-0.002)(R -0.003, F -0.001)]  [G loss: 0.012] \n",
      "4370 (5, 1) [D loss: (-0.004)(R -0.003, F -0.005)]  [G loss: 0.011] \n",
      "4371 (5, 1) [D loss: (-0.005)(R -0.004, F -0.006)]  [G loss: 0.015] \n",
      "4372 (5, 1) [D loss: (-0.001)(R -0.002, F -0.000)]  [G loss: 0.015] \n",
      "4373 (5, 1) [D loss: (-0.003)(R 0.002, F -0.008)]  [G loss: 0.014] \n",
      "4374 (5, 1) [D loss: (-0.003)(R -0.001, F -0.005)]  [G loss: 0.013] \n",
      "4375 (5, 1) [D loss: (-0.005)(R -0.001, F -0.009)]  [G loss: 0.013] \n",
      "4376 (5, 1) [D loss: (-0.000)(R 0.007, F -0.008)]  [G loss: 0.017] \n",
      "4377 (5, 1) [D loss: (-0.005)(R -0.002, F -0.008)]  [G loss: 0.011] \n",
      "4378 (5, 1) [D loss: (-0.001)(R 0.001, F -0.003)]  [G loss: 0.011] \n",
      "4379 (5, 1) [D loss: (-0.005)(R -0.006, F -0.004)]  [G loss: 0.010] \n",
      "4380 (5, 1) [D loss: (-0.001)(R -0.005, F 0.003)]  [G loss: 0.009] \n",
      "4381 (5, 1) [D loss: (0.001)(R 0.000, F 0.002)]  [G loss: 0.010] \n",
      "4382 (5, 1) [D loss: (-0.005)(R -0.005, F -0.006)]  [G loss: 0.011] \n",
      "4383 (5, 1) [D loss: (-0.002)(R 0.002, F -0.006)]  [G loss: 0.015] \n",
      "4384 (5, 1) [D loss: (-0.006)(R -0.005, F -0.007)]  [G loss: 0.011] \n",
      "4385 (5, 1) [D loss: (-0.004)(R -0.001, F -0.007)]  [G loss: 0.015] \n",
      "4386 (5, 1) [D loss: (-0.007)(R -0.003, F -0.012)]  [G loss: 0.014] \n",
      "4387 (5, 1) [D loss: (-0.005)(R -0.003, F -0.007)]  [G loss: 0.008] \n",
      "4388 (5, 1) [D loss: (-0.002)(R -0.002, F -0.001)]  [G loss: 0.004] \n",
      "4389 (5, 1) [D loss: (-0.001)(R -0.005, F 0.004)]  [G loss: 0.009] \n",
      "4390 (5, 1) [D loss: (-0.004)(R -0.006, F -0.003)]  [G loss: 0.014] \n",
      "4391 (5, 1) [D loss: (-0.004)(R -0.004, F -0.003)]  [G loss: 0.011] \n",
      "4392 (5, 1) [D loss: (-0.006)(R -0.009, F -0.003)]  [G loss: 0.009] \n",
      "4393 (5, 1) [D loss: (-0.001)(R -0.002, F 0.000)]  [G loss: 0.006] \n",
      "4394 (5, 1) [D loss: (-0.001)(R -0.002, F -0.000)]  [G loss: 0.009] \n",
      "4395 (5, 1) [D loss: (-0.002)(R -0.005, F 0.001)]  [G loss: 0.008] \n",
      "4396 (5, 1) [D loss: (-0.003)(R -0.004, F -0.002)]  [G loss: 0.010] \n",
      "4397 (5, 1) [D loss: (-0.007)(R -0.009, F -0.004)]  [G loss: 0.011] \n",
      "4398 (5, 1) [D loss: (-0.003)(R -0.003, F -0.002)]  [G loss: 0.009] \n",
      "4399 (5, 1) [D loss: (-0.005)(R -0.009, F -0.002)]  [G loss: 0.008] \n",
      "4400 (5, 1) [D loss: (-0.006)(R -0.005, F -0.006)]  [G loss: 0.013] \n",
      "4401 (5, 1) [D loss: (-0.001)(R 0.000, F -0.003)]  [G loss: 0.013] \n",
      "4402 (5, 1) [D loss: (-0.004)(R 0.001, F -0.009)]  [G loss: 0.015] \n",
      "4403 (5, 1) [D loss: (-0.000)(R -0.003, F 0.002)]  [G loss: 0.015] \n",
      "4404 (5, 1) [D loss: (-0.003)(R -0.005, F -0.002)]  [G loss: 0.012] \n",
      "4405 (5, 1) [D loss: (-0.002)(R -0.002, F -0.003)]  [G loss: 0.013] \n",
      "4406 (5, 1) [D loss: (-0.001)(R -0.001, F -0.002)]  [G loss: 0.013] \n",
      "4407 (5, 1) [D loss: (-0.004)(R -0.003, F -0.004)]  [G loss: 0.012] \n",
      "4408 (5, 1) [D loss: (-0.002)(R 0.004, F -0.009)]  [G loss: 0.015] \n",
      "4409 (5, 1) [D loss: (-0.003)(R -0.001, F -0.005)]  [G loss: 0.015] \n",
      "4410 (5, 1) [D loss: (-0.005)(R -0.004, F -0.006)]  [G loss: 0.011] \n",
      "4411 (5, 1) [D loss: (-0.001)(R 0.003, F -0.005)]  [G loss: 0.014] \n",
      "4412 (5, 1) [D loss: (-0.004)(R -0.005, F -0.004)]  [G loss: 0.013] \n",
      "4413 (5, 1) [D loss: (-0.005)(R -0.003, F -0.007)]  [G loss: 0.013] \n",
      "4414 (5, 1) [D loss: (-0.003)(R -0.000, F -0.006)]  [G loss: 0.013] \n",
      "4415 (5, 1) [D loss: (-0.003)(R -0.006, F -0.000)]  [G loss: 0.009] \n",
      "4416 (5, 1) [D loss: (-0.002)(R -0.007, F 0.004)]  [G loss: 0.009] \n",
      "4417 (5, 1) [D loss: (-0.000)(R -0.000, F -0.000)]  [G loss: 0.009] \n",
      "4418 (5, 1) [D loss: (-0.001)(R -0.003, F 0.000)]  [G loss: 0.011] \n",
      "4419 (5, 1) [D loss: (-0.003)(R -0.011, F 0.004)]  [G loss: 0.010] \n",
      "4420 (5, 1) [D loss: (-0.001)(R -0.002, F 0.001)]  [G loss: 0.011] \n",
      "4421 (5, 1) [D loss: (-0.004)(R -0.002, F -0.006)]  [G loss: 0.012] \n",
      "4422 (5, 1) [D loss: (-0.003)(R -0.003, F -0.003)]  [G loss: 0.010] \n",
      "4423 (5, 1) [D loss: (-0.002)(R -0.002, F -0.002)]  [G loss: 0.010] \n",
      "4424 (5, 1) [D loss: (-0.005)(R -0.005, F -0.006)]  [G loss: 0.011] \n",
      "4425 (5, 1) [D loss: (-0.003)(R -0.008, F 0.001)]  [G loss: 0.010] \n",
      "4426 (5, 1) [D loss: (0.000)(R -0.001, F 0.002)]  [G loss: 0.013] \n",
      "4427 (5, 1) [D loss: (-0.003)(R -0.004, F -0.002)]  [G loss: 0.011] \n",
      "4428 (5, 1) [D loss: (-0.001)(R 0.000, F -0.002)]  [G loss: 0.013] \n",
      "4429 (5, 1) [D loss: (-0.006)(R -0.005, F -0.007)]  [G loss: 0.010] \n",
      "4430 (5, 1) [D loss: (-0.004)(R -0.001, F -0.007)]  [G loss: 0.012] \n",
      "4431 (5, 1) [D loss: (-0.003)(R -0.000, F -0.006)]  [G loss: 0.015] \n",
      "4432 (5, 1) [D loss: (-0.003)(R 0.000, F -0.006)]  [G loss: 0.013] \n",
      "4433 (5, 1) [D loss: (-0.003)(R -0.003, F -0.003)]  [G loss: 0.011] \n",
      "4434 (5, 1) [D loss: (-0.003)(R -0.002, F -0.004)]  [G loss: 0.013] \n",
      "4435 (5, 1) [D loss: (-0.001)(R 0.004, F -0.006)]  [G loss: 0.012] \n",
      "4436 (5, 1) [D loss: (-0.004)(R 0.000, F -0.008)]  [G loss: 0.012] \n",
      "4437 (5, 1) [D loss: (-0.001)(R 0.002, F -0.003)]  [G loss: 0.009] \n",
      "4438 (5, 1) [D loss: (0.000)(R -0.002, F 0.002)]  [G loss: 0.011] \n",
      "4439 (5, 1) [D loss: (-0.006)(R -0.004, F -0.007)]  [G loss: 0.015] \n",
      "4440 (5, 1) [D loss: (-0.005)(R 0.000, F -0.009)]  [G loss: 0.015] \n",
      "4441 (5, 1) [D loss: (-0.002)(R 0.002, F -0.005)]  [G loss: 0.013] \n",
      "4442 (5, 1) [D loss: (-0.004)(R 0.000, F -0.007)]  [G loss: 0.011] \n",
      "4443 (5, 1) [D loss: (-0.001)(R -0.001, F -0.002)]  [G loss: 0.011] \n",
      "4444 (5, 1) [D loss: (-0.004)(R -0.005, F -0.004)]  [G loss: 0.012] \n",
      "4445 (5, 1) [D loss: (-0.005)(R -0.009, F 0.000)]  [G loss: 0.009] \n",
      "4446 (5, 1) [D loss: (-0.002)(R -0.001, F -0.003)]  [G loss: 0.008] \n",
      "4447 (5, 1) [D loss: (-0.003)(R -0.001, F -0.004)]  [G loss: 0.011] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4448 (5, 1) [D loss: (-0.007)(R -0.007, F -0.008)]  [G loss: 0.013] \n",
      "4449 (5, 1) [D loss: (-0.002)(R -0.006, F 0.002)]  [G loss: 0.011] \n",
      "4450 (5, 1) [D loss: (-0.001)(R 0.001, F -0.003)]  [G loss: 0.012] \n",
      "4451 (5, 1) [D loss: (-0.003)(R 0.001, F -0.008)]  [G loss: 0.012] \n",
      "4452 (5, 1) [D loss: (-0.006)(R -0.004, F -0.009)]  [G loss: 0.013] \n",
      "4453 (5, 1) [D loss: (-0.002)(R 0.001, F -0.005)]  [G loss: 0.008] \n",
      "4454 (5, 1) [D loss: (-0.002)(R -0.004, F 0.001)]  [G loss: 0.009] \n",
      "4455 (5, 1) [D loss: (-0.002)(R -0.001, F -0.003)]  [G loss: 0.012] \n",
      "4456 (5, 1) [D loss: (0.002)(R 0.008, F -0.004)]  [G loss: 0.014] \n",
      "4457 (5, 1) [D loss: (-0.001)(R 0.003, F -0.005)]  [G loss: 0.015] \n",
      "4458 (5, 1) [D loss: (-0.001)(R -0.001, F -0.002)]  [G loss: 0.013] \n",
      "4459 (5, 1) [D loss: (-0.003)(R -0.001, F -0.005)]  [G loss: 0.014] \n",
      "4460 (5, 1) [D loss: (0.001)(R 0.005, F -0.003)]  [G loss: 0.013] \n",
      "4461 (5, 1) [D loss: (-0.001)(R 0.000, F -0.003)]  [G loss: 0.014] \n",
      "4462 (5, 1) [D loss: (-0.002)(R 0.003, F -0.007)]  [G loss: 0.013] \n",
      "4463 (5, 1) [D loss: (-0.004)(R -0.001, F -0.006)]  [G loss: 0.012] \n",
      "4464 (5, 1) [D loss: (-0.004)(R 0.002, F -0.009)]  [G loss: 0.015] \n",
      "4465 (5, 1) [D loss: (-0.002)(R 0.004, F -0.008)]  [G loss: 0.018] \n",
      "4466 (5, 1) [D loss: (-0.001)(R 0.003, F -0.006)]  [G loss: 0.015] \n",
      "4467 (5, 1) [D loss: (-0.002)(R 0.004, F -0.009)]  [G loss: 0.014] \n",
      "4468 (5, 1) [D loss: (-0.005)(R 0.001, F -0.011)]  [G loss: 0.016] \n",
      "4469 (5, 1) [D loss: (-0.002)(R -0.003, F -0.001)]  [G loss: 0.013] \n",
      "4470 (5, 1) [D loss: (-0.000)(R 0.001, F -0.002)]  [G loss: 0.012] \n",
      "4471 (5, 1) [D loss: (-0.005)(R -0.004, F -0.006)]  [G loss: 0.013] \n",
      "4472 (5, 1) [D loss: (-0.005)(R -0.004, F -0.007)]  [G loss: 0.011] \n",
      "4473 (5, 1) [D loss: (-0.003)(R 0.000, F -0.007)]  [G loss: 0.013] \n",
      "4474 (5, 1) [D loss: (-0.004)(R 0.003, F -0.010)]  [G loss: 0.012] \n",
      "4475 (5, 1) [D loss: (-0.004)(R 0.001, F -0.009)]  [G loss: 0.017] \n",
      "4476 (5, 1) [D loss: (-0.002)(R 0.008, F -0.011)]  [G loss: 0.018] \n",
      "4477 (5, 1) [D loss: (-0.004)(R -0.004, F -0.004)]  [G loss: 0.014] \n",
      "4478 (5, 1) [D loss: (-0.004)(R -0.003, F -0.005)]  [G loss: 0.003] \n",
      "4479 (5, 1) [D loss: (-0.001)(R -0.005, F 0.002)]  [G loss: 0.003] \n",
      "4480 (5, 1) [D loss: (-0.000)(R -0.000, F -0.001)]  [G loss: 0.014] \n",
      "4481 (5, 1) [D loss: (-0.007)(R -0.007, F -0.007)]  [G loss: 0.016] \n",
      "4482 (5, 1) [D loss: (-0.005)(R -0.002, F -0.008)]  [G loss: 0.013] \n",
      "4483 (5, 1) [D loss: (-0.003)(R -0.001, F -0.006)]  [G loss: 0.012] \n",
      "4484 (5, 1) [D loss: (-0.002)(R -0.001, F -0.002)]  [G loss: 0.010] \n",
      "4485 (5, 1) [D loss: (-0.001)(R 0.002, F -0.004)]  [G loss: 0.013] \n",
      "4486 (5, 1) [D loss: (-0.003)(R 0.000, F -0.006)]  [G loss: 0.015] \n",
      "4487 (5, 1) [D loss: (-0.004)(R -0.004, F -0.005)]  [G loss: 0.013] \n",
      "4488 (5, 1) [D loss: (-0.002)(R -0.003, F -0.000)]  [G loss: 0.009] \n",
      "4489 (5, 1) [D loss: (-0.008)(R -0.006, F -0.010)]  [G loss: 0.008] \n",
      "4490 (5, 1) [D loss: (-0.001)(R -0.004, F 0.001)]  [G loss: 0.008] \n",
      "4491 (5, 1) [D loss: (-0.004)(R -0.007, F -0.002)]  [G loss: 0.009] \n",
      "4492 (5, 1) [D loss: (-0.003)(R -0.002, F -0.005)]  [G loss: 0.012] \n",
      "4493 (5, 1) [D loss: (-0.001)(R -0.001, F -0.000)]  [G loss: 0.010] \n",
      "4494 (5, 1) [D loss: (-0.002)(R -0.002, F -0.003)]  [G loss: 0.011] \n",
      "4495 (5, 1) [D loss: (-0.003)(R -0.005, F -0.001)]  [G loss: 0.010] \n",
      "4496 (5, 1) [D loss: (-0.000)(R -0.004, F 0.004)]  [G loss: 0.008] \n",
      "4497 (5, 1) [D loss: (-0.005)(R -0.013, F 0.004)]  [G loss: 0.005] \n",
      "4498 (5, 1) [D loss: (-0.003)(R -0.007, F 0.001)]  [G loss: 0.004] \n",
      "4499 (5, 1) [D loss: (-0.001)(R -0.003, F 0.001)]  [G loss: 0.011] \n",
      "4500 (5, 1) [D loss: (-0.006)(R -0.005, F -0.006)]  [G loss: 0.013] \n",
      "4501 (5, 1) [D loss: (-0.001)(R -0.002, F -0.000)]  [G loss: 0.006] \n",
      "4502 (5, 1) [D loss: (-0.002)(R -0.004, F 0.000)]  [G loss: 0.012] \n",
      "4503 (5, 1) [D loss: (-0.005)(R -0.005, F -0.004)]  [G loss: 0.016] \n",
      "4504 (5, 1) [D loss: (-0.009)(R -0.006, F -0.013)]  [G loss: 0.015] \n",
      "4505 (5, 1) [D loss: (0.001)(R 0.002, F 0.000)]  [G loss: 0.010] \n",
      "4506 (5, 1) [D loss: (-0.004)(R -0.006, F -0.002)]  [G loss: 0.008] \n",
      "4507 (5, 1) [D loss: (-0.002)(R -0.005, F 0.001)]  [G loss: 0.009] \n",
      "4508 (5, 1) [D loss: (-0.002)(R 0.000, F -0.004)]  [G loss: 0.011] \n",
      "4509 (5, 1) [D loss: (-0.005)(R -0.001, F -0.008)]  [G loss: 0.013] \n",
      "4510 (5, 1) [D loss: (-0.003)(R 0.000, F -0.006)]  [G loss: 0.013] \n",
      "4511 (5, 1) [D loss: (-0.004)(R -0.004, F -0.004)]  [G loss: 0.010] \n",
      "4512 (5, 1) [D loss: (-0.001)(R 0.002, F -0.003)]  [G loss: 0.009] \n",
      "4513 (5, 1) [D loss: (-0.004)(R -0.003, F -0.005)]  [G loss: 0.012] \n",
      "4514 (5, 1) [D loss: (-0.005)(R -0.002, F -0.009)]  [G loss: 0.011] \n",
      "4515 (5, 1) [D loss: (-0.001)(R -0.001, F -0.001)]  [G loss: 0.007] \n",
      "4516 (5, 1) [D loss: (-0.002)(R -0.000, F -0.004)]  [G loss: 0.012] \n",
      "4517 (5, 1) [D loss: (-0.003)(R -0.003, F -0.003)]  [G loss: 0.015] \n",
      "4518 (5, 1) [D loss: (-0.004)(R 0.001, F -0.009)]  [G loss: 0.015] \n",
      "4519 (5, 1) [D loss: (-0.005)(R -0.003, F -0.008)]  [G loss: 0.010] \n",
      "4520 (5, 1) [D loss: (-0.002)(R 0.002, F -0.007)]  [G loss: 0.012] \n",
      "4521 (5, 1) [D loss: (-0.006)(R -0.003, F -0.010)]  [G loss: 0.018] \n",
      "4522 (5, 1) [D loss: (-0.005)(R -0.001, F -0.008)]  [G loss: 0.013] \n",
      "4523 (5, 1) [D loss: (-0.002)(R 0.004, F -0.009)]  [G loss: 0.012] \n",
      "4524 (5, 1) [D loss: (-0.001)(R 0.002, F -0.003)]  [G loss: 0.012] \n",
      "4525 (5, 1) [D loss: (-0.006)(R -0.000, F -0.013)]  [G loss: 0.019] \n",
      "4526 (5, 1) [D loss: (-0.007)(R -0.003, F -0.011)]  [G loss: 0.019] \n",
      "4527 (5, 1) [D loss: (-0.000)(R 0.002, F -0.002)]  [G loss: 0.016] \n",
      "4528 (5, 1) [D loss: (-0.005)(R -0.001, F -0.009)]  [G loss: 0.013] \n",
      "4529 (5, 1) [D loss: (0.000)(R 0.006, F -0.005)]  [G loss: 0.013] \n",
      "4530 (5, 1) [D loss: (-0.003)(R 0.004, F -0.011)]  [G loss: 0.015] \n",
      "4531 (5, 1) [D loss: (-0.006)(R -0.007, F -0.005)]  [G loss: 0.011] \n",
      "4532 (5, 1) [D loss: (-0.000)(R -0.002, F 0.001)]  [G loss: 0.013] \n",
      "4533 (5, 1) [D loss: (-0.003)(R -0.002, F -0.004)]  [G loss: 0.002] \n",
      "4534 (5, 1) [D loss: (-0.001)(R -0.006, F 0.004)]  [G loss: 0.003] \n",
      "4535 (5, 1) [D loss: (-0.004)(R -0.010, F 0.002)]  [G loss: 0.004] \n",
      "4536 (5, 1) [D loss: (-0.004)(R -0.010, F 0.002)]  [G loss: 0.006] \n",
      "4537 (5, 1) [D loss: (-0.005)(R -0.010, F 0.000)]  [G loss: 0.005] \n",
      "4538 (5, 1) [D loss: (-0.004)(R -0.008, F -0.000)]  [G loss: 0.005] \n",
      "4539 (5, 1) [D loss: (-0.004)(R -0.012, F 0.004)]  [G loss: 0.006] \n",
      "4540 (5, 1) [D loss: (-0.003)(R -0.009, F 0.003)]  [G loss: 0.002] \n",
      "4541 (5, 1) [D loss: (-0.008)(R -0.013, F -0.003)]  [G loss: 0.002] \n",
      "4542 (5, 1) [D loss: (-0.004)(R -0.011, F 0.003)]  [G loss: 0.004] \n",
      "4543 (5, 1) [D loss: (-0.001)(R -0.006, F 0.004)]  [G loss: 0.006] \n",
      "4544 (5, 1) [D loss: (-0.003)(R -0.011, F 0.006)]  [G loss: 0.006] \n",
      "4545 (5, 1) [D loss: (-0.003)(R -0.006, F -0.000)]  [G loss: 0.005] \n",
      "4546 (5, 1) [D loss: (-0.001)(R -0.001, F -0.001)]  [G loss: 0.009] \n",
      "4547 (5, 1) [D loss: (-0.004)(R -0.005, F -0.004)]  [G loss: 0.011] \n",
      "4548 (5, 1) [D loss: (-0.004)(R -0.002, F -0.005)]  [G loss: 0.014] \n",
      "4549 (5, 1) [D loss: (-0.003)(R -0.004, F -0.002)]  [G loss: 0.013] \n",
      "4550 (5, 1) [D loss: (-0.002)(R -0.000, F -0.004)]  [G loss: 0.012] \n",
      "4551 (5, 1) [D loss: (-0.003)(R -0.002, F -0.004)]  [G loss: 0.013] \n",
      "4552 (5, 1) [D loss: (-0.002)(R -0.002, F -0.002)]  [G loss: 0.012] \n",
      "4553 (5, 1) [D loss: (-0.002)(R -0.002, F -0.003)]  [G loss: 0.014] \n",
      "4554 (5, 1) [D loss: (-0.002)(R 0.002, F -0.006)]  [G loss: 0.014] \n",
      "4555 (5, 1) [D loss: (-0.002)(R 0.003, F -0.008)]  [G loss: 0.013] \n",
      "4556 (5, 1) [D loss: (-0.004)(R -0.000, F -0.008)]  [G loss: 0.015] \n",
      "4557 (5, 1) [D loss: (-0.002)(R -0.001, F -0.003)]  [G loss: 0.015] \n",
      "4558 (5, 1) [D loss: (-0.001)(R 0.001, F -0.003)]  [G loss: 0.012] \n",
      "4559 (5, 1) [D loss: (0.000)(R 0.001, F -0.000)]  [G loss: 0.010] \n",
      "4560 (5, 1) [D loss: (-0.004)(R -0.004, F -0.005)]  [G loss: 0.009] \n",
      "4561 (5, 1) [D loss: (-0.003)(R -0.005, F -0.001)]  [G loss: 0.011] \n",
      "4562 (5, 1) [D loss: (-0.002)(R -0.001, F -0.003)]  [G loss: 0.009] \n",
      "4563 (5, 1) [D loss: (-0.003)(R -0.003, F -0.004)]  [G loss: 0.010] \n",
      "4564 (5, 1) [D loss: (-0.000)(R -0.003, F 0.002)]  [G loss: 0.008] \n",
      "4565 (5, 1) [D loss: (-0.003)(R -0.001, F -0.005)]  [G loss: 0.011] \n",
      "4566 (5, 1) [D loss: (0.001)(R -0.001, F 0.002)]  [G loss: 0.009] \n",
      "4567 (5, 1) [D loss: (-0.005)(R -0.002, F -0.009)]  [G loss: 0.014] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4568 (5, 1) [D loss: (-0.001)(R 0.003, F -0.006)]  [G loss: 0.013] \n",
      "4569 (5, 1) [D loss: (-0.001)(R 0.001, F -0.004)]  [G loss: 0.010] \n",
      "4570 (5, 1) [D loss: (-0.002)(R -0.003, F -0.000)]  [G loss: 0.004] \n",
      "4571 (5, 1) [D loss: (0.000)(R 0.000, F 0.000)]  [G loss: 0.008] \n",
      "4572 (5, 1) [D loss: (-0.003)(R -0.005, F -0.001)]  [G loss: 0.011] \n",
      "4573 (5, 1) [D loss: (0.001)(R -0.002, F 0.005)]  [G loss: 0.010] \n",
      "4574 (5, 1) [D loss: (-0.005)(R -0.007, F -0.003)]  [G loss: 0.010] \n",
      "4575 (5, 1) [D loss: (-0.004)(R -0.005, F -0.004)]  [G loss: 0.010] \n",
      "4576 (5, 1) [D loss: (-0.006)(R -0.005, F -0.008)]  [G loss: 0.013] \n",
      "4577 (5, 1) [D loss: (-0.006)(R 0.001, F -0.013)]  [G loss: 0.013] \n",
      "4578 (5, 1) [D loss: (-0.005)(R -0.005, F -0.005)]  [G loss: 0.006] \n",
      "4579 (5, 1) [D loss: (-0.005)(R -0.001, F -0.009)]  [G loss: 0.015] \n",
      "4580 (5, 1) [D loss: (-0.003)(R -0.000, F -0.006)]  [G loss: 0.011] \n",
      "4581 (5, 1) [D loss: (-0.002)(R -0.001, F -0.004)]  [G loss: 0.015] \n",
      "4582 (5, 1) [D loss: (-0.003)(R -0.000, F -0.006)]  [G loss: 0.015] \n",
      "4583 (5, 1) [D loss: (-0.001)(R -0.001, F -0.001)]  [G loss: 0.010] \n",
      "4584 (5, 1) [D loss: (-0.002)(R 0.001, F -0.005)]  [G loss: 0.010] \n",
      "4585 (5, 1) [D loss: (-0.004)(R -0.007, F -0.002)]  [G loss: 0.007] \n",
      "4586 (5, 1) [D loss: (0.000)(R -0.005, F 0.005)]  [G loss: 0.007] \n",
      "4587 (5, 1) [D loss: (0.001)(R -0.001, F 0.003)]  [G loss: 0.008] \n",
      "4588 (5, 1) [D loss: (-0.001)(R -0.000, F -0.001)]  [G loss: 0.009] \n",
      "4589 (5, 1) [D loss: (-0.008)(R -0.004, F -0.012)]  [G loss: 0.011] \n",
      "4590 (5, 1) [D loss: (-0.003)(R -0.004, F -0.002)]  [G loss: 0.009] \n",
      "4591 (5, 1) [D loss: (-0.004)(R -0.004, F -0.005)]  [G loss: 0.013] \n",
      "4592 (5, 1) [D loss: (0.000)(R 0.002, F -0.001)]  [G loss: 0.008] \n",
      "4593 (5, 1) [D loss: (-0.004)(R -0.001, F -0.008)]  [G loss: 0.011] \n",
      "4594 (5, 1) [D loss: (-0.003)(R -0.000, F -0.007)]  [G loss: 0.013] \n",
      "4595 (5, 1) [D loss: (-0.004)(R -0.001, F -0.007)]  [G loss: 0.010] \n",
      "4596 (5, 1) [D loss: (-0.002)(R -0.002, F -0.002)]  [G loss: 0.009] \n",
      "4597 (5, 1) [D loss: (0.000)(R -0.001, F 0.001)]  [G loss: 0.008] \n",
      "4598 (5, 1) [D loss: (-0.003)(R -0.002, F -0.004)]  [G loss: 0.012] \n",
      "4599 (5, 1) [D loss: (-0.003)(R -0.003, F -0.003)]  [G loss: 0.010] \n",
      "4600 (5, 1) [D loss: (-0.003)(R -0.003, F -0.003)]  [G loss: 0.009] \n",
      "4601 (5, 1) [D loss: (-0.003)(R -0.002, F -0.004)]  [G loss: 0.007] \n",
      "4602 (5, 1) [D loss: (-0.001)(R -0.004, F 0.002)]  [G loss: 0.008] \n",
      "4603 (5, 1) [D loss: (-0.006)(R -0.002, F -0.009)]  [G loss: 0.010] \n",
      "4604 (5, 1) [D loss: (-0.003)(R -0.002, F -0.004)]  [G loss: 0.009] \n",
      "4605 (5, 1) [D loss: (-0.003)(R -0.003, F -0.004)]  [G loss: 0.013] \n",
      "4606 (5, 1) [D loss: (-0.003)(R 0.002, F -0.008)]  [G loss: 0.014] \n",
      "4607 (5, 1) [D loss: (-0.007)(R -0.002, F -0.013)]  [G loss: 0.016] \n",
      "4608 (5, 1) [D loss: (-0.003)(R 0.000, F -0.006)]  [G loss: 0.014] \n",
      "4609 (5, 1) [D loss: (-0.001)(R 0.002, F -0.003)]  [G loss: 0.009] \n",
      "4610 (5, 1) [D loss: (-0.001)(R 0.002, F -0.004)]  [G loss: 0.009] \n",
      "4611 (5, 1) [D loss: (-0.004)(R -0.001, F -0.008)]  [G loss: 0.013] \n",
      "4612 (5, 1) [D loss: (-0.006)(R -0.004, F -0.008)]  [G loss: 0.012] \n",
      "4613 (5, 1) [D loss: (-0.003)(R -0.006, F 0.000)]  [G loss: 0.007] \n",
      "4614 (5, 1) [D loss: (-0.001)(R -0.001, F -0.002)]  [G loss: 0.005] \n",
      "4615 (5, 1) [D loss: (-0.002)(R -0.004, F 0.001)]  [G loss: 0.008] \n",
      "4616 (5, 1) [D loss: (-0.007)(R -0.010, F -0.004)]  [G loss: 0.018] \n",
      "4617 (5, 1) [D loss: (-0.005)(R -0.007, F -0.002)]  [G loss: 0.010] \n",
      "4618 (5, 1) [D loss: (-0.005)(R -0.002, F -0.008)]  [G loss: 0.012] \n",
      "4619 (5, 1) [D loss: (-0.004)(R -0.005, F -0.003)]  [G loss: 0.008] \n",
      "4620 (5, 1) [D loss: (0.001)(R -0.001, F 0.003)]  [G loss: 0.007] \n",
      "4621 (5, 1) [D loss: (-0.004)(R -0.004, F -0.003)]  [G loss: 0.008] \n",
      "4622 (5, 1) [D loss: (-0.004)(R -0.006, F -0.003)]  [G loss: 0.010] \n",
      "4623 (5, 1) [D loss: (-0.001)(R -0.004, F 0.003)]  [G loss: 0.008] \n",
      "4624 (5, 1) [D loss: (-0.004)(R -0.005, F -0.003)]  [G loss: 0.010] \n",
      "4625 (5, 1) [D loss: (-0.003)(R -0.004, F -0.002)]  [G loss: 0.010] \n",
      "4626 (5, 1) [D loss: (-0.002)(R -0.002, F -0.002)]  [G loss: 0.008] \n",
      "4627 (5, 1) [D loss: (-0.002)(R -0.002, F -0.002)]  [G loss: 0.011] \n",
      "4628 (5, 1) [D loss: (-0.005)(R 0.002, F -0.012)]  [G loss: 0.009] \n",
      "4629 (5, 1) [D loss: (-0.001)(R 0.002, F -0.004)]  [G loss: 0.009] \n",
      "4630 (5, 1) [D loss: (-0.003)(R -0.003, F -0.003)]  [G loss: 0.011] \n",
      "4631 (5, 1) [D loss: (-0.004)(R -0.005, F -0.002)]  [G loss: 0.015] \n",
      "4632 (5, 1) [D loss: (-0.004)(R -0.004, F -0.004)]  [G loss: 0.009] \n",
      "4633 (5, 1) [D loss: (-0.005)(R -0.009, F -0.001)]  [G loss: 0.009] \n",
      "4634 (5, 1) [D loss: (-0.004)(R -0.006, F -0.003)]  [G loss: 0.010] \n",
      "4635 (5, 1) [D loss: (-0.001)(R -0.007, F 0.005)]  [G loss: 0.004] \n",
      "4636 (5, 1) [D loss: (-0.002)(R -0.003, F -0.002)]  [G loss: 0.014] \n",
      "4637 (5, 1) [D loss: (0.000)(R 0.003, F -0.003)]  [G loss: 0.012] \n",
      "4638 (5, 1) [D loss: (-0.002)(R 0.000, F -0.004)]  [G loss: 0.013] \n",
      "4639 (5, 1) [D loss: (-0.001)(R 0.005, F -0.006)]  [G loss: 0.012] \n",
      "4640 (5, 1) [D loss: (-0.003)(R -0.001, F -0.004)]  [G loss: 0.014] \n",
      "4641 (5, 1) [D loss: (-0.004)(R -0.003, F -0.006)]  [G loss: 0.009] \n",
      "4642 (5, 1) [D loss: (-0.004)(R -0.004, F -0.003)]  [G loss: 0.009] \n",
      "4643 (5, 1) [D loss: (-0.004)(R -0.006, F -0.002)]  [G loss: 0.010] \n",
      "4644 (5, 1) [D loss: (-0.006)(R -0.008, F -0.004)]  [G loss: 0.009] \n",
      "4645 (5, 1) [D loss: (-0.002)(R -0.005, F 0.000)]  [G loss: 0.007] \n",
      "4646 (5, 1) [D loss: (-0.002)(R -0.005, F 0.001)]  [G loss: 0.009] \n",
      "4647 (5, 1) [D loss: (0.000)(R 0.001, F -0.001)]  [G loss: 0.010] \n",
      "4648 (5, 1) [D loss: (-0.002)(R 0.001, F -0.004)]  [G loss: 0.009] \n",
      "4649 (5, 1) [D loss: (-0.002)(R -0.002, F -0.002)]  [G loss: 0.011] \n",
      "4650 (5, 1) [D loss: (-0.002)(R 0.003, F -0.006)]  [G loss: 0.013] \n",
      "4651 (5, 1) [D loss: (-0.002)(R 0.001, F -0.005)]  [G loss: 0.015] \n",
      "4652 (5, 1) [D loss: (-0.005)(R -0.003, F -0.007)]  [G loss: 0.011] \n",
      "4653 (5, 1) [D loss: (-0.002)(R 0.003, F -0.006)]  [G loss: 0.013] \n",
      "4654 (5, 1) [D loss: (-0.003)(R -0.001, F -0.006)]  [G loss: 0.011] \n",
      "4655 (5, 1) [D loss: (-0.002)(R 0.001, F -0.005)]  [G loss: 0.011] \n",
      "4656 (5, 1) [D loss: (-0.004)(R 0.000, F -0.008)]  [G loss: 0.015] \n",
      "4657 (5, 1) [D loss: (-0.008)(R -0.007, F -0.010)]  [G loss: 0.006] \n",
      "4658 (5, 1) [D loss: (-0.001)(R -0.003, F 0.001)]  [G loss: 0.004] \n",
      "4659 (5, 1) [D loss: (-0.001)(R -0.003, F 0.000)]  [G loss: 0.006] \n",
      "4660 (5, 1) [D loss: (-0.003)(R -0.002, F -0.003)]  [G loss: 0.014] \n",
      "4661 (5, 1) [D loss: (-0.004)(R -0.006, F -0.001)]  [G loss: 0.009] \n",
      "4662 (5, 1) [D loss: (-0.002)(R -0.005, F 0.000)]  [G loss: 0.009] \n",
      "4663 (5, 1) [D loss: (-0.003)(R -0.005, F -0.001)]  [G loss: 0.006] \n",
      "4664 (5, 1) [D loss: (-0.003)(R -0.005, F -0.002)]  [G loss: 0.004] \n",
      "4665 (5, 1) [D loss: (-0.005)(R -0.007, F -0.002)]  [G loss: 0.008] \n",
      "4666 (5, 1) [D loss: (-0.003)(R -0.004, F -0.002)]  [G loss: 0.012] \n",
      "4667 (5, 1) [D loss: (-0.001)(R -0.001, F -0.002)]  [G loss: 0.011] \n",
      "4668 (5, 1) [D loss: (-0.005)(R -0.007, F -0.003)]  [G loss: 0.007] \n",
      "4669 (5, 1) [D loss: (-0.000)(R -0.000, F -0.000)]  [G loss: 0.005] \n",
      "4670 (5, 1) [D loss: (-0.007)(R -0.009, F -0.006)]  [G loss: 0.002] \n",
      "4671 (5, 1) [D loss: (-0.001)(R -0.003, F 0.001)]  [G loss: 0.004] \n",
      "4672 (5, 1) [D loss: (-0.003)(R -0.007, F 0.000)]  [G loss: 0.009] \n",
      "4673 (5, 1) [D loss: (0.001)(R 0.002, F 0.001)]  [G loss: 0.008] \n",
      "4674 (5, 1) [D loss: (-0.001)(R -0.000, F -0.002)]  [G loss: 0.010] \n",
      "4675 (5, 1) [D loss: (-0.004)(R -0.003, F -0.005)]  [G loss: 0.015] \n",
      "4676 (5, 1) [D loss: (-0.000)(R 0.001, F -0.002)]  [G loss: 0.016] \n",
      "4677 (5, 1) [D loss: (-0.003)(R -0.002, F -0.005)]  [G loss: 0.013] \n",
      "4678 (5, 1) [D loss: (-0.003)(R 0.001, F -0.008)]  [G loss: 0.017] \n",
      "4679 (5, 1) [D loss: (-0.006)(R -0.004, F -0.009)]  [G loss: 0.014] \n",
      "4680 (5, 1) [D loss: (0.001)(R 0.002, F -0.000)]  [G loss: 0.012] \n",
      "4681 (5, 1) [D loss: (-0.004)(R -0.005, F -0.004)]  [G loss: 0.012] \n",
      "4682 (5, 1) [D loss: (-0.004)(R -0.003, F -0.005)]  [G loss: 0.009] \n",
      "4683 (5, 1) [D loss: (-0.002)(R -0.001, F -0.002)]  [G loss: 0.011] \n",
      "4684 (5, 1) [D loss: (-0.003)(R -0.002, F -0.005)]  [G loss: 0.012] \n",
      "4685 (5, 1) [D loss: (-0.003)(R -0.005, F -0.002)]  [G loss: 0.012] \n",
      "4686 (5, 1) [D loss: (-0.003)(R -0.002, F -0.004)]  [G loss: 0.008] \n",
      "4687 (5, 1) [D loss: (-0.002)(R -0.001, F -0.003)]  [G loss: 0.010] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4688 (5, 1) [D loss: (-0.001)(R -0.001, F -0.000)]  [G loss: 0.010] \n",
      "4689 (5, 1) [D loss: (-0.002)(R -0.000, F -0.004)]  [G loss: 0.008] \n",
      "4690 (5, 1) [D loss: (-0.002)(R -0.001, F -0.003)]  [G loss: 0.009] \n",
      "4691 (5, 1) [D loss: (-0.002)(R -0.002, F -0.002)]  [G loss: 0.007] \n",
      "4692 (5, 1) [D loss: (-0.004)(R -0.005, F -0.002)]  [G loss: 0.009] \n",
      "4693 (5, 1) [D loss: (-0.002)(R 0.000, F -0.004)]  [G loss: 0.009] \n",
      "4694 (5, 1) [D loss: (-0.001)(R 0.002, F -0.004)]  [G loss: 0.012] \n",
      "4695 (5, 1) [D loss: (-0.003)(R -0.001, F -0.005)]  [G loss: 0.012] \n",
      "4696 (5, 1) [D loss: (-0.001)(R -0.002, F -0.000)]  [G loss: 0.008] \n",
      "4697 (5, 1) [D loss: (-0.002)(R -0.001, F -0.004)]  [G loss: 0.006] \n",
      "4698 (5, 1) [D loss: (-0.006)(R -0.006, F -0.007)]  [G loss: 0.005] \n",
      "4699 (5, 1) [D loss: (-0.001)(R 0.000, F -0.003)]  [G loss: 0.010] \n",
      "4700 (5, 1) [D loss: (-0.003)(R -0.003, F -0.002)]  [G loss: 0.011] \n",
      "4701 (5, 1) [D loss: (-0.007)(R -0.004, F -0.009)]  [G loss: 0.016] \n",
      "4702 (5, 1) [D loss: (-0.002)(R -0.001, F -0.003)]  [G loss: 0.009] \n",
      "4703 (5, 1) [D loss: (-0.003)(R -0.002, F -0.003)]  [G loss: 0.011] \n",
      "4704 (5, 1) [D loss: (-0.004)(R -0.002, F -0.006)]  [G loss: 0.011] \n",
      "4705 (5, 1) [D loss: (-0.005)(R -0.001, F -0.009)]  [G loss: 0.011] \n",
      "4706 (5, 1) [D loss: (-0.001)(R -0.002, F 0.000)]  [G loss: 0.009] \n",
      "4707 (5, 1) [D loss: (-0.004)(R -0.006, F -0.003)]  [G loss: 0.008] \n",
      "4708 (5, 1) [D loss: (-0.004)(R -0.006, F -0.002)]  [G loss: 0.007] \n",
      "4709 (5, 1) [D loss: (-0.001)(R -0.001, F 0.000)]  [G loss: 0.010] \n",
      "4710 (5, 1) [D loss: (-0.006)(R -0.004, F -0.007)]  [G loss: 0.013] \n",
      "4711 (5, 1) [D loss: (-0.000)(R 0.002, F -0.002)]  [G loss: 0.009] \n",
      "4712 (5, 1) [D loss: (-0.004)(R -0.005, F -0.002)]  [G loss: 0.009] \n",
      "4713 (5, 1) [D loss: (-0.004)(R -0.006, F -0.001)]  [G loss: 0.010] \n",
      "4714 (5, 1) [D loss: (-0.002)(R -0.005, F 0.000)]  [G loss: 0.005] \n",
      "4715 (5, 1) [D loss: (-0.003)(R -0.008, F 0.002)]  [G loss: 0.006] \n",
      "4716 (5, 1) [D loss: (-0.001)(R -0.002, F -0.000)]  [G loss: 0.005] \n",
      "4717 (5, 1) [D loss: (-0.004)(R -0.005, F -0.003)]  [G loss: 0.007] \n",
      "4718 (5, 1) [D loss: (-0.005)(R -0.005, F -0.005)]  [G loss: 0.009] \n",
      "4719 (5, 1) [D loss: (-0.004)(R -0.004, F -0.004)]  [G loss: 0.005] \n",
      "4720 (5, 1) [D loss: (-0.001)(R -0.007, F 0.004)]  [G loss: 0.007] \n",
      "4721 (5, 1) [D loss: (-0.007)(R -0.012, F -0.002)]  [G loss: 0.008] \n",
      "4722 (5, 1) [D loss: (-0.002)(R -0.003, F -0.001)]  [G loss: 0.003] \n",
      "4723 (5, 1) [D loss: (-0.003)(R -0.008, F 0.002)]  [G loss: 0.001] \n",
      "4724 (5, 1) [D loss: (-0.001)(R -0.008, F 0.006)]  [G loss: 0.005] \n",
      "4725 (5, 1) [D loss: (-0.003)(R -0.006, F -0.001)]  [G loss: 0.007] \n",
      "4726 (5, 1) [D loss: (-0.004)(R -0.005, F -0.003)]  [G loss: 0.012] \n",
      "4727 (5, 1) [D loss: (-0.001)(R 0.000, F -0.003)]  [G loss: 0.010] \n",
      "4728 (5, 1) [D loss: (-0.002)(R 0.002, F -0.006)]  [G loss: 0.011] \n",
      "4729 (5, 1) [D loss: (0.000)(R 0.002, F -0.002)]  [G loss: 0.010] \n",
      "4730 (5, 1) [D loss: (-0.003)(R -0.002, F -0.004)]  [G loss: 0.012] \n",
      "4731 (5, 1) [D loss: (-0.003)(R 0.000, F -0.007)]  [G loss: 0.011] \n",
      "4732 (5, 1) [D loss: (-0.004)(R -0.004, F -0.003)]  [G loss: 0.008] \n",
      "4733 (5, 1) [D loss: (-0.002)(R -0.002, F -0.003)]  [G loss: 0.008] \n",
      "4734 (5, 1) [D loss: (0.001)(R -0.005, F 0.008)]  [G loss: 0.005] \n",
      "4735 (5, 1) [D loss: (-0.002)(R -0.001, F -0.003)]  [G loss: 0.008] \n",
      "4736 (5, 1) [D loss: (-0.003)(R -0.002, F -0.004)]  [G loss: 0.016] \n",
      "4737 (5, 1) [D loss: (-0.006)(R -0.002, F -0.010)]  [G loss: 0.018] \n",
      "4738 (5, 1) [D loss: (-0.008)(R 0.001, F -0.017)]  [G loss: 0.012] \n",
      "4739 (5, 1) [D loss: (-0.000)(R -0.000, F -0.000)]  [G loss: 0.010] \n",
      "4740 (5, 1) [D loss: (0.000)(R 0.005, F -0.005)]  [G loss: 0.012] \n",
      "4741 (5, 1) [D loss: (-0.005)(R -0.007, F -0.004)]  [G loss: 0.011] \n",
      "4742 (5, 1) [D loss: (-0.004)(R -0.004, F -0.003)]  [G loss: 0.011] \n",
      "4743 (5, 1) [D loss: (-0.008)(R -0.008, F -0.008)]  [G loss: 0.013] \n",
      "4744 (5, 1) [D loss: (-0.006)(R -0.007, F -0.005)]  [G loss: 0.005] \n",
      "4745 (5, 1) [D loss: (-0.000)(R -0.001, F -0.000)]  [G loss: 0.007] \n",
      "4746 (5, 1) [D loss: (-0.001)(R -0.004, F 0.002)]  [G loss: 0.010] \n",
      "4747 (5, 1) [D loss: (-0.002)(R 0.000, F -0.003)]  [G loss: 0.006] \n",
      "4748 (5, 1) [D loss: (-0.002)(R -0.003, F -0.001)]  [G loss: 0.009] \n",
      "4749 (5, 1) [D loss: (-0.004)(R -0.004, F -0.004)]  [G loss: 0.014] \n",
      "4750 (5, 1) [D loss: (-0.002)(R 0.002, F -0.006)]  [G loss: 0.013] \n",
      "4751 (5, 1) [D loss: (-0.002)(R -0.003, F -0.001)]  [G loss: 0.011] \n",
      "4752 (5, 1) [D loss: (-0.004)(R -0.001, F -0.006)]  [G loss: 0.007] \n",
      "4753 (5, 1) [D loss: (-0.003)(R -0.003, F -0.002)]  [G loss: 0.005] \n",
      "4754 (5, 1) [D loss: (-0.002)(R -0.002, F -0.002)]  [G loss: 0.010] \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-85-13afab3e5641>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;34m,\u001b[0m \u001b[0mlarge_n_critic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;34m,\u001b[0m \u001b[0mclip_threshold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.01\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0;34m,\u001b[0m \u001b[0musing_generator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m )\n",
      "\u001b[0;32m~/Git/Personal/GDL/generative_deep_learning_code/models/WGAN.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, x_train, batch_size, epochs, run_folder, print_every_n_batches, n_critic, clip_threshold, large_it_critic, large_n_critic, using_generator)\u001b[0m\n\u001b[1;32m    301\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 303\u001b[0;31m                 \u001b[0md_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_critic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclip_threshold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0musing_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    304\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m             \u001b[0mg_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Git/Personal/GDL/generative_deep_learning_code/models/WGAN.py\u001b[0m in \u001b[0;36mtrain_critic\u001b[0;34m(self, x_train, batch_size, clip_threshold, using_generator)\u001b[0m\n\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m         \u001b[0mnoise\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mz_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 258\u001b[0;31m         \u001b[0mgen_imgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnoise\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    259\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0md_loss_real\u001b[0m \u001b[0;34m=\u001b[0m   \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcritic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrue_imgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/gdl/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m   1167\u001b[0m                                             \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1168\u001b[0m                                             \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1169\u001b[0;31m                                             steps=steps)\n\u001b[0m\u001b[1;32m   1170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1171\u001b[0m     def train_on_batch(self, x, y,\n",
      "\u001b[0;32m~/.virtualenvs/gdl/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mpredict_loop\u001b[0;34m(model, f, ins, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m    292\u001b[0m                 \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 294\u001b[0;31m             \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    295\u001b[0m             \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbatch_index\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/gdl/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/gdl/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/gdl/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1380\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1381\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1382\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1383\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1384\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "gan.train(     \n",
    "    x_train\n",
    "    , batch_size = 128\n",
    "    , epochs = 100000\n",
    "    , run_folder = RUN_FOLDER\n",
    "    , print_every_n_batches = 5\n",
    "    , n_critic = 5\n",
    "    , large_it_critic = 5\n",
    "    , large_n_critic = 5\n",
    "    , clip_threshold = 0.01\n",
    "    , using_generator = False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[D loss: (-0.003)(R -0.001, F -0.005)]\n",
      "[D loss: (-0.012)(R -0.014, F -0.010)]\n",
      "[D loss: (0.000)(R -0.007, F 0.007)]\n",
      "[D loss: (-0.003)(R 0.003, F -0.010)]\n",
      "[D loss: (-0.008)(R -0.004, F -0.012)]\n",
      "[D loss: (-0.013)(R -0.008, F -0.017)]\n",
      "[D loss: (-0.024)(R -0.018, F -0.030)]\n",
      "[D loss: (0.002)(R 0.010, F -0.005)]\n",
      "[D loss: (-0.003)(R 0.006, F -0.012)]\n",
      "[D loss: (-0.011)(R 0.008, F -0.031)]\n",
      "[D loss: (-0.017)(R -0.015, F -0.019)]\n",
      "[D loss: (-0.032)(R -0.004, F -0.061)]\n",
      "[D loss: (-0.017)(R 0.005, F -0.038)]\n",
      "[D loss: (-0.025)(R -0.019, F -0.031)]\n",
      "[D loss: (-0.013)(R 0.003, F -0.030)]\n",
      "[D loss: (-0.015)(R 0.001, F -0.031)]\n",
      "[D loss: (-0.013)(R -0.005, F -0.020)]\n",
      "[D loss: (-0.025)(R -0.028, F -0.023)]\n",
      "[D loss: (-0.017)(R 0.004, F -0.038)]\n",
      "[D loss: (-0.015)(R 0.006, F -0.036)]\n",
      "[D loss: (-0.017)(R 0.002, F -0.035)]\n",
      "[D loss: (-0.020)(R -0.014, F -0.027)]\n",
      "[D loss: (-0.022)(R -0.002, F -0.041)]\n",
      "[D loss: (-0.029)(R -0.017, F -0.040)]\n",
      "[D loss: (-0.011)(R 0.014, F -0.036)]\n",
      "[D loss: (-0.037)(R -0.014, F -0.060)]\n",
      "[D loss: (-0.035)(R -0.004, F -0.066)]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-69-e5f41af0443f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mgen_imgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnoise\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0md_loss_real\u001b[0m \u001b[0;34m=\u001b[0m   \u001b[0mgan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcritic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrue_imgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0md_loss_fake\u001b[0m \u001b[0;34m=\u001b[0m   \u001b[0mgan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcritic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgen_imgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfake\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0md_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.5\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0md_loss_real\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0md_loss_fake\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/gdl/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1217\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/gdl/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/gdl/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/gdl/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1380\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1381\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1382\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1383\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1384\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 32\n",
    "\n",
    "check = True\n",
    "while check :\n",
    "    \n",
    "    for _ in range(5):\n",
    "\n",
    "        valid = np.ones((BATCH_SIZE,1))\n",
    "        fake = -np.ones((BATCH_SIZE,1))\n",
    "\n",
    "        idx = np.random.randint(0, x_train.shape[0], BATCH_SIZE)\n",
    "        true_imgs = x_train[idx]\n",
    "\n",
    "        noise = np.random.normal(0, 1, (BATCH_SIZE, gan.z_dim))\n",
    "        gen_imgs = gan.generator.predict(noise)\n",
    "\n",
    "        d_loss_real =   gan.critic.train_on_batch(true_imgs, valid)\n",
    "        d_loss_fake =   gan.critic.train_on_batch(gen_imgs, fake)\n",
    "        d_loss = 0.5 * (d_loss_real + d_loss_fake)\n",
    "        \n",
    "        for l in gan.critic.layers:\n",
    "            weights = l.get_weights()\n",
    "            weights = [np.clip(w, -0.01, 0.01) for w in weights]\n",
    "            l.set_weights(weights)\n",
    "            \n",
    "\n",
    "    # Plot the progress\n",
    "    print (\"[D loss: (%.3f)(R %.3f, F %.3f)]\" % (d_loss, d_loss_real, d_loss_fake))  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "plt.plot([x[0] for x in gan.d_losses], color='black', linewidth=0.25)\n",
    "\n",
    "plt.plot([x[1] for x in gan.d_losses], color='green', linewidth=0.25)\n",
    "plt.plot([x[2] for x in gan.d_losses], color='red', linewidth=0.25)\n",
    "plt.plot(gan.g_losses, color='orange', linewidth=0.25)\n",
    "\n",
    "plt.xlabel('batch', fontsize=18)\n",
    "plt.ylabel('loss', fontsize=16)\n",
    "\n",
    "# plt.xlim(0, 2000)\n",
    "# plt.ylim(0, 2)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan.critic.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for l in self.critic.layers:\n",
    "        \n",
    "    weights = l.get_weights()\n",
    "    if 'batch_normalization' in l.get_config()['name']:\n",
    "        weights = [np.clip(w, -0.01, 0.01) for w in weights[:2]] + weights[2:]\n",
    "    else:\n",
    "        weights = [np.clip(w, -0.01, 0.01) for w in weights]\n",
    "\n",
    "    l.set_weights(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for l in gan.critic.layers:\n",
    "    print(l.get_config()['name'])\n",
    "    if 'batch_normalization' in l.get_config()['name']:\n",
    "        weights = l.get_weights()\n",
    "        print(l.get_weights()[0])\n",
    "        print(l.get_weights()[1])\n",
    "        print(l.get_weights()[2])\n",
    "        print(l.get_weights()[3])\n",
    "#         weights = [np.clip(w, -0.01, 0.01) for w in weights[:2]] + weights[2:]\n",
    "#         l.set_weights(weights)\n",
    "#         print('-----')\n",
    "#         print(l.get_weights()[0])\n",
    "#         print(l.get_weights()[1])\n",
    "#         print(l.get_weights()[2])\n",
    "#         print(l.get_weights()[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gdl",
   "language": "python",
   "name": "gdl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
