{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WGAN Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from models.WGAN import WGAN\n",
    "from utils.loaders import load_safari, load_cifar\n",
    "from keras.preprocessing.image import ImageDataGenerator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "RUN_ID = '0036'\n",
    "RUN_FOLDER = os.path.join(\"./run\", RUN_ID)\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "IMAGE_SIZE = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = 15\n",
    "(x_train, y_train) = load_cifar(label,100)\n",
    "# (x_train, y_train) = load_safari('elephant')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x117a297f0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4wLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvqOYd8AAAHehJREFUeJztnWuMpGeV3/+n7n2dW8+lPR57xsZrbNhdg0YOK9CGZbUbB21kkFYWKEL+gHZW0SIFafPBIlIgUj6wUQDxISIagrXeiHDZBYSVoGQdh8haJTKMiW/YwdjGlxnm5rl3V9ftfU8+VDkZt5//6Zrp6Wrbz/8njab7OfW876mn3lNv1/Ovc465O4QQ+VHZbAeEEJuDgl+ITFHwC5EpCn4hMkXBL0SmKPiFyBQFvxCZouAXIlMU/EJkSm09k83sLgBfBVAF8O/d/YvR45utGZ+e3Z601WvclVqtmhx3L+mcRr1ObfUGP5dRC+Bl+tuQBRkHgE63T22DgvsffvMysJXEVpbBufiZwvWIuLovjl7tt03fIt9SjV6yYFqFLjKfZWROe/k8up32WC/bVQe/mVUB/FsAfwDgKICfmtmD7v4MmzM9ux0f+UefTdr27NxBz7Vj29bk+KDfoXP27dtJbXsXF6itZnxJOsvp811s9+ic5145TW2nz16ktqI/4LYBt3V76TebdrfLjxe8eVWiqzZ6E6LH5HPcC24Df/OKj5ket6sIrKGNGwf9wP9grVp1cnMDv64azbQf//0/H6ZzVrOeP/vvBPC8u7/o7j0A3wZw9zqOJ4SYIOsJ/r0AXr3s96OjMSHE24AN3/Azs0NmdsTMjnQ7yxt9OiHEmKwn+I8B2HfZ79ePxt6Aux9294PufrDZmlnH6YQQ15L1BP9PAdxiZgfMrAHgEwAevDZuCSE2mqve7Xf3gZl9BsB/xVDqu9/dfx7NqVer2LVtW9K2dw/f7V/cnbYNCr6DPTsbyHnGVYJ6vUltvXp6x7YT7cx7eicXAGqNWWqrOD8mnO8Co9pOH68e7ZZzWyVwwwKVoAxlgjQe3ouuUhblJ6NUjfthwfNqNrmPRZ9fqzfs2Z0+Xotfw9PTjeT4/3q4ReesZl06v7v/CMCP1nMMIcTmoG/4CZEpCn4hMkXBL0SmKPiFyBQFvxCZsq7d/ivF3dHvpWWqXmeFzltpLyXH+4HE5kVaCgGAlSX+TcNq8H5Yq08nxwdBdmFRch/rFS4DllUuKVUr/LkNkD5fGUhlRZBQU+EpZ0Ak9QVZhAyL1iNYx2D5wTS9SvA6V4Ln1WjxeTt2zFNbr8uv761b55Ljc7P8S3GDIp3AZYFMuRrd+YXIFAW/EJmi4BciUxT8QmSKgl+ITJnobn8JR6dI7ywvrfBad9Pt9E7vgJSsAoBmkKAzzENKMxjwnd56Lf1euWMr35Xt9vjxLpzjZbwGVZ68M3D+nk13vgv+nAvnl0FpwVZ6kOTCkm2iMljBZj/KMvCfXFMRFkgE00H9xz17dlFbs8VVmPPnzlHbCqnz2O7wORcuXEiO94ialkJ3fiEyRcEvRKYo+IXIFAW/EJmi4BciUxT8QmTKRKU+mKFST5+y0+fSy8XltNS3bZbLeS3S0QQAakGySjVo5VVhspdzyXFxJ6/TVx2cp7aiwRNZdl13gNpOn0nX8Dv667N0zqDg94Bunz+3fsF97JGuQvOzfD0WFtL1HQHg18ffVBj6/7HS4TUZmRg53eDPed8i7/Y0FVSgXl7myTvLy7yGX0m8bAfPq9tJS3pRC7jV6M4vRKYo+IXIFAW/EJmi4BciUxT8QmSKgl+ITFmX1GdmLwG4BKAAMHD3g+HJKhVsnU23E6oEb0P9flryaATZV3PT3GYW1J4b8AyxXi8t5ZSknhoAbCOtxgBg1vjy/+TH/4Pabr2ZH3PuxhuS41vmttA5M9NT1Hbs+Alqe+HYa9RmZTrDbW6Gn+um63jGXBHUwPv1a1wyLUn23s6g3t7unVzqu3CB13987QzPwuv0gr5ntbT0XAYZkNYgMvcV1PC7Fjr/77k7vwqEEG9J9Ge/EJmy3uB3AH9rZo+Z2aFr4ZAQYjKs98/+D7n7MTPbBeAhM/s/7v7I5Q8YvSkcAoC5ef5ZVQgxWdZ153f3Y6P/TwH4AYA7E4857O4H3f3g1HS6OYEQYvJcdfCb2YyZzb3+M4A/BPD0tXJMCLGxrOfP/t0AfjAqyFgD8B/d/b9EE1rNBm57141JW1kGEls3ncEUFc6MMveizKc+yUYDgGo1fczpaZ6pNj/DbT7g773t089Q2ys/51LUTbf/g+T49mle2HE2sG3ZzyXCSpAZ96sTl9KGoPvXSpsXNK1U+PVRJVIZAMw009Ly9BSXgmuB7jw1xTNJa0E0bd/OpUUmPa+Q6x4ALrXT8nckma/mqoPf3V8E8NtXO18IsblI6hMiUxT8QmSKgl+ITFHwC5EpCn4hMmWiBTyrFcOW6fQpPXClOp/OBGsFUtPSpXQvMwAoy/GLHL7Bj1q6X1wkD144zeWr3tlT1Fb00oU4AeDEM49R2wzSklh9lve6a8ztpbb5XTdT203XcRlzpZfO6usP+OvcJtmbANBscf/37eXfHJ1qkuzC4Hj1Or8+uuf5dTU/n5YVAWDbtu3U1l5aSo6/doYXXe1Z+nUOlNQ3oTu/EJmi4BciUxT8QmSKgl+ITFHwC5Epk23XhRJeXHk9Ppa40Vnh9dT6QZupaLe/EmRGdEmtvmovSDoxvtt/6fSr1FZzntRRXzlNbXYhnVhZcb4PvNw+Q21nz/AafhfKKKHp+uT49M5FOmcmSJCam+GKRLvNW2G5p1/PVotfb8vLfJe9wadh+zaeaFaW3MdGJZ3Ys3/fdXTOqdNpH+tRdtEqdOcXIlMU/EJkioJfiExR8AuRKQp+ITJFwS9EpkxU6ivLEu12Wp6rzvHKvlXyHuXO227VA+mwKLg0h+CYtUp6uaolT0hplVw2Onf+RWpbucjlt9t+413UNtdIy5jlgPv4/EtPUNtD//MlauuUfI3v+eQ/To4f2Mvn9Ae83ZUtpRN0AKA8xyXf2vRCcrxS30bn1Gv8nri4Zze1dXpcXu4GtrI1nfajwROFllfS0mEkVb/psWM/UgjxjkLBL0SmKPiFyBQFvxCZouAXIlMU/EJkyppSn5ndD+CPAJxy9/eOxrYD+A6A/QBeAnCPu3OdZkRZOtrdtETRHXApZG4u3eqoVefuD4KsvkgijJhqpbO2rENaUwGodl6gtgN7eKZd59YD1LZjN5epik76mDVSyw4AGmmlCQDQ7vFstJrxNa5ceC457ie45Fip8Lp6nQF/zSo9Lh+ePJOWy2Z23kbn1Kd45iGqgVTZ5bUcO51ABuymbRdPvEbntDvprM8iaEW3mnHu/H8J4K5VY/cBeNjdbwHw8Oh3IcTbiDWD390fAbD6myp3A3hg9PMDAD52jf0SQmwwV/uZf7e7Hx/9fALDjr1CiLcR697w8+EHaPqBzMwOmdkRMzuytMSr2gghJsvVBv9JM1sEgNH/tPuEux9294PufnB2lvcoF0JMlqsN/gcB3Dv6+V4AP7w27gghJsU4Ut+3AHwYwIKZHQXweQBfBPBdM/s0gJcB3DPOyRwAUyIGJc+0s/ZKcrxsBJlefV4AE84lmSgratBN+1HpcknG+yepbccW7v97bvsNauv1034AgE2npS0jrcYAYHfB/bhtfzorDgCmgmqWLUu3G+td4gVBm01+OW6dSrdsA4BOIBH+4tl0a7NXXvglnfOe3/ljaqtO8+2tghQLBYCi5FKl1dOvmdcCubpCAukK+nWtGfzu/kli+v3xTyOEeKuhb/gJkSkKfiEyRcEvRKYo+IXIFAW/EJky0QKe7kBRpCUPCySKLslgsiCDqRLIeV5yCaVe57LXynI6cXHl1PN0Tq3OZcAdjV3UNgiyHKuBHDk1nfa/GmSjzc4GPeb+3q3U1unwjL+dO7YkxwdBz8ByJciKG3B583zQq29xa7r/36/PnqdzVi7wwqo18BTIi0v8uRnpNwkAXSJLeyB/V7m6OTa68wuRKQp+ITJFwS9Epij4hcgUBb8QmaLgFyJTJir1mQG1GjtlVHgwLZNE8mCj3qS2dpdnWA2CPn69C6fTcy7wTLXBPJfsOl2eeRgVIK23eIYbiAxYb/GXutHgttvffTO1eSDbsV6JveB5FQO+9meXuNR3/Dzvh+hIr1Vznsubx1/5BbUt3rKf2mameMbfUied5QgAtTItVW6d4fJspZK+vutB9uabjjH2I4UQ7ygU/EJkioJfiExR8AuRKQp+ITJlwok9jj5JYpgKarSxnWMb8EQQVPhOaY0LAej3eOst76YTe+bqQf3BoDPYIGhBVZRc/egFiSxG6tnVmnwXuG7BPcC5H4MBtzXJ61kGO/rdLt8Rv3ieJ+JUq+kaeABwgazVsVeP0jkDTyclAcCO6z9EbdOz/MJy4897qkpUk+DaKcnrUq2MX8RPd34hMkXBL0SmKPiFyBQFvxCZouAXIlMU/EJkyjjtuu4H8EcATrn7e0djXwDwJwBez3T5nLv/aIxjoVpNn5In/ACtVlrKGXS55NXpB/XPaoGG0knLeQDQKtMJJDvnuYxW9rj00u9zP6aneK24V4+foTbWFipKqKkwqQlAr8Pl1Kg91Q2zO5Pj1uTPq2xzP86d58/5qWdepra9B/alDRbIchXuY63JZUUnCToAULMgUYtePkECGpFMLdIHVzHOnf8vAdyVGP+Ku98x+rdm4Ash3lqsGfzu/ggAnjMphHhbsp7P/J8xsyfN7H4z23bNPBJCTISrDf6vAbgZwB0AjgP4EnugmR0ysyNmdmR56eJVnk4Ica25quB395PuXrh7CeDrAO4MHnvY3Q+6+8GZ2fmr9VMIcY25quA3s8XLfv04gKevjTtCiEkxjtT3LQAfBrBgZkcBfB7Ah83sDgy1iJcA/Ok4JzMztFqk9hjJ3AOAAcneK4P3Lgv6GVWN187rXzhGbVuLtNzUqnCJZ1Dj7b/KQCprNPh6sDp9AHDiVHpvtiRt0oaH48fbuZPXpWvO8Oy3Y6fTGXrnglp8588H7bqqB6itto3X43v6+XT23tT0Vjrn1vd+kNrmt19HbYFyCy871NbtpSfWgmu4KNJr5Vcg9a0Z/O7+ycTwN8Y+gxDiLYm+4SdEpij4hcgUBb8QmaLgFyJTFPxCZMqEC3gCnV46G6k/4FKIkb5cNZIhCADVGs8Qu3TuJLV5O92SCwB2LqTlt0rQaSwqTDrd4tljCAo+zs/zb1M/99yTyfFfHT1F5yx1uDw0P/cKtVXq/Lk15nYkxxf2cslu9773cNueW6ntujt4ht7pUyTjz7ncu32BZAIC8CADshJk9bVa/D476Kev46hAauFpGTBqobYa3fmFyBQFvxCZouAXIlMU/EJkioJfiExR8AuRKRPv1dfrksKDxmWNej3tpjuXw5Yu8cpjZ15+ltpuaC5zPyztR1Hhyzg1xTPO6g3+3lsJjjk/w+WcFikweYY/LTQWbqG22sKN1LZrcT+1Ld787uT4zutvonOq4NJh0ePXRxlcBzt2p/2IBLEyaAE56AZ+lMFRPchaJe5HvRyDVo5jozu/EJmi4BciUxT8QmSKgl+ITFHwC5EpE93thwMVT29TVkjyDgAY2drs9Hk9uDOneS0+D1pyLezk7ZgM6fPVanwnN6zFF2wOW7CDXXe+db9ncVdy/I7WfjrnN38vValtyOx2noiDKk+oYZvzyx3etqpPlCAAqJX8PuXgW990xzw4nnlQdzGQAsogqcaD8xWeTmorSeu1oY2cZ/wSfrrzC5ErCn4hMkXBL0SmKPiFyBQFvxCZouAXIlPGade1D8BfAdiNYXuuw+7+VTPbDuA7APZj2LLrHnfnGtpocp+0E6oEule3l6631uteoHNOvfpLatvuvE7fTH2B2mpGfG9wyStqhVUE2RkW1IrrsEwQACuWrgt442/9fTqnMnsDtfVIzUUAsOI8tXmZnjcTaFH9Cn/OvbA0XeBjlbS1ChJjotZaBXleADAI5NkoEccHJHEtSO4qyQE9kMxXM86dfwDgz939dgAfAPBnZnY7gPsAPOzutwB4ePS7EOJtwprB7+7H3f1no58vAXgWwF4AdwN4YPSwBwB8bKOcFEJce67oM7+Z7QfwPgCPAtjt7sdHphMYfiwQQrxNGDv4zWwWwPcAfNbdL15uc3cH0h/mzeyQmR0xsyPLyxdTDxFCbAJjBb+Z1TEM/G+6+/dHwyfNbHFkXwSQ7Arh7ofd/aC7H5yZmb8WPgshrgFrBr8N2+V8A8Cz7v7ly0wPArh39PO9AH547d0TQmwU42T1fRDApwA8ZWaPj8Y+B+CLAL5rZp8G8DKAe9Y+VAkjGUwWZEQN+mmpr1w5Q+fM4RK1TVub2qrGs85Kkj1WCeQrD2yRKDMo+LzzHT6zaKbbZG3ZxrdkeoF0WARSZdWCGoREqiyLoEBekW5BBQDVICsuvoexYwZ+BNcAglqTHr2ileA6qKavb4+y+si1aERKT7Fm8Lv734Ffp78/9pmEEG8p9A0/ITJFwS9Epij4hcgUBb8QmaLgFyJTJlrAs+I9THdfSdsCSalB5KFjJ3jmHpZPUNN1N6Qz3wCgUuNyTZ+oPPUKl6gsyLJimVlDG5dsOm0uUy3Mp79INeNLdI6vvMxtdd5CqwzuHSVJmysLLis2AoWtHkifRRlMJJKYF10+Y5CW3gCgXuUhMwiugzLIPMQgLUv3ejy7kCl6lSAj8U2PHfuRQoh3FAp+ITJFwS9Epij4hcgUBb8QmaLgFyJTJir12aCN2pknkrZI6gOTh84fT48D2MYVKmyZ4f3ziiALr1pP93CbmuK93Wo1Lv8UgexV9IOecEu8cGmzejJ9vGM8kzHKSqwHWWwWZPUVJEuzHz3nAe+9COPrUQSFM53YykGwvoGs6IHU14kyU6Nku25aqux2uOTIKLo8m3U1uvMLkSkKfiEyRcEvRKYo+IXIFAW/EJky2d1+L1AfnE3bgp3jkrTrQo/X8Nt5/fXU1priu/1W4bY62e23oD5b1JKLJQoBwMXlYOe7DBJPivT6Vrq8k5qXfOc7qiMXvWbM0giUhUER1E8M2mRFG+lOPPFAdagE6gH6XL2pB/fSQVAnEaQlWi1QHei1E6zTanTnFyJTFPxCZIqCX4hMUfALkSkKfiEyRcEvRKasKfWZ2T4Af4VhC24HcNjdv2pmXwDwJwBOjx76OXf/UXwwAFUivTiXUFZWiK5hXAqZn+WZPdUKT8CwqL2WpX3seyBTlvxc3ZI/57OXeC02b7SordJIy5EswQUALEhW8eC5DQKpklGGrc2CNmSB/5FkynyMJMxq0FKsEgmL0XUVtPIqiKmIct3YOkY94FYxjs4/APDn7v4zM5sD8JiZPTSyfcXd/834pxNCvFUYp1ffcQDHRz9fMrNnAezdaMeEEBvLFX3mN7P9AN4H4NHR0GfM7Ekzu9/Mtl1j34QQG8jYwW9mswC+B+Cz7n4RwNcA3AzgDgz/MvgSmXfIzI6Y2ZGllai+uhBikowV/GZWxzDwv+nu3wcAdz/p7oW7lwC+DuDO1Fx3P+zuB9394GzwnXohxGRZM/ht2HLmGwCedfcvXza+eNnDPg7g6WvvnhBioxhnt/+DAD4F4Ckze3w09jkAnzSzOzCU/14C8KdrHah0R7uXllHay7x90quvpFtvtab5e9f0FJfDWk0+L5IBmaka6CseZPV5kOnVXeFZfXPNoAYhqU0XSX31Opccu12eQRi1FGs2m8nxqFajB/UOa9G8IPvN6P2Nr6EX3NZv8+s0kiMjGRD1dBgOSKwAwAqRIyMpdTXj7Pb/HdLqYazpCyHe0ugbfkJkioJfiExR8AuRKQp+ITJFwS9Epky0gOdgUOD0mXSrqVMneTHO9kpablrYtZgcB4BWIyjEGTzrSpVLMlWS0VV1LudVatyP5QHP3EOQWdascxmzUU+/n1sglQ2/ykFsrUBiC7LwOp30c2MS4NAPfq56g8uA3ucS26WL6fZV/UCmrDe4j9Uab80WqXllkIEK4kulFqwHybaMXss3HX/sRwoh3lEo+IXIFAW/EJmi4BciUxT8QmSKgl+ITJmo1FcWJZYvtZO26SkuoczPpaWtHQtzdA6pEwogLsLYrHNprqymfbzQ58tYqXLZ6FLQm86ndlBbvzlNbYWlZUerBNmFgVRZBtJWEWTTLZHCpdblUlSvwzPmtmzjr/WAq4D41enTyfEzZ9LjALB7+zy13bT3OmqrBD0b3YN+iCQTrx7IsxWS2RllTb7psWM/UgjxjkLBL0SmKPiFyBQFvxCZouAXIlMU/EJkykSlPoOhTjK3bvvNW+i8fn85OR4Vx6wE2U3NIOOv1eTS1kVP9/97rcuz7IpAh+oF2Xm1XQvU1g2kLSCd4VYLshWj/m5FyS+RbpdLlc35G5LjgwGfMxUVT20FvReD7MJ9M8SPXzyeHAeAKUvL0UDc13Aw4FLloOSZh06WJCqQ2u2TAp7BnNXozi9Epij4hcgUBb8QmaLgFyJTFPxCZMqau/1m1gLwCIDm6PF/4+6fN7MDAL4NYAeAxwB8yt15bycAjWYNNx7YlbRtmee77GU//R5Vb/A5VuVb4h2SdAKAbZYPITvmjRpfxr5zZaG9klYxAKAStH7ykj+3Kml5Vfa5MmLBLntR8JfUEKktaT+qQS27qNXUSpuvVbS/XfbT/s81+Ws2Q3wHgG6ft1ErC/6aFYGt7KefwcVlXuPx6KlTyfGovdpqxrnzdwF8xN1/G8N23HeZ2QcA/AWAr7j7uwCcA/Dpsc8qhNh01gx+H7I0+rU++ucAPgLgb0bjDwD42IZ4KITYEMb6zG9m1VGH3lMAHgLwAoDz/v+TlI8C2LsxLgohNoKxgt/dC3e/A8D1AO4E8O5xT2Bmh8zsiJkdWVrh3+4SQkyWK9rtd/fzAH4M4HcAbDWz13dNrgdwjMw57O4H3f3g7BTf/BJCTJY1g9/MdprZ1tHPUwD+AMCzGL4J/PHoYfcC+OFGOSmEuPaMk9izCOABM6ti+GbxXXf/T2b2DIBvm9m/AvC/AXxjrQNVqhXMkHp8Uc29GmmfVAtaYYWyUS+onVfhx2w004kbc0FrrYvtwPbyr6itGhyzFkiLUVsueq5AFg1yZkJoikvUtSrIMLqS2nRvOB2R2HY0uPRWD66BMG0mapUV2EpSQ9GDs03PzCTHK1EgrWLN4Hf3JwG8LzH+Ioaf/4UQb0P0DT8hMkXBL0SmKPiFyBQFvxCZouAXIlOMtQrakJOZnQbw8ujXBQCvTezkHPnxRuTHG3m7+XGju+8c54ATDf43nNjsiLsf3JSTyw/5IT/0Z78QuaLgFyJTNjP4D2/iuS9HfrwR+fFG3rF+bNpnfiHE5qI/+4XIlE0JfjO7y8x+YWbPm9l9m+HDyI+XzOwpM3vczI5M8Lz3m9kpM3v6srHtZvaQmf1y9P+2TfLjC2Z2bLQmj5vZRyfgxz4z+7GZPWNmPzezfzoan+iaBH5MdE3MrGVmPzGzJ0Z+/MvR+AEze3QUN98xM17BdhzcfaL/AFQxLAN2E4AGgCcA3D5pP0a+vARgYRPO+7sA3g/g6cvG/jWA+0Y/3wfgLzbJjy8A+GcTXo9FAO8f/TwH4DkAt096TQI/JromGHZPnB39XAfwKIAPAPgugE+Mxv8dgH+ynvNsxp3/TgDPu/uLPiz1/W0Ad2+CH5uGuz8C4Oyq4bsxLIQKTKggKvFj4rj7cXf/2ejnSxgWi9mLCa9J4MdE8SEbXjR3M4J/L4BXL/t9M4t/OoC/NbPHzOzQJvnwOrvd/fjo5xMAdm+iL58xsydHHws2/OPH5ZjZfgzrRzyKTVyTVX4AE16TSRTNzX3D70Pu/n4A/xDAn5nZ7262Q8DwnR9rFI3ZQL4G4GYMezQcB/ClSZ3YzGYBfA/AZ9394uW2Sa5Jwo+Jr4mvo2juuGxG8B8DsO+y32nxz43G3Y+N/j8F4AfY3MpEJ81sEQBG/6dbsmww7n5ydOGVAL6OCa2JmdUxDLhvuvv3R8MTX5OUH5u1JqNzX3HR3HHZjOD/KYBbRjuXDQCfAPDgpJ0wsxkzm3v9ZwB/CODpeNaG8iCGhVCBTSyI+nqwjfg4JrAmZmYY1oB81t2/fJlpomvC/Jj0mkysaO6kdjBX7WZ+FMOd1BcA/PNN8uEmDJWGJwD8fJJ+APgWhn8+9jH87PZpDHsePgzglwD+G4Dtm+THfwDwFIAnMQy+xQn48SEM/6R/EsDjo38fnfSaBH5MdE0A/BaGRXGfxPCN5l9cds3+BMDzAP4aQHM959E3/ITIlNw3/ITIFgW/EJmi4BciUxT8QmSKgl+ITFHwC5EpCn4hMkXBL0Sm/F+NIGnnzB+xawAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow((x_train[2,:,:,:]+1)*0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.0\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print(np.min(x_train))\n",
    "print(np.max(x_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(600, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# gan = WGAN(input_dim = (IMAGE_SIZE,IMAGE_SIZE,3)\n",
    "#         , critic_conv_filters = [64,128,256,512]\n",
    "#         , critic_conv_kernel_size = [5,5,5,5]\n",
    "#         , critic_conv_strides = [2,2,2,2]\n",
    "#         , critic_conv_padding = 'same'\n",
    "#         , critic_batch_norm_momentum = None #0.9\n",
    "#         , critic_activation = 'leaky_relu'\n",
    "#         , critic_dropout_rate = None\n",
    "#         , critic_learning_rate = 0.00005\n",
    "#         , generator_initial_dense_layer_size = (4, 4, 512)\n",
    "#         , generator_upsample =[1,1,1,1]\n",
    "#         , generator_conv_filters = [256,128, 64,3]\n",
    "#         , generator_conv_kernel_size = [3,3,3,3]\n",
    "#         , generator_conv_strides = [2,2,2,2]\n",
    "#         , generator_conv_padding = 'same'\n",
    "#         , generator_batch_norm_momentum = 0.9\n",
    "#         , generator_activation = 'relu'\n",
    "#         , generator_dropout_rate = None\n",
    "#         , generator_learning_rate = 0.00005\n",
    "#         , optimiser = 'rmsprop'\n",
    "#         , z_dim = 100\n",
    "#         )\n",
    "\n",
    "gan = WGAN(input_dim = (IMAGE_SIZE,IMAGE_SIZE,3)\n",
    "        , critic_conv_filters = [64,64,128,128]\n",
    "        , critic_conv_kernel_size = [5,5,5,5]\n",
    "        , critic_conv_strides = [2,2,2,1]\n",
    "        , critic_conv_padding = 'same'\n",
    "        , critic_batch_norm_momentum = None\n",
    "        , critic_activation = 'leaky_relu'\n",
    "        , critic_dropout_rate = None\n",
    "        , critic_learning_rate = 0.00005\n",
    "        , generator_initial_dense_layer_size = (8, 8, 64)\n",
    "        , generator_upsample = [2,2, 1, 1]\n",
    "        , generator_conv_filters = [128,64, 64,3]\n",
    "        , generator_conv_kernel_size = [5,5,5,5]\n",
    "        , generator_conv_strides = [1,1, 1, 1]\n",
    "        , generator_conv_padding = 'same'\n",
    "        , generator_batch_norm_momentum = 0.8\n",
    "        , generator_activation = 'relu'\n",
    "        , generator_dropout_rate = None\n",
    "        , generator_learning_rate = 0.00005\n",
    "        , optimiser = 'rmsprop'\n",
    "        , z_dim = 100\n",
    "        )\n",
    "\n",
    "gan.save(RUN_FOLDER)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gan.load_weights(os.path.join(RUN_FOLDER, 'weights/weights.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "critic_input (InputLayer)    (None, 32, 32, 3)         0         \n",
      "_________________________________________________________________\n",
      "critic_conv_0 (Conv2D)       (None, 16, 16, 64)        4864      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "critic_conv_1 (Conv2D)       (None, 8, 8, 64)          102464    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "critic_conv_2 (Conv2D)       (None, 4, 4, 128)         204928    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "critic_conv_3 (Conv2D)       (None, 4, 4, 128)         409728    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 2049      \n",
      "=================================================================\n",
      "Total params: 724,033\n",
      "Trainable params: 724,033\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "gan.critic.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "generator_input (InputLayer) (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 4096)              413696    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 4096)              16384     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)    (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2 (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "generator_conv_0 (Conv2DTran (None, 16, 16, 128)       204928    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 16, 16, 128)       512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)    (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2 (None, 32, 32, 128)       0         \n",
      "_________________________________________________________________\n",
      "generator_conv_1 (Conv2DTran (None, 32, 32, 64)        204864    \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 32, 32, 64)        256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)    (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "generator_conv_2 (Conv2DTran (None, 32, 32, 64)        102464    \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 32, 32, 64)        256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)    (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "generator_conv_3 (Conv2DTran (None, 32, 32, 3)         4803      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 32, 32, 3)         0         \n",
      "=================================================================\n",
      "Total params: 948,163\n",
      "Trainable params: 939,459\n",
      "Non-trainable params: 8,704\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "gan.generator.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/davidfoster/.virtualenvs/gdl/lib/python3.6/site-packages/keras/engine/training.py:490: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 (5, 1) [D loss: (-0.000)(R -0.001, F 0.000)]  [G loss: -0.001] \n",
      "1 (5, 1) [D loss: (-0.000)(R -0.001, F 0.001)]  [G loss: -0.000] \n",
      "2 (5, 1) [D loss: (-0.001)(R -0.002, F 0.001)]  [G loss: -0.000] \n",
      "3 (5, 1) [D loss: (-0.000)(R -0.002, F 0.002)]  [G loss: -0.000] \n",
      "4 (5, 1) [D loss: (-0.003)(R -0.004, F 0.001)]  [G loss: -0.001] \n",
      "5 (5, 1) [D loss: (-0.001)(R -0.004, F 0.004)]  [G loss: -0.002] \n",
      "6 (5, 1) [D loss: (-0.001)(R -0.005, F 0.004)]  [G loss: -0.004] \n",
      "7 (5, 1) [D loss: (-0.000)(R -0.006, F 0.006)]  [G loss: -0.004] \n",
      "8 (5, 1) [D loss: (-0.001)(R -0.006, F 0.005)]  [G loss: -0.004] \n",
      "9 (5, 1) [D loss: (-0.002)(R -0.006, F 0.004)]  [G loss: -0.010] \n",
      "10 (5, 1) [D loss: (0.001)(R -0.005, F 0.006)]  [G loss: -0.004] \n",
      "11 (5, 1) [D loss: (-0.001)(R -0.004, F 0.003)]  [G loss: -0.002] \n",
      "12 (5, 1) [D loss: (-0.001)(R -0.003, F 0.002)]  [G loss: -0.003] \n",
      "13 (5, 1) [D loss: (-0.001)(R -0.002, F 0.001)]  [G loss: 0.000] \n",
      "14 (5, 1) [D loss: (-0.002)(R -0.001, F -0.000)]  [G loss: 0.003] \n",
      "15 (5, 1) [D loss: (-0.002)(R -0.001, F -0.001)]  [G loss: 0.004] \n",
      "16 (5, 1) [D loss: (-0.001)(R 0.001, F -0.002)]  [G loss: 0.007] \n",
      "17 (5, 1) [D loss: (-0.008)(R -0.000, F -0.008)]  [G loss: 0.013] \n",
      "18 (5, 1) [D loss: (-0.001)(R 0.001, F -0.002)]  [G loss: 0.011] \n",
      "19 (5, 1) [D loss: (-0.047)(R -0.006, F -0.041)]  [G loss: 0.019] \n",
      "20 (5, 1) [D loss: (0.007)(R -0.000, F 0.008)]  [G loss: 0.007] \n",
      "21 (5, 1) [D loss: (-0.002)(R -0.000, F -0.001)]  [G loss: 0.007] \n",
      "22 (5, 1) [D loss: (-0.008)(R 0.004, F -0.012)]  [G loss: 0.004] \n",
      "23 (5, 1) [D loss: (0.004)(R 0.001, F 0.003)]  [G loss: 0.003] \n",
      "24 (5, 1) [D loss: (-0.004)(R -0.004, F -0.001)]  [G loss: -0.001] \n",
      "25 (5, 1) [D loss: (-0.002)(R -0.002, F 0.000)]  [G loss: -0.005] \n",
      "26 (5, 1) [D loss: (-0.000)(R -0.005, F 0.005)]  [G loss: -0.006] \n",
      "27 (5, 1) [D loss: (0.001)(R -0.005, F 0.005)]  [G loss: -0.006] \n",
      "28 (5, 1) [D loss: (-0.000)(R -0.005, F 0.005)]  [G loss: -0.006] \n",
      "29 (5, 1) [D loss: (-0.001)(R -0.005, F 0.004)]  [G loss: -0.003] \n",
      "30 (5, 1) [D loss: (-0.003)(R -0.006, F 0.003)]  [G loss: -0.001] \n",
      "31 (5, 1) [D loss: (-0.004)(R -0.007, F 0.003)]  [G loss: -0.001] \n",
      "32 (5, 1) [D loss: (-0.007)(R -0.007, F 0.000)]  [G loss: 0.003] \n",
      "33 (5, 1) [D loss: (-0.007)(R -0.010, F 0.003)]  [G loss: 0.002] \n",
      "34 (5, 1) [D loss: (-0.007)(R -0.008, F 0.002)]  [G loss: 0.005] \n",
      "35 (5, 1) [D loss: (-0.003)(R -0.007, F 0.004)]  [G loss: 0.005] \n",
      "36 (5, 1) [D loss: (-0.001)(R -0.004, F 0.003)]  [G loss: 0.005] \n",
      "37 (5, 1) [D loss: (-0.010)(R -0.007, F -0.003)]  [G loss: 0.007] \n",
      "38 (5, 1) [D loss: (0.001)(R -0.003, F 0.004)]  [G loss: 0.007] \n",
      "39 (5, 1) [D loss: (-0.003)(R -0.002, F -0.001)]  [G loss: 0.007] \n",
      "40 (5, 1) [D loss: (-0.014)(R -0.005, F -0.009)]  [G loss: 0.006] \n",
      "41 (5, 1) [D loss: (0.001)(R -0.003, F 0.004)]  [G loss: 0.003] \n",
      "42 (5, 1) [D loss: (0.003)(R 0.000, F 0.003)]  [G loss: 0.005] \n",
      "43 (5, 1) [D loss: (-0.003)(R -0.000, F -0.003)]  [G loss: 0.003] \n",
      "44 (5, 1) [D loss: (-0.001)(R -0.000, F -0.001)]  [G loss: 0.002] \n",
      "45 (5, 1) [D loss: (-0.000)(R -0.000, F 0.000)]  [G loss: 0.001] \n",
      "46 (5, 1) [D loss: (-0.002)(R 0.000, F -0.002)]  [G loss: 0.001] \n",
      "47 (5, 1) [D loss: (-0.007)(R -0.004, F -0.002)]  [G loss: -0.002] \n",
      "48 (5, 1) [D loss: (-0.000)(R -0.002, F 0.001)]  [G loss: 0.002] \n",
      "49 (5, 1) [D loss: (-0.001)(R -0.002, F 0.001)]  [G loss: 0.002] \n",
      "50 (5, 1) [D loss: (-0.002)(R -0.001, F -0.001)]  [G loss: 0.002] \n",
      "51 (5, 1) [D loss: (-0.002)(R 0.001, F -0.003)]  [G loss: 0.002] \n",
      "52 (5, 1) [D loss: (-0.001)(R 0.000, F -0.001)]  [G loss: 0.004] \n",
      "53 (5, 1) [D loss: (-0.003)(R -0.001, F -0.002)]  [G loss: 0.006] \n",
      "54 (5, 1) [D loss: (-0.001)(R 0.001, F -0.003)]  [G loss: 0.008] \n",
      "55 (5, 1) [D loss: (-0.008)(R 0.000, F -0.008)]  [G loss: 0.012] \n",
      "56 (5, 1) [D loss: (-0.003)(R 0.002, F -0.005)]  [G loss: 0.011] \n",
      "57 (5, 1) [D loss: (-0.007)(R -0.000, F -0.007)]  [G loss: 0.012] \n",
      "58 (5, 1) [D loss: (-0.011)(R 0.002, F -0.013)]  [G loss: 0.016] \n",
      "59 (5, 1) [D loss: (-0.001)(R 0.003, F -0.004)]  [G loss: 0.014] \n",
      "60 (5, 1) [D loss: (-0.017)(R 0.001, F -0.018)]  [G loss: 0.014] \n",
      "61 (5, 1) [D loss: (0.001)(R 0.004, F -0.003)]  [G loss: 0.009] \n",
      "62 (5, 1) [D loss: (0.001)(R 0.003, F -0.001)]  [G loss: 0.009] \n",
      "63 (5, 1) [D loss: (-0.001)(R 0.003, F -0.003)]  [G loss: 0.006] \n",
      "64 (5, 1) [D loss: (-0.003)(R 0.000, F -0.003)]  [G loss: 0.004] \n",
      "65 (5, 1) [D loss: (-0.003)(R 0.002, F -0.004)]  [G loss: 0.003] \n",
      "66 (5, 1) [D loss: (0.001)(R -0.000, F 0.001)]  [G loss: 0.006] \n",
      "67 (5, 1) [D loss: (-0.004)(R -0.002, F -0.003)]  [G loss: 0.006] \n",
      "68 (5, 1) [D loss: (-0.006)(R 0.000, F -0.006)]  [G loss: 0.006] \n",
      "69 (5, 1) [D loss: (-0.004)(R 0.001, F -0.004)]  [G loss: 0.010] \n",
      "70 (5, 1) [D loss: (-0.004)(R 0.001, F -0.005)]  [G loss: 0.009] \n",
      "71 (5, 1) [D loss: (-0.005)(R 0.002, F -0.006)]  [G loss: 0.010] \n",
      "72 (5, 1) [D loss: (-0.005)(R 0.002, F -0.007)]  [G loss: 0.012] \n",
      "73 (5, 1) [D loss: (-0.007)(R 0.003, F -0.010)]  [G loss: 0.016] \n",
      "74 (5, 1) [D loss: (-0.007)(R 0.004, F -0.010)]  [G loss: 0.016] \n",
      "75 (5, 1) [D loss: (-0.008)(R 0.005, F -0.013)]  [G loss: 0.020] \n",
      "76 (5, 1) [D loss: (-0.005)(R 0.007, F -0.012)]  [G loss: 0.020] \n",
      "77 (5, 1) [D loss: (-0.008)(R 0.006, F -0.015)]  [G loss: 0.022] \n",
      "78 (5, 1) [D loss: (-0.012)(R 0.007, F -0.019)]  [G loss: 0.025] \n",
      "79 (5, 1) [D loss: (-0.008)(R 0.007, F -0.015)]  [G loss: 0.024] \n",
      "80 (5, 1) [D loss: (-0.022)(R 0.005, F -0.027)]  [G loss: 0.024] \n",
      "81 (5, 1) [D loss: (-0.009)(R 0.004, F -0.013)]  [G loss: 0.026] \n",
      "82 (5, 1) [D loss: (-0.013)(R 0.007, F -0.020)]  [G loss: 0.026] \n",
      "83 (5, 1) [D loss: (-0.017)(R 0.004, F -0.021)]  [G loss: 0.027] \n",
      "84 (5, 1) [D loss: (-0.015)(R 0.010, F -0.026)]  [G loss: 0.022] \n",
      "85 (5, 1) [D loss: (-0.014)(R 0.005, F -0.019)]  [G loss: 0.030] \n",
      "86 (5, 1) [D loss: (-0.024)(R 0.007, F -0.031)]  [G loss: 0.020] \n",
      "87 (5, 1) [D loss: (-0.012)(R 0.006, F -0.018)]  [G loss: 0.029] \n",
      "88 (5, 1) [D loss: (-0.007)(R 0.007, F -0.014)]  [G loss: 0.021] \n",
      "89 (5, 1) [D loss: (-0.016)(R -0.000, F -0.016)]  [G loss: 0.016] \n",
      "90 (5, 1) [D loss: (-0.013)(R 0.001, F -0.014)]  [G loss: 0.032] \n",
      "91 (5, 1) [D loss: (-0.019)(R 0.008, F -0.027)]  [G loss: 0.027] \n",
      "92 (5, 1) [D loss: (-0.009)(R 0.006, F -0.014)]  [G loss: 0.029] \n",
      "93 (5, 1) [D loss: (-0.020)(R 0.004, F -0.023)]  [G loss: 0.040] \n",
      "94 (5, 1) [D loss: (-0.017)(R 0.007, F -0.024)]  [G loss: 0.034] \n",
      "95 (5, 1) [D loss: (-0.028)(R 0.012, F -0.040)]  [G loss: 0.050] \n",
      "96 (5, 1) [D loss: (-0.009)(R 0.014, F -0.023)]  [G loss: 0.045] \n",
      "97 (5, 1) [D loss: (-0.019)(R 0.015, F -0.034)]  [G loss: 0.053] \n",
      "98 (5, 1) [D loss: (-0.022)(R 0.019, F -0.042)]  [G loss: 0.061] \n",
      "99 (5, 1) [D loss: (-0.019)(R 0.026, F -0.045)]  [G loss: 0.062] \n",
      "100 (5, 1) [D loss: (-0.030)(R 0.024, F -0.053)]  [G loss: 0.069] \n",
      "101 (5, 1) [D loss: (-0.031)(R 0.020, F -0.051)]  [G loss: 0.064] \n",
      "102 (5, 1) [D loss: (-0.025)(R 0.029, F -0.054)]  [G loss: 0.070] \n",
      "103 (5, 1) [D loss: (-0.023)(R 0.030, F -0.053)]  [G loss: 0.070] \n",
      "104 (5, 1) [D loss: (-0.025)(R 0.028, F -0.053)]  [G loss: 0.064] \n",
      "105 (5, 1) [D loss: (-0.033)(R 0.023, F -0.056)]  [G loss: 0.069] \n",
      "106 (5, 1) [D loss: (-0.013)(R 0.024, F -0.037)]  [G loss: 0.063] \n",
      "107 (5, 1) [D loss: (-0.014)(R 0.024, F -0.038)]  [G loss: 0.059] \n",
      "108 (5, 1) [D loss: (-0.017)(R 0.021, F -0.038)]  [G loss: 0.058] \n",
      "109 (5, 1) [D loss: (-0.008)(R 0.023, F -0.031)]  [G loss: 0.053] \n",
      "110 (5, 1) [D loss: (-0.019)(R 0.023, F -0.042)]  [G loss: 0.050] \n",
      "111 (5, 1) [D loss: (-0.022)(R 0.011, F -0.033)]  [G loss: 0.053] \n",
      "112 (5, 1) [D loss: (-0.029)(R 0.013, F -0.042)]  [G loss: 0.049] \n",
      "113 (5, 1) [D loss: (-0.010)(R 0.012, F -0.022)]  [G loss: 0.044] \n",
      "114 (5, 1) [D loss: (-0.016)(R 0.007, F -0.023)]  [G loss: 0.042] \n",
      "115 (5, 1) [D loss: (-0.013)(R 0.004, F -0.018)]  [G loss: 0.041] \n",
      "116 (5, 1) [D loss: (-0.015)(R 0.005, F -0.021)]  [G loss: 0.043] \n",
      "117 (5, 1) [D loss: (-0.013)(R 0.004, F -0.018)]  [G loss: 0.036] \n",
      "118 (5, 1) [D loss: (-0.009)(R 0.007, F -0.015)]  [G loss: 0.038] \n",
      "119 (5, 1) [D loss: (-0.024)(R 0.002, F -0.026)]  [G loss: 0.036] \n",
      "120 (5, 1) [D loss: (-0.027)(R 0.007, F -0.034)]  [G loss: 0.040] \n",
      "121 (5, 1) [D loss: (-0.022)(R 0.004, F -0.027)]  [G loss: 0.036] \n",
      "122 (5, 1) [D loss: (-0.005)(R -0.000, F -0.005)]  [G loss: 0.033] \n",
      "123 (5, 1) [D loss: (-0.011)(R 0.008, F -0.019)]  [G loss: 0.038] \n"
     ]
    }
   ],
   "source": [
    "gan.train(     \n",
    "    x_train\n",
    "    , batch_size = 128\n",
    "    , epochs = 20000\n",
    "    , run_folder = RUN_FOLDER\n",
    "    , print_every_n_batches = 5\n",
    "    , n_critic = 5\n",
    "    , large_it_critic = 10\n",
    "    , large_n_critic = 5\n",
    "    , clip_threshold = 0.01\n",
    "    , using_generator = False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check = True\n",
    "while check :\n",
    "    \n",
    "    for _ in range(5):\n",
    "\n",
    "        valid = np.ones((BATCH_SIZE,1), dtype=np.float32)\n",
    "        fake = -np.ones((BATCH_SIZE,1), dtype=np.float32)\n",
    "\n",
    "        idx = np.random.randint(0, x_train.shape[0], BATCH_SIZE)\n",
    "        true_imgs = x_train[idx]\n",
    "\n",
    "        noise = np.random.normal(0, 1, (BATCH_SIZE, gan.z_dim))\n",
    "        gen_imgs = gan.generator.predict(noise)\n",
    "\n",
    "        d_loss_real =   gan.critic.train_on_batch(true_imgs, valid)\n",
    "        d_loss_fake =   gan.critic.train_on_batch(gen_imgs, fake)\n",
    "        d_loss = (d_loss_real + d_loss_fake)\n",
    "\n",
    "    for l in gan.critic.layers:\n",
    "        weights = l.get_weights()\n",
    "        weights = [np.clip(w, -0.01, 0.01) for w in weights]\n",
    "        l.set_weights(weights)\n",
    "\n",
    "    # Plot the progress\n",
    "    print (\"[D loss: (%.3f)(R %.3f, F %.3f)]\" % (d_loss, d_loss_real, d_loss_fake))\n",
    "    \n",
    "      \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check = True\n",
    "while check:\n",
    "    valid = np.ones((BATCH_SIZE,1), dtype=np.float32)\n",
    "    fake = -np.ones((BATCH_SIZE,1), dtype=np.float32)\n",
    "    noise = np.random.normal(0, 1, (BATCH_SIZE,100))\n",
    "\n",
    "    idx = np.random.randint(0, x_train.shape[0], BATCH_SIZE)\n",
    "    true_imgs = x_train[idx]\n",
    "    \n",
    "#     g_loss = gan.train_generator(batch_size = BATCH_SIZE)\n",
    "    g_loss = gan.model.train_on_batch(noise, valid)\n",
    "    # Plot the progress\n",
    "    print (\"[G loss: %.3f]\" % (g_loss))\n",
    "    \n",
    "    g_loss = gan.model.test_on_batch(noise, valid)\n",
    "    print (\"[G loss: %.3f]\" % (g_loss))\n",
    "    print('-------')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = np.random.normal(0, 1, (BATCH_SIZE,100))\n",
    "img = gan.generator.predict(np.array([noise[0]]))[0]\n",
    "\n",
    "plt.imshow(np.clip((img+1)*0.5,0,1))\n",
    "\n",
    "gan.critic.predict(np.array([img]))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.random.randint(0, x_train.shape[0], 1)[0]\n",
    "img = x_train[idx]\n",
    "print(gan.critic.predict(np.array([img]))[0])\n",
    "plt.imshow((img + 1) * 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot([x[0] for x in gan.d_losses], color='black', linewidth=1)\n",
    "\n",
    "plt.plot([x[1] for x in gan.d_losses], color='green', linewidth=0.5)\n",
    "plt.plot([x[2] for x in gan.d_losses], color='red', linewidth=0.5)\n",
    "\n",
    "plt.plot(gan.g_losses, color='orange', linewidth=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gan.model.to_json(indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[x[0] for x in gan.d_losses][:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan.g_losses[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan.critic.get_weights()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gdl",
   "language": "python",
   "name": "gdl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
