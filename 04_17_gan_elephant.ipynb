{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GAN Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from models.GAN import GAN\n",
    "from utils.loaders import load_safari"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "RUN_ID = '0017'\n",
    "RUN_FOLDER = os.path.join(\"./run\", RUN_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train) = load_safari('elephant')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80000, 28, 28, 1)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x14302b860>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_train[0,:,:,0], cmap = 'gray_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(x_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# works\n",
    "\n",
    "gan = GAN(input_dim = (28,28,1)\n",
    "        , discriminator_conv_filters = [64,64,128,128]\n",
    "        , discriminator_conv_kernel_size = [5,5,5,5]\n",
    "        , discriminator_conv_strides = [2,2,2,1]\n",
    "        , discriminator_conv_padding = 'same'\n",
    "        , discriminator_batch_norm_momentum = None\n",
    "        , discriminator_activation = 'relu'\n",
    "        , discriminator_dropout_rate = 0.4\n",
    "        , discriminator_learning_rate = 0.0008 \n",
    "        , generator_initial_dense_layer_size = (7, 7, 64)\n",
    "        , generator_use_upsampling = [True,True, False,False]\n",
    "        , generator_conv_t_filters = [128,64, 64,1]\n",
    "        , generator_conv_t_kernel_size = [5,5,5,5]\n",
    "        , generator_conv_t_strides = [1,1,1,1]\n",
    "        , generator_conv_t_padding = 'same'\n",
    "        , generator_batch_norm_momentum = 0.9\n",
    "        , generator_activation = 'relu'\n",
    "        , generator_dropout_rate = None\n",
    "        , generator_learning_rate = 0.0004 \n",
    "        , optimiser = 'rmsprop'\n",
    "        , z_dim = 100\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "gan.save(RUN_FOLDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gan.load_weights(os.path.join(RUN_FOLDER, 'weights/weights.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "discriminator_input (InputLa (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "discriminator_conv_0 (Conv2D (None, 14, 14, 64)        1664      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)    (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "discriminator_conv_1 (Conv2D (None, 7, 7, 64)          102464    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)    (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "discriminator_conv_2 (Conv2D (None, 4, 4, 128)         204928    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)    (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "discriminator_conv_3 (Conv2D (None, 4, 4, 128)         409728    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)    (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 2049      \n",
      "=================================================================\n",
      "Total params: 1,441,666\n",
      "Trainable params: 720,833\n",
      "Non-trainable params: 720,833\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/davidfoster/.virtualenvs/gdl/lib/python3.6/site-packages/keras/engine/training.py:490: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n"
     ]
    }
   ],
   "source": [
    "gan.discriminator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "generator_input (InputLayer) (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 3136)              316736    \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 3136)              12544     \n",
      "_________________________________________________________________\n",
      "activation_24 (Activation)   (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "reshape_4 (Reshape)          (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "generator_conv_t_0 (Conv2DTr (None, 14, 14, 128)       204928    \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 14, 14, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_25 (Activation)   (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "generator_conv_t_1 (Conv2DTr (None, 28, 28, 64)        204864    \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 28, 28, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_26 (Activation)   (None, 28, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "generator_conv_t_2 (Conv2DTr (None, 28, 28, 64)        102464    \n",
      "_________________________________________________________________\n",
      "batch_normalization_16 (Batc (None, 28, 28, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_27 (Activation)   (None, 28, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "generator_conv_t_3 (Conv2DTr (None, 28, 28, 1)         1601      \n",
      "_________________________________________________________________\n",
      "activation_28 (Activation)   (None, 28, 28, 1)         0         \n",
      "=================================================================\n",
      "Total params: 844,161\n",
      "Trainable params: 837,377\n",
      "Non-trainable params: 6,784\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "gan.generator.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [D loss: 0.692726] [D acc: 0.574219] [G loss: 0.099604] [G acc: 1.000000]\n",
      "1 [D loss: 2.157887] [D acc: 0.500000] [G loss: 1.133151] [G acc: 0.000000]\n",
      "2 [D loss: 0.786640] [D acc: 0.500000] [G loss: 0.890125] [G acc: 0.000000]\n",
      "3 [D loss: 0.628010] [D acc: 0.679688] [G loss: 1.560783] [G acc: 0.000000]\n",
      "4 [D loss: 0.428830] [D acc: 0.898438] [G loss: 2.842371] [G acc: 0.000000]\n",
      "5 [D loss: 0.133066] [D acc: 1.000000] [G loss: 11.274679] [G acc: 0.000000]\n",
      "6 [D loss: 0.493525] [D acc: 0.765625] [G loss: 0.050605] [G acc: 1.000000]\n",
      "7 [D loss: 2.554204] [D acc: 0.500000] [G loss: 1.963197] [G acc: 0.000000]\n",
      "8 [D loss: 0.397054] [D acc: 0.996094] [G loss: 1.520084] [G acc: 0.000000]\n",
      "9 [D loss: 0.248331] [D acc: 1.000000] [G loss: 2.656789] [G acc: 0.000000]\n",
      "10 [D loss: 0.142357] [D acc: 0.992188] [G loss: 3.796268] [G acc: 0.000000]\n",
      "11 [D loss: 0.344039] [D acc: 0.972656] [G loss: 15.298037] [G acc: 0.000000]\n",
      "12 [D loss: 0.724090] [D acc: 0.679688] [G loss: 2.359208] [G acc: 0.000000]\n",
      "13 [D loss: 0.096846] [D acc: 0.984375] [G loss: 4.118361] [G acc: 0.000000]\n",
      "14 [D loss: 0.058615] [D acc: 0.984375] [G loss: 3.820576] [G acc: 0.000000]\n",
      "15 [D loss: 0.032927] [D acc: 0.996094] [G loss: 3.932697] [G acc: 0.000000]\n",
      "16 [D loss: 0.044577] [D acc: 0.992188] [G loss: 2.648135] [G acc: 0.000000]\n",
      "17 [D loss: 0.406947] [D acc: 0.617188] [G loss: 6.078020] [G acc: 0.000000]\n",
      "18 [D loss: 0.543654] [D acc: 0.519531] [G loss: 3.352267] [G acc: 0.000000]\n",
      "19 [D loss: 0.126149] [D acc: 0.949219] [G loss: 1.202016] [G acc: 0.210938]\n",
      "20 [D loss: 0.276342] [D acc: 0.960938] [G loss: 3.702338] [G acc: 0.000000]\n",
      "21 [D loss: 0.201949] [D acc: 0.917969] [G loss: 0.596315] [G acc: 0.789062]\n",
      "22 [D loss: 0.065891] [D acc: 0.972656] [G loss: 0.262178] [G acc: 0.984375]\n",
      "23 [D loss: 0.036487] [D acc: 0.996094] [G loss: 0.156763] [G acc: 0.976562]\n",
      "24 [D loss: 0.114049] [D acc: 0.980469] [G loss: 1.731264] [G acc: 0.195312]\n",
      "25 [D loss: 0.305765] [D acc: 0.925781] [G loss: 6.269343] [G acc: 0.000000]\n",
      "26 [D loss: 0.087503] [D acc: 0.972656] [G loss: 4.588899] [G acc: 0.000000]\n",
      "27 [D loss: 0.060393] [D acc: 0.988281] [G loss: 4.106515] [G acc: 0.000000]\n",
      "28 [D loss: 0.019434] [D acc: 0.996094] [G loss: 4.529356] [G acc: 0.000000]\n",
      "29 [D loss: 0.040539] [D acc: 0.992188] [G loss: 4.371024] [G acc: 0.000000]\n",
      "30 [D loss: 0.042078] [D acc: 0.992188] [G loss: 4.526336] [G acc: 0.000000]\n",
      "31 [D loss: 0.177330] [D acc: 0.988281] [G loss: 11.536807] [G acc: 0.000000]\n",
      "32 [D loss: 0.159570] [D acc: 0.957031] [G loss: 6.086331] [G acc: 0.000000]\n",
      "33 [D loss: 0.023038] [D acc: 0.996094] [G loss: 5.168183] [G acc: 0.000000]\n",
      "34 [D loss: 0.219602] [D acc: 0.988281] [G loss: 13.499510] [G acc: 0.000000]\n",
      "35 [D loss: 0.204961] [D acc: 0.917969] [G loss: 2.079746] [G acc: 0.000000]\n",
      "36 [D loss: 0.557609] [D acc: 0.550781] [G loss: 12.967377] [G acc: 0.000000]\n",
      "37 [D loss: 0.228790] [D acc: 0.906250] [G loss: 6.221750] [G acc: 0.000000]\n",
      "38 [D loss: 0.042888] [D acc: 0.980469] [G loss: 4.969354] [G acc: 0.000000]\n",
      "39 [D loss: 0.021229] [D acc: 0.996094] [G loss: 4.817615] [G acc: 0.000000]\n",
      "40 [D loss: 0.048240] [D acc: 0.988281] [G loss: 4.297806] [G acc: 0.000000]\n",
      "41 [D loss: 1.934783] [D acc: 0.500000] [G loss: 4.989358] [G acc: 0.000000]\n",
      "42 [D loss: 0.238788] [D acc: 0.980469] [G loss: 6.790066] [G acc: 0.000000]\n",
      "43 [D loss: 0.297431] [D acc: 0.933594] [G loss: 5.219063] [G acc: 0.000000]\n",
      "44 [D loss: 0.148390] [D acc: 0.945312] [G loss: 2.171789] [G acc: 0.000000]\n",
      "45 [D loss: 0.114394] [D acc: 0.984375] [G loss: 5.069750] [G acc: 0.000000]\n",
      "46 [D loss: 0.058217] [D acc: 0.976562] [G loss: 4.381597] [G acc: 0.000000]\n",
      "47 [D loss: 0.036668] [D acc: 0.988281] [G loss: 4.309243] [G acc: 0.000000]\n",
      "48 [D loss: 0.042465] [D acc: 0.984375] [G loss: 4.426687] [G acc: 0.000000]\n",
      "49 [D loss: 0.060266] [D acc: 0.984375] [G loss: 4.680738] [G acc: 0.000000]\n",
      "50 [D loss: 1.390348] [D acc: 0.507812] [G loss: 10.803522] [G acc: 0.000000]\n",
      "51 [D loss: 0.184821] [D acc: 0.917969] [G loss: 4.285389] [G acc: 0.000000]\n",
      "52 [D loss: 0.214297] [D acc: 0.980469] [G loss: 10.845509] [G acc: 0.000000]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-fa14df52bc6b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;34m,\u001b[0m \u001b[0mrun_folder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRUN_FOLDER\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;34m,\u001b[0m \u001b[0mprint_every_n_batches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0;34m,\u001b[0m \u001b[0minitial_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m )\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Git/Personal/GDL/generative_deep_learning_code/models/GAN.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, x_train, batch_size, epochs, run_folder, print_every_n_batches, initial_epoch)\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;31m# g_loss = 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;31m# g_acc = 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 299\u001b[0;31m             \u001b[0mg_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnoise\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m             \u001b[0;31m# Plot the progress\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/gdl/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1217\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/gdl/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/gdl/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/gdl/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1380\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1381\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1382\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1383\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1384\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "d_losses, g_losses, d_accs, g_accs = gan.train(     \n",
    "    x_train\n",
    "    , batch_size = 128\n",
    "    , epochs = 2000\n",
    "    , run_folder = RUN_FOLDER\n",
    "    , print_every_n_batches = 10\n",
    "    , initial_epoch = 0\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan.model.optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(g_accs, color='orange', linewidth=1)\n",
    "plt.plot(d_accs, color='green', linewidth=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    print(gan.discriminator.predict(np.array([x_train[i]]))[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = np.random.uniform(-1, 1, 100)\n",
    "img = gan.generator.predict(np.array([noise]))[0]\n",
    "\n",
    "print(img.shape)\n",
    "plt.imshow(img[:,:,0])\n",
    "\n",
    "gan.discriminator.predict(np.array([img]))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(gan.discriminator.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan.discriminator.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pointer = 0\n",
    "for x, y in enumerate(gan.discriminator.layers):\n",
    "    \n",
    "    print(y)\n",
    "    print(y.trainable)\n",
    "    for i in gan.discriminator.layers[x].get_weights():\n",
    "        \n",
    "        print(pointer)\n",
    "        print(i.shape)\n",
    "        pointer+=1\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(gan.discriminator.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan.discriminator.get_weights()[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan.discriminator.get_weights()[22]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train[0][16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan.model.save_weights(os.path.join(RUN_FOLDER, 'weights/weights.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gdl",
   "language": "python",
   "name": "gdl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
