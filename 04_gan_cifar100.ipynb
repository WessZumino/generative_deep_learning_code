{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GAN Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from models.GAN import GAN\n",
    "from utils.loaders import load_safari\n",
    "from keras.datasets import cifar100,cifar10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "RUN_ID = '0016'\n",
    "RUN_FOLDER = os.path.join(\"./run\", RUN_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = 7\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "# (x_train, y_train), (x_test, y_test) = cifar10.load_data(label_mode='fine')\n",
    "\n",
    "mask = [y[0]==label for y in y_train]\n",
    "\n",
    "x_train = x_train[mask]\n",
    "y_train = y_train[mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x109c21a58>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_train[200,:,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = (x_train.astype('float32') - 127.5) / 127.5\n",
    "x_test = (x_test.astype('float32') - 127.5) / 127.5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.92941177\n",
      "0.94509804\n"
     ]
    }
   ],
   "source": [
    "print(np.min(x_train[0]))\n",
    "print(np.max(x_train[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 32, 32, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan = GAN(input_dim = (32,32,3)\n",
    "        , discriminator_conv_filters = [32,64,128,256]\n",
    "        , discriminator_conv_kernel_size = [5,5,5,5]\n",
    "        , discriminator_conv_strides = [2,2,2,2]\n",
    "        , discriminator_conv_padding = 'same'\n",
    "        , discriminator_batch_norm_momentum = 0.9\n",
    "        , discriminator_activation = 'leaky_relu'\n",
    "        , discriminator_dropout_rate = None\n",
    "        , discriminator_learning_rate = 0.0005 #0.0002 #\n",
    "        , generator_initial_dense_layer_size = (2,2,256)\n",
    "        , generator_use_upsampling = [False,False, False,False]\n",
    "        , generator_conv_t_filters = [128,64, 32,3]\n",
    "        , generator_conv_t_kernel_size = [5,5,5,5]\n",
    "        , generator_conv_t_strides = [2,2,2,2]\n",
    "        , generator_conv_t_padding = 'same'\n",
    "        , generator_batch_norm_momentum = 0.9\n",
    "        , generator_activation = 'leaky_relu'\n",
    "        , generator_dropout_rate = None\n",
    "        , generator_learning_rate = 0.0005 #0.0002 #\n",
    "        , optimiser = 'adam'\n",
    "        , z_dim = 100\n",
    "        )\n",
    "\n",
    "gan.save(RUN_FOLDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gan.load_weights(os.path.join(RUN_FOLDER, 'weights/weights.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "discriminator_input (InputLa (None, 32, 32, 3)         0         \n",
      "_________________________________________________________________\n",
      "discriminator_conv_0 (Conv2D (None, 16, 16, 32)        2432      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 16, 16, 32)        128       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "discriminator_conv_1 (Conv2D (None, 8, 8, 64)          51264     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 8, 8, 64)          256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "discriminator_conv_2 (Conv2D (None, 4, 4, 128)         204928    \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 4, 4, 128)         512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "discriminator_conv_3 (Conv2D (None, 2, 2, 256)         819456    \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 2, 2, 256)         1024      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 2, 2, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 1025      \n",
      "=================================================================\n",
      "Total params: 1,081,025\n",
      "Trainable params: 0\n",
      "Non-trainable params: 1,081,025\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "gan.discriminator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "generator_input (InputLayer) (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1024)              103424    \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)    (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 2, 2, 256)         0         \n",
      "_________________________________________________________________\n",
      "generator_conv_t_0 (Conv2DTr (None, 4, 4, 128)         819328    \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 4, 4, 128)         512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)    (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "generator_conv_t_1 (Conv2DTr (None, 8, 8, 64)          204864    \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 8, 8, 64)          256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)    (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "generator_conv_t_2 (Conv2DTr (None, 16, 16, 32)        51232     \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 16, 16, 32)        128       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)    (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "generator_conv_t_3 (Conv2DTr (None, 32, 32, 3)         2403      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 32, 32, 3)         0         \n",
      "=================================================================\n",
      "Total params: 1,186,243\n",
      "Trainable params: 1,183,747\n",
      "Non-trainable params: 2,496\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "gan.generator.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [D loss: 0.979434] [D acc: 0.203125] [G loss: 0.666885] [G acc: 0.632812]\n",
      "1 [D loss: 4.463055] [D acc: 0.246094] [G loss: 0.000619] [G acc: 1.000000]\n",
      "2 [D loss: 4.457185] [D acc: 0.226562] [G loss: 0.000519] [G acc: 1.000000]\n",
      "3 [D loss: 4.464030] [D acc: 0.250000] [G loss: 0.000443] [G acc: 1.000000]\n",
      "4 [D loss: 4.517453] [D acc: 0.203125] [G loss: 0.000404] [G acc: 1.000000]\n",
      "5 [D loss: 4.564306] [D acc: 0.203125] [G loss: 0.000343] [G acc: 1.000000]\n",
      "6 [D loss: 4.697560] [D acc: 0.226562] [G loss: 0.000281] [G acc: 1.000000]\n",
      "7 [D loss: 4.668487] [D acc: 0.203125] [G loss: 0.000274] [G acc: 1.000000]\n",
      "8 [D loss: 4.724884] [D acc: 0.210938] [G loss: 0.000238] [G acc: 1.000000]\n",
      "9 [D loss: 4.705108] [D acc: 0.230469] [G loss: 0.000234] [G acc: 1.000000]\n",
      "10 [D loss: 4.764194] [D acc: 0.234375] [G loss: 0.000190] [G acc: 1.000000]\n",
      "11 [D loss: 4.788761] [D acc: 0.210938] [G loss: 0.000183] [G acc: 1.000000]\n",
      "12 [D loss: 4.821237] [D acc: 0.230469] [G loss: 0.000172] [G acc: 1.000000]\n",
      "13 [D loss: 4.867229] [D acc: 0.214844] [G loss: 0.000168] [G acc: 1.000000]\n",
      "14 [D loss: 4.872157] [D acc: 0.242188] [G loss: 0.000165] [G acc: 1.000000]\n",
      "15 [D loss: 4.925068] [D acc: 0.195312] [G loss: 0.000135] [G acc: 1.000000]\n",
      "16 [D loss: 4.852870] [D acc: 0.257812] [G loss: 0.000140] [G acc: 1.000000]\n",
      "17 [D loss: 4.967023] [D acc: 0.226562] [G loss: 0.000132] [G acc: 1.000000]\n",
      "18 [D loss: 5.037874] [D acc: 0.222656] [G loss: 0.000119] [G acc: 1.000000]\n",
      "19 [D loss: 5.053021] [D acc: 0.199219] [G loss: 0.000113] [G acc: 1.000000]\n",
      "20 [D loss: 5.056042] [D acc: 0.207031] [G loss: 0.000108] [G acc: 1.000000]\n",
      "21 [D loss: 5.083261] [D acc: 0.207031] [G loss: 0.000104] [G acc: 1.000000]\n",
      "22 [D loss: 5.108236] [D acc: 0.234375] [G loss: 0.000095] [G acc: 1.000000]\n",
      "23 [D loss: 5.135027] [D acc: 0.210938] [G loss: 0.000089] [G acc: 1.000000]\n",
      "24 [D loss: 5.098776] [D acc: 0.242188] [G loss: 0.000082] [G acc: 1.000000]\n",
      "25 [D loss: 5.243845] [D acc: 0.179688] [G loss: 0.000075] [G acc: 1.000000]\n",
      "26 [D loss: 5.184937] [D acc: 0.199219] [G loss: 0.000075] [G acc: 1.000000]\n",
      "27 [D loss: 5.298935] [D acc: 0.195312] [G loss: 0.000070] [G acc: 1.000000]\n",
      "28 [D loss: 5.206573] [D acc: 0.242188] [G loss: 0.000071] [G acc: 1.000000]\n",
      "29 [D loss: 5.233896] [D acc: 0.203125] [G loss: 0.000068] [G acc: 1.000000]\n",
      "30 [D loss: 5.191831] [D acc: 0.218750] [G loss: 0.000060] [G acc: 1.000000]\n",
      "31 [D loss: 5.274674] [D acc: 0.222656] [G loss: 0.000062] [G acc: 1.000000]\n",
      "32 [D loss: 5.307571] [D acc: 0.234375] [G loss: 0.000061] [G acc: 1.000000]\n",
      "33 [D loss: 5.327353] [D acc: 0.218750] [G loss: 0.000056] [G acc: 1.000000]\n",
      "34 [D loss: 5.385451] [D acc: 0.222656] [G loss: 0.000056] [G acc: 1.000000]\n",
      "35 [D loss: 5.314438] [D acc: 0.226562] [G loss: 0.000052] [G acc: 1.000000]\n",
      "36 [D loss: 5.434138] [D acc: 0.210938] [G loss: 0.000051] [G acc: 1.000000]\n",
      "37 [D loss: 5.410578] [D acc: 0.218750] [G loss: 0.000047] [G acc: 1.000000]\n",
      "38 [D loss: 5.482219] [D acc: 0.218750] [G loss: 0.000042] [G acc: 1.000000]\n",
      "39 [D loss: 5.478279] [D acc: 0.257812] [G loss: 0.000044] [G acc: 1.000000]\n",
      "40 [D loss: 5.480350] [D acc: 0.261719] [G loss: 0.000038] [G acc: 1.000000]\n",
      "41 [D loss: 5.520877] [D acc: 0.210938] [G loss: 0.000037] [G acc: 1.000000]\n",
      "42 [D loss: 5.547833] [D acc: 0.281250] [G loss: 0.000039] [G acc: 1.000000]\n",
      "43 [D loss: 5.468064] [D acc: 0.226562] [G loss: 0.000037] [G acc: 1.000000]\n",
      "44 [D loss: 5.558181] [D acc: 0.222656] [G loss: 0.000031] [G acc: 1.000000]\n",
      "45 [D loss: 5.609248] [D acc: 0.242188] [G loss: 0.000039] [G acc: 1.000000]\n",
      "46 [D loss: 5.586908] [D acc: 0.234375] [G loss: 0.000034] [G acc: 1.000000]\n",
      "47 [D loss: 5.612185] [D acc: 0.214844] [G loss: 0.000031] [G acc: 1.000000]\n",
      "48 [D loss: 5.645864] [D acc: 0.234375] [G loss: 0.000027] [G acc: 1.000000]\n",
      "49 [D loss: 5.695391] [D acc: 0.246094] [G loss: 0.000026] [G acc: 1.000000]\n",
      "50 [D loss: 5.679928] [D acc: 0.246094] [G loss: 0.000027] [G acc: 1.000000]\n",
      "51 [D loss: 5.687578] [D acc: 0.226562] [G loss: 0.000025] [G acc: 1.000000]\n",
      "52 [D loss: 5.700503] [D acc: 0.238281] [G loss: 0.000024] [G acc: 1.000000]\n",
      "53 [D loss: 5.723722] [D acc: 0.261719] [G loss: 0.000023] [G acc: 1.000000]\n",
      "54 [D loss: 5.782308] [D acc: 0.207031] [G loss: 0.000023] [G acc: 1.000000]\n",
      "55 [D loss: 5.763897] [D acc: 0.207031] [G loss: 0.000023] [G acc: 1.000000]\n",
      "56 [D loss: 5.747834] [D acc: 0.246094] [G loss: 0.000020] [G acc: 1.000000]\n",
      "57 [D loss: 5.785913] [D acc: 0.261719] [G loss: 0.000020] [G acc: 1.000000]\n",
      "58 [D loss: 5.843313] [D acc: 0.214844] [G loss: 0.000020] [G acc: 1.000000]\n",
      "59 [D loss: 5.848334] [D acc: 0.187500] [G loss: 0.000019] [G acc: 1.000000]\n",
      "60 [D loss: 5.944234] [D acc: 0.269531] [G loss: 0.000017] [G acc: 1.000000]\n",
      "61 [D loss: 5.893620] [D acc: 0.195312] [G loss: 0.000017] [G acc: 1.000000]\n",
      "62 [D loss: 5.949564] [D acc: 0.230469] [G loss: 0.000018] [G acc: 1.000000]\n",
      "63 [D loss: 5.940338] [D acc: 0.238281] [G loss: 0.000015] [G acc: 1.000000]\n",
      "64 [D loss: 5.992930] [D acc: 0.207031] [G loss: 0.000016] [G acc: 1.000000]\n",
      "65 [D loss: 5.929935] [D acc: 0.238281] [G loss: 0.000014] [G acc: 1.000000]\n",
      "66 [D loss: 5.951814] [D acc: 0.230469] [G loss: 0.000015] [G acc: 1.000000]\n",
      "67 [D loss: 5.966521] [D acc: 0.265625] [G loss: 0.000013] [G acc: 1.000000]\n",
      "68 [D loss: 6.066137] [D acc: 0.195312] [G loss: 0.000013] [G acc: 1.000000]\n",
      "69 [D loss: 5.990037] [D acc: 0.183594] [G loss: 0.000013] [G acc: 1.000000]\n",
      "70 [D loss: 6.084524] [D acc: 0.234375] [G loss: 0.000012] [G acc: 1.000000]\n",
      "71 [D loss: 6.018260] [D acc: 0.250000] [G loss: 0.000011] [G acc: 1.000000]\n",
      "72 [D loss: 6.097524] [D acc: 0.265625] [G loss: 0.000011] [G acc: 1.000000]\n",
      "73 [D loss: 6.101552] [D acc: 0.230469] [G loss: 0.000012] [G acc: 1.000000]\n",
      "74 [D loss: 6.058872] [D acc: 0.265625] [G loss: 0.000010] [G acc: 1.000000]\n",
      "75 [D loss: 6.179091] [D acc: 0.246094] [G loss: 0.000009] [G acc: 1.000000]\n",
      "76 [D loss: 6.134388] [D acc: 0.234375] [G loss: 0.000010] [G acc: 1.000000]\n",
      "77 [D loss: 6.131034] [D acc: 0.269531] [G loss: 0.000009] [G acc: 1.000000]\n",
      "78 [D loss: 6.160747] [D acc: 0.238281] [G loss: 0.000009] [G acc: 1.000000]\n",
      "79 [D loss: 6.109101] [D acc: 0.238281] [G loss: 0.000008] [G acc: 1.000000]\n",
      "80 [D loss: 6.099275] [D acc: 0.285156] [G loss: 0.000008] [G acc: 1.000000]\n",
      "81 [D loss: 6.260378] [D acc: 0.253906] [G loss: 0.000008] [G acc: 1.000000]\n",
      "82 [D loss: 6.278319] [D acc: 0.214844] [G loss: 0.000007] [G acc: 1.000000]\n",
      "83 [D loss: 6.282483] [D acc: 0.253906] [G loss: 0.000008] [G acc: 1.000000]\n",
      "84 [D loss: 6.251277] [D acc: 0.210938] [G loss: 0.000007] [G acc: 1.000000]\n",
      "85 [D loss: 6.270920] [D acc: 0.222656] [G loss: 0.000006] [G acc: 1.000000]\n",
      "86 [D loss: 6.317367] [D acc: 0.265625] [G loss: 0.000006] [G acc: 1.000000]\n",
      "87 [D loss: 6.273964] [D acc: 0.261719] [G loss: 0.000006] [G acc: 1.000000]\n",
      "88 [D loss: 6.333093] [D acc: 0.285156] [G loss: 0.000006] [G acc: 1.000000]\n",
      "89 [D loss: 6.342329] [D acc: 0.269531] [G loss: 0.000006] [G acc: 1.000000]\n",
      "90 [D loss: 6.343353] [D acc: 0.246094] [G loss: 0.000005] [G acc: 1.000000]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-fa14df52bc6b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;34m,\u001b[0m \u001b[0mrun_folder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRUN_FOLDER\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;34m,\u001b[0m \u001b[0mprint_every_n_batches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0;34m,\u001b[0m \u001b[0minitial_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m )\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Git/Personal/GDL/generative_deep_learning_code/models/GAN.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, x_train, batch_size, epochs, run_folder, print_every_n_batches, initial_epoch)\u001b[0m\n\u001b[1;32m    292\u001b[0m             \u001b[0mnoise\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mz_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 294\u001b[0;31m             \u001b[0mg_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnoise\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    295\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m             \u001b[0;31m# Plot the progress\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/gdl/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1217\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/gdl/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/gdl/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/gdl/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1380\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1381\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1382\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1383\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1384\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "d_losses, g_losses, d_accs, g_accs = gan.train(     \n",
    "    x_train\n",
    "    , batch_size = 128\n",
    "    , epochs = 2000\n",
    "    , run_folder = RUN_FOLDER\n",
    "    , print_every_n_batches = 10\n",
    "    , initial_epoch = 0\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(g_accs, color='orange', linewidth=1)\n",
    "plt.plot(d_accs, color='green', linewidth=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    print(gan.discriminator.predict(np.array([x_train[i]]))[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = np.random.uniform(-1, 1, 100)\n",
    "img = gan.generator.predict(np.array([noise]))[0]\n",
    "\n",
    "print(img.shape)\n",
    "plt.imshow(img[:,:,0])\n",
    "\n",
    "gan.discriminator.predict(np.array([img]))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(gan.discriminator.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan.discriminator.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pointer = 0\n",
    "for x, y in enumerate(gan.discriminator.layers):\n",
    "    \n",
    "    print(y)\n",
    "    print(y.trainable)\n",
    "    for i in gan.discriminator.layers[x].get_weights():\n",
    "        \n",
    "        print(pointer)\n",
    "        print(i.shape)\n",
    "        pointer+=1\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(gan.discriminator.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan.discriminator.get_weights()[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan.discriminator.get_weights()[22]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train[0][16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan.model.save_weights(os.path.join(RUN_FOLDER, 'weights/weights.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gdl",
   "language": "python",
   "name": "gdl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
