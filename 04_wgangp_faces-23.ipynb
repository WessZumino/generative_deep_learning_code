{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WGAN Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from models.WGANGP import WGANGP\n",
    "from utils.loaders import load_safari, load_cifar10\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "RUN_ID = '0023'\n",
    "RUN_FOLDER = os.path.join(\"./run\", RUN_ID)\n",
    "DATA_FOLDER = './data/celeb/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 202599 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "data_gen = ImageDataGenerator(preprocessing_function=lambda x: (x.astype('float32') - 127.5) / 127.5)\n",
    "\n",
    "x_train = data_gen.flow_from_directory(DATA_FOLDER\n",
    "                                         , target_size = (64,64)\n",
    "                                         , batch_size = 32\n",
    "                                         , shuffle = True\n",
    "                                         , class_mode = 'input'\n",
    "                                         , subset = \"training\"\n",
    "                                            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x14d71c828>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_train[0][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.0\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print(np.min(x_train[0][0]))\n",
    "print(np.max(x_train[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#works\n",
    "\n",
    "gan = WGANGP(input_dim = (64,64,3)\n",
    "        , critic_conv_filters = [64,64,128,128]\n",
    "        , critic_conv_kernel_size = [5,5,5,5]\n",
    "        , critic_conv_strides = [2,2,2,1]\n",
    "        , critic_conv_padding = 'same'\n",
    "        , critic_batch_norm_momentum = None\n",
    "        , critic_activation = 'leaky_relu'\n",
    "        , critic_dropout_rate = None\n",
    "        , critic_learning_rate = 0.00005\n",
    "        , generator_initial_dense_layer_size = (16, 16, 32)\n",
    "        , generator_use_upsampling = [True,True, False,False]\n",
    "        , generator_conv_t_filters = [128,64, 64,3]\n",
    "        , generator_conv_t_kernel_size = [5,5,5,5]\n",
    "        , generator_conv_t_strides = [1,1,1,1]\n",
    "        , generator_conv_t_padding = 'same'\n",
    "        , generator_batch_norm_momentum = 0.8\n",
    "        , generator_activation = 'leaky_relu'\n",
    "        , generator_dropout_rate = None\n",
    "        , generator_learning_rate = 0.00005\n",
    "        , optimiser = 'rmsprop'\n",
    "        , z_dim = 100\n",
    "        )\n",
    "\n",
    "\n",
    "gan.save(RUN_FOLDER)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gan.load_weights(os.path.join(RUN_FOLDER, 'weights/weights.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "critic_input (InputLayer)    (None, 64, 64, 3)         0         \n",
      "_________________________________________________________________\n",
      "critic_conv_0 (Conv2D)       (None, 32, 32, 64)        4864      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_17 (LeakyReLU)   (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "critic_conv_1 (Conv2D)       (None, 16, 16, 64)        102464    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_18 (LeakyReLU)   (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "critic_conv_2 (Conv2D)       (None, 8, 8, 128)         204928    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_19 (LeakyReLU)   (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "critic_conv_3 (Conv2D)       (None, 8, 8, 128)         409728    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_20 (LeakyReLU)   (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 8193      \n",
      "=================================================================\n",
      "Total params: 730,177\n",
      "Trainable params: 0\n",
      "Non-trainable params: 730,177\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "gan.critic.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "generator_input (InputLayer) (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 8192)              827392    \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 8192)              32768     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_21 (LeakyReLU)   (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "reshape_3 (Reshape)          (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_6 (UpSampling2 (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "generator_conv_t_0 (Conv2DTr (None, 32, 32, 128)       102528    \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 32, 32, 128)       512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_22 (LeakyReLU)   (None, 32, 32, 128)       0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_7 (UpSampling2 (None, 64, 64, 128)       0         \n",
      "_________________________________________________________________\n",
      "generator_conv_t_1 (Conv2DTr (None, 64, 64, 64)        204864    \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 64, 64, 64)        256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_23 (LeakyReLU)   (None, 64, 64, 64)        0         \n",
      "_________________________________________________________________\n",
      "generator_conv_t_2 (Conv2DTr (None, 64, 64, 64)        102464    \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 64, 64, 64)        256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_24 (LeakyReLU)   (None, 64, 64, 64)        0         \n",
      "_________________________________________________________________\n",
      "generator_conv_t_3 (Conv2DTr (None, 64, 64, 3)         4803      \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 64, 64, 3)         0         \n",
      "=================================================================\n",
      "Total params: 1,275,843\n",
      "Trainable params: 1,258,947\n",
      "Non-trainable params: 16,896\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "gan.generator.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/davidfoster/.virtualenvs/gdl/lib/python3.6/site-packages/keras/engine/training.py:490: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 (5, 1) [D loss: (8.5)] [D acc: (0.000)] [G loss: 0.0] [G acc: 0.156]\n",
      "1 (5, 1) [D loss: (7.5)] [D acc: (0.000)] [G loss: -0.0] [G acc: 0.750]\n",
      "2 (5, 1) [D loss: (5.8)] [D acc: (0.000)] [G loss: -0.6] [G acc: 1.000]\n",
      "3 (5, 1) [D loss: (2.6)] [D acc: (0.000)] [G loss: -2.2] [G acc: 0.969]\n",
      "4 (5, 1) [D loss: (-3.6)] [D acc: (0.000)] [G loss: -6.4] [G acc: 1.000]\n",
      "5 (5, 1) [D loss: (-4.9)] [D acc: (0.000)] [G loss: -13.8] [G acc: 1.000]\n",
      "6 (5, 1) [D loss: (-9.0)] [D acc: (0.000)] [G loss: -20.8] [G acc: 1.000]\n",
      "7 (5, 1) [D loss: (-6.2)] [D acc: (0.000)] [G loss: -23.7] [G acc: 1.000]\n",
      "8 (5, 1) [D loss: (-13.4)] [D acc: (0.000)] [G loss: -25.1] [G acc: 1.000]\n",
      "9 (5, 1) [D loss: (-14.5)] [D acc: (0.000)] [G loss: -22.9] [G acc: 1.000]\n",
      "10 (5, 1) [D loss: (-19.2)] [D acc: (0.000)] [G loss: -18.2] [G acc: 1.000]\n",
      "11 (5, 1) [D loss: (-23.1)] [D acc: (0.000)] [G loss: -12.0] [G acc: 0.906]\n",
      "12 (5, 1) [D loss: (-22.5)] [D acc: (0.000)] [G loss: -6.2] [G acc: 0.625]\n",
      "13 (5, 1) [D loss: (-27.7)] [D acc: (0.000)] [G loss: -0.6] [G acc: 0.469]\n",
      "14 (5, 1) [D loss: (-30.7)] [D acc: (0.000)] [G loss: 3.2] [G acc: 0.469]\n",
      "15 (5, 1) [D loss: (-37.9)] [D acc: (0.000)] [G loss: 9.0] [G acc: 0.281]\n",
      "16 (5, 1) [D loss: (-32.2)] [D acc: (0.000)] [G loss: 4.7] [G acc: 0.500]\n",
      "17 (5, 1) [D loss: (-29.2)] [D acc: (0.000)] [G loss: 7.4] [G acc: 0.312]\n",
      "18 (5, 1) [D loss: (-30.6)] [D acc: (0.000)] [G loss: 3.4] [G acc: 0.406]\n",
      "19 (5, 1) [D loss: (-42.9)] [D acc: (0.000)] [G loss: -2.2] [G acc: 0.406]\n",
      "20 (5, 1) [D loss: (-31.9)] [D acc: (0.000)] [G loss: 10.7] [G acc: 0.156]\n",
      "21 (5, 1) [D loss: (-25.6)] [D acc: (0.000)] [G loss: 20.6] [G acc: 0.125]\n",
      "22 (5, 1) [D loss: (-41.6)] [D acc: (0.000)] [G loss: 7.1] [G acc: 0.250]\n",
      "23 (5, 1) [D loss: (-24.0)] [D acc: (0.000)] [G loss: 16.1] [G acc: 0.125]\n",
      "24 (5, 1) [D loss: (-34.6)] [D acc: (0.000)] [G loss: 6.2] [G acc: 0.219]\n",
      "25 (5, 1) [D loss: (-23.0)] [D acc: (0.000)] [G loss: 15.5] [G acc: 0.250]\n",
      "26 (5, 1) [D loss: (-27.1)] [D acc: (0.000)] [G loss: 18.0] [G acc: 0.094]\n",
      "27 (5, 1) [D loss: (-24.4)] [D acc: (0.000)] [G loss: 9.5] [G acc: 0.156]\n",
      "28 (5, 1) [D loss: (-23.0)] [D acc: (0.000)] [G loss: 3.7] [G acc: 0.344]\n",
      "29 (5, 1) [D loss: (-30.8)] [D acc: (0.000)] [G loss: -4.3] [G acc: 0.594]\n",
      "30 (5, 1) [D loss: (-32.2)] [D acc: (0.000)] [G loss: 1.7] [G acc: 0.406]\n",
      "31 (5, 1) [D loss: (-32.9)] [D acc: (0.000)] [G loss: -6.3] [G acc: 0.688]\n",
      "32 (5, 1) [D loss: (-36.7)] [D acc: (0.000)] [G loss: 2.7] [G acc: 0.406]\n",
      "33 (5, 1) [D loss: (-27.9)] [D acc: (0.000)] [G loss: 3.2] [G acc: 0.375]\n",
      "34 (5, 1) [D loss: (-36.0)] [D acc: (0.000)] [G loss: 11.0] [G acc: 0.188]\n",
      "35 (5, 1) [D loss: (-40.4)] [D acc: (0.000)] [G loss: 13.7] [G acc: 0.250]\n",
      "36 (5, 1) [D loss: (-31.5)] [D acc: (0.000)] [G loss: 13.4] [G acc: 0.125]\n",
      "37 (5, 1) [D loss: (-39.8)] [D acc: (0.000)] [G loss: 15.4] [G acc: 0.062]\n",
      "38 (5, 1) [D loss: (-30.8)] [D acc: (0.000)] [G loss: 16.8] [G acc: 0.156]\n",
      "39 (5, 1) [D loss: (-37.7)] [D acc: (0.000)] [G loss: 16.3] [G acc: 0.094]\n",
      "40 (5, 1) [D loss: (-26.5)] [D acc: (0.000)] [G loss: 16.6] [G acc: 0.188]\n",
      "41 (5, 1) [D loss: (-38.3)] [D acc: (0.000)] [G loss: 16.2] [G acc: 0.094]\n",
      "42 (5, 1) [D loss: (-30.1)] [D acc: (0.000)] [G loss: 23.9] [G acc: 0.000]\n",
      "43 (5, 1) [D loss: (-29.9)] [D acc: (0.000)] [G loss: 20.5] [G acc: 0.031]\n",
      "44 (5, 1) [D loss: (-30.6)] [D acc: (0.000)] [G loss: 12.7] [G acc: 0.250]\n",
      "45 (5, 1) [D loss: (-26.8)] [D acc: (0.000)] [G loss: 10.1] [G acc: 0.250]\n",
      "46 (5, 1) [D loss: (-31.0)] [D acc: (0.000)] [G loss: 4.1] [G acc: 0.438]\n",
      "47 (5, 1) [D loss: (-27.0)] [D acc: (0.000)] [G loss: 24.5] [G acc: 0.031]\n",
      "48 (5, 1) [D loss: (-29.3)] [D acc: (0.000)] [G loss: -9.9] [G acc: 0.656]\n",
      "49 (5, 1) [D loss: (-40.4)] [D acc: (0.000)] [G loss: 13.5] [G acc: 0.094]\n",
      "50 (5, 1) [D loss: (-32.2)] [D acc: (0.000)] [G loss: 16.6] [G acc: 0.125]\n",
      "51 (5, 1) [D loss: (-35.3)] [D acc: (0.000)] [G loss: 3.8] [G acc: 0.438]\n",
      "52 (5, 1) [D loss: (-24.0)] [D acc: (0.000)] [G loss: 12.3] [G acc: 0.094]\n",
      "53 (5, 1) [D loss: (-22.9)] [D acc: (0.000)] [G loss: 13.5] [G acc: 0.094]\n",
      "54 (5, 1) [D loss: (-21.7)] [D acc: (0.000)] [G loss: 5.6] [G acc: 0.375]\n",
      "55 (5, 1) [D loss: (-25.0)] [D acc: (0.000)] [G loss: -4.2] [G acc: 0.594]\n",
      "56 (5, 1) [D loss: (-19.5)] [D acc: (0.000)] [G loss: 15.1] [G acc: 0.062]\n",
      "57 (5, 1) [D loss: (-22.3)] [D acc: (0.000)] [G loss: -0.6] [G acc: 0.469]\n",
      "58 (5, 1) [D loss: (-25.4)] [D acc: (0.000)] [G loss: 9.0] [G acc: 0.281]\n",
      "59 (5, 1) [D loss: (-25.3)] [D acc: (0.000)] [G loss: 15.7] [G acc: 0.125]\n",
      "60 (5, 1) [D loss: (-25.9)] [D acc: (0.000)] [G loss: -2.4] [G acc: 0.500]\n",
      "61 (5, 1) [D loss: (-28.5)] [D acc: (0.000)] [G loss: 9.0] [G acc: 0.219]\n",
      "62 (5, 1) [D loss: (-25.6)] [D acc: (0.000)] [G loss: -1.3] [G acc: 0.562]\n",
      "63 (5, 1) [D loss: (-23.1)] [D acc: (0.000)] [G loss: -0.9] [G acc: 0.531]\n",
      "64 (5, 1) [D loss: (-18.7)] [D acc: (0.000)] [G loss: 13.2] [G acc: 0.188]\n",
      "65 (5, 1) [D loss: (-20.3)] [D acc: (0.000)] [G loss: 1.5] [G acc: 0.469]\n",
      "66 (5, 1) [D loss: (-28.6)] [D acc: (0.000)] [G loss: 18.0] [G acc: 0.094]\n",
      "67 (5, 1) [D loss: (-21.1)] [D acc: (0.000)] [G loss: 4.1] [G acc: 0.438]\n",
      "68 (5, 1) [D loss: (-20.9)] [D acc: (0.000)] [G loss: 6.2] [G acc: 0.281]\n",
      "69 (5, 1) [D loss: (-15.5)] [D acc: (0.000)] [G loss: 5.6] [G acc: 0.344]\n",
      "70 (5, 1) [D loss: (-25.7)] [D acc: (0.000)] [G loss: 2.6] [G acc: 0.438]\n",
      "71 (5, 1) [D loss: (-23.0)] [D acc: (0.000)] [G loss: 13.1] [G acc: 0.062]\n",
      "72 (5, 1) [D loss: (-25.5)] [D acc: (0.000)] [G loss: -5.7] [G acc: 0.625]\n",
      "73 (5, 1) [D loss: (-20.0)] [D acc: (0.000)] [G loss: 4.5] [G acc: 0.281]\n",
      "74 (5, 1) [D loss: (-23.2)] [D acc: (0.000)] [G loss: 17.9] [G acc: 0.000]\n",
      "75 (5, 1) [D loss: (-15.8)] [D acc: (0.000)] [G loss: 6.3] [G acc: 0.250]\n",
      "76 (5, 1) [D loss: (-23.1)] [D acc: (0.000)] [G loss: 14.3] [G acc: 0.125]\n",
      "77 (5, 1) [D loss: (-22.3)] [D acc: (0.000)] [G loss: -1.7] [G acc: 0.531]\n",
      "78 (5, 1) [D loss: (-23.7)] [D acc: (0.000)] [G loss: 13.5] [G acc: 0.094]\n",
      "79 (5, 1) [D loss: (-16.2)] [D acc: (0.000)] [G loss: 11.7] [G acc: 0.094]\n",
      "80 (5, 1) [D loss: (-17.8)] [D acc: (0.000)] [G loss: -12.6] [G acc: 0.844]\n",
      "81 (5, 1) [D loss: (-20.6)] [D acc: (0.000)] [G loss: 7.2] [G acc: 0.281]\n",
      "82 (5, 1) [D loss: (-18.8)] [D acc: (0.000)] [G loss: 15.7] [G acc: 0.094]\n",
      "83 (5, 1) [D loss: (-21.7)] [D acc: (0.000)] [G loss: -2.5] [G acc: 0.625]\n",
      "84 (5, 1) [D loss: (-20.0)] [D acc: (0.000)] [G loss: 1.4] [G acc: 0.406]\n",
      "85 (5, 1) [D loss: (-21.9)] [D acc: (0.000)] [G loss: 10.4] [G acc: 0.188]\n",
      "86 (5, 1) [D loss: (-14.9)] [D acc: (0.000)] [G loss: -4.6] [G acc: 0.688]\n",
      "87 (5, 1) [D loss: (-22.8)] [D acc: (0.000)] [G loss: 1.0] [G acc: 0.469]\n",
      "88 (5, 1) [D loss: (-14.6)] [D acc: (0.000)] [G loss: 11.6] [G acc: 0.062]\n",
      "89 (5, 1) [D loss: (-16.3)] [D acc: (0.000)] [G loss: 3.5] [G acc: 0.281]\n",
      "90 (5, 1) [D loss: (-15.2)] [D acc: (0.000)] [G loss: 4.1] [G acc: 0.312]\n",
      "91 (5, 1) [D loss: (-16.4)] [D acc: (0.000)] [G loss: 2.3] [G acc: 0.469]\n",
      "92 (5, 1) [D loss: (-17.7)] [D acc: (0.000)] [G loss: 7.0] [G acc: 0.188]\n",
      "93 (5, 1) [D loss: (-19.5)] [D acc: (0.000)] [G loss: 7.8] [G acc: 0.188]\n",
      "94 (5, 1) [D loss: (-15.4)] [D acc: (0.000)] [G loss: 10.9] [G acc: 0.188]\n",
      "95 (5, 1) [D loss: (-20.4)] [D acc: (0.000)] [G loss: 13.5] [G acc: 0.094]\n",
      "96 (5, 1) [D loss: (-14.6)] [D acc: (0.000)] [G loss: 8.2] [G acc: 0.156]\n",
      "97 (5, 1) [D loss: (-13.9)] [D acc: (0.000)] [G loss: 12.5] [G acc: 0.188]\n",
      "98 (5, 1) [D loss: (-17.6)] [D acc: (0.000)] [G loss: 4.5] [G acc: 0.156]\n",
      "99 (5, 1) [D loss: (-18.1)] [D acc: (0.000)] [G loss: 22.4] [G acc: 0.000]\n",
      "100 (5, 1) [D loss: (-13.4)] [D acc: (0.000)] [G loss: -8.3] [G acc: 0.812]\n",
      "101 (5, 1) [D loss: (-19.7)] [D acc: (0.000)] [G loss: 12.0] [G acc: 0.219]\n",
      "102 (5, 1) [D loss: (-15.3)] [D acc: (0.000)] [G loss: 1.9] [G acc: 0.250]\n",
      "103 (5, 1) [D loss: (-16.1)] [D acc: (0.000)] [G loss: 3.3] [G acc: 0.344]\n",
      "104 (5, 1) [D loss: (-16.1)] [D acc: (0.000)] [G loss: -0.0] [G acc: 0.531]\n",
      "105 (5, 1) [D loss: (-15.7)] [D acc: (0.000)] [G loss: 7.3] [G acc: 0.156]\n",
      "106 (5, 1) [D loss: (-12.5)] [D acc: (0.000)] [G loss: 12.9] [G acc: 0.031]\n",
      "107 (5, 1) [D loss: (-11.1)] [D acc: (0.000)] [G loss: 11.7] [G acc: 0.031]\n",
      "108 (5, 1) [D loss: (-11.9)] [D acc: (0.000)] [G loss: -5.0] [G acc: 0.750]\n",
      "109 (5, 1) [D loss: (-16.3)] [D acc: (0.000)] [G loss: 5.6] [G acc: 0.312]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110 (5, 1) [D loss: (-11.5)] [D acc: (0.000)] [G loss: -5.7] [G acc: 0.781]\n",
      "111 (5, 1) [D loss: (-15.1)] [D acc: (0.000)] [G loss: 9.8] [G acc: 0.031]\n",
      "112 (5, 1) [D loss: (-12.2)] [D acc: (0.000)] [G loss: 19.0] [G acc: 0.000]\n",
      "113 (5, 1) [D loss: (-13.8)] [D acc: (0.000)] [G loss: -10.3] [G acc: 0.906]\n",
      "114 (5, 1) [D loss: (-13.9)] [D acc: (0.000)] [G loss: 3.7] [G acc: 0.281]\n",
      "115 (5, 1) [D loss: (-14.5)] [D acc: (0.000)] [G loss: 14.5] [G acc: 0.000]\n",
      "116 (5, 1) [D loss: (-12.2)] [D acc: (0.000)] [G loss: 13.9] [G acc: 0.031]\n",
      "117 (5, 1) [D loss: (-9.6)] [D acc: (0.000)] [G loss: 9.2] [G acc: 0.031]\n",
      "118 (5, 1) [D loss: (-10.8)] [D acc: (0.000)] [G loss: 5.2] [G acc: 0.219]\n",
      "119 (5, 1) [D loss: (-15.1)] [D acc: (0.000)] [G loss: 7.0] [G acc: 0.188]\n",
      "120 (5, 1) [D loss: (-10.7)] [D acc: (0.000)] [G loss: 9.8] [G acc: 0.031]\n",
      "121 (5, 1) [D loss: (-14.1)] [D acc: (0.000)] [G loss: 13.3] [G acc: 0.125]\n",
      "122 (5, 1) [D loss: (-14.7)] [D acc: (0.000)] [G loss: 14.6] [G acc: 0.000]\n",
      "123 (5, 1) [D loss: (-14.2)] [D acc: (0.000)] [G loss: 21.7] [G acc: 0.000]\n",
      "124 (5, 1) [D loss: (-10.2)] [D acc: (0.000)] [G loss: 10.6] [G acc: 0.031]\n",
      "125 (5, 1) [D loss: (-12.3)] [D acc: (0.000)] [G loss: 17.7] [G acc: 0.000]\n",
      "126 (5, 1) [D loss: (-11.0)] [D acc: (0.000)] [G loss: 7.4] [G acc: 0.125]\n",
      "127 (5, 1) [D loss: (-12.5)] [D acc: (0.000)] [G loss: 18.8] [G acc: 0.000]\n",
      "128 (5, 1) [D loss: (-10.6)] [D acc: (0.000)] [G loss: 6.0] [G acc: 0.156]\n",
      "129 (5, 1) [D loss: (-13.0)] [D acc: (0.000)] [G loss: 12.4] [G acc: 0.062]\n",
      "130 (5, 1) [D loss: (-10.5)] [D acc: (0.000)] [G loss: 5.2] [G acc: 0.125]\n",
      "131 (5, 1) [D loss: (-11.3)] [D acc: (0.000)] [G loss: -1.4] [G acc: 0.469]\n",
      "132 (5, 1) [D loss: (-10.4)] [D acc: (0.000)] [G loss: 16.3] [G acc: 0.031]\n",
      "133 (5, 1) [D loss: (-10.2)] [D acc: (0.000)] [G loss: 1.0] [G acc: 0.312]\n",
      "134 (5, 1) [D loss: (-10.7)] [D acc: (0.000)] [G loss: 10.9] [G acc: 0.031]\n",
      "135 (5, 1) [D loss: (-11.3)] [D acc: (0.000)] [G loss: 27.3] [G acc: 0.000]\n",
      "136 (5, 1) [D loss: (-10.1)] [D acc: (0.000)] [G loss: -3.2] [G acc: 0.719]\n",
      "137 (5, 1) [D loss: (-9.9)] [D acc: (0.000)] [G loss: 7.6] [G acc: 0.125]\n",
      "138 (5, 1) [D loss: (-9.8)] [D acc: (0.000)] [G loss: 14.6] [G acc: 0.000]\n",
      "139 (5, 1) [D loss: (-11.1)] [D acc: (0.000)] [G loss: 4.6] [G acc: 0.281]\n",
      "140 (5, 1) [D loss: (-12.0)] [D acc: (0.000)] [G loss: 8.0] [G acc: 0.125]\n",
      "141 (5, 1) [D loss: (-11.2)] [D acc: (0.000)] [G loss: 35.5] [G acc: 0.000]\n",
      "142 (5, 1) [D loss: (-12.6)] [D acc: (0.000)] [G loss: 3.3] [G acc: 0.344]\n",
      "143 (5, 1) [D loss: (-8.8)] [D acc: (0.000)] [G loss: 5.2] [G acc: 0.125]\n",
      "144 (5, 1) [D loss: (-10.3)] [D acc: (0.000)] [G loss: 7.3] [G acc: 0.062]\n",
      "145 (5, 1) [D loss: (-12.9)] [D acc: (0.000)] [G loss: 22.2] [G acc: 0.031]\n",
      "146 (5, 1) [D loss: (-12.4)] [D acc: (0.000)] [G loss: 17.5] [G acc: 0.000]\n",
      "147 (5, 1) [D loss: (-11.2)] [D acc: (0.000)] [G loss: 11.3] [G acc: 0.031]\n",
      "148 (5, 1) [D loss: (-9.5)] [D acc: (0.000)] [G loss: 13.0] [G acc: 0.000]\n",
      "149 (5, 1) [D loss: (-12.0)] [D acc: (0.000)] [G loss: 11.0] [G acc: 0.000]\n",
      "150 (5, 1) [D loss: (-10.6)] [D acc: (0.000)] [G loss: 10.5] [G acc: 0.062]\n",
      "151 (5, 1) [D loss: (-10.4)] [D acc: (0.000)] [G loss: 16.1] [G acc: 0.000]\n",
      "152 (5, 1) [D loss: (-10.7)] [D acc: (0.000)] [G loss: 15.6] [G acc: 0.031]\n",
      "153 (5, 1) [D loss: (-10.2)] [D acc: (0.000)] [G loss: -2.9] [G acc: 0.594]\n",
      "154 (5, 1) [D loss: (-9.5)] [D acc: (0.000)] [G loss: 10.3] [G acc: 0.031]\n",
      "155 (5, 1) [D loss: (-9.8)] [D acc: (0.000)] [G loss: 14.7] [G acc: 0.000]\n",
      "156 (5, 1) [D loss: (-11.1)] [D acc: (0.000)] [G loss: 4.4] [G acc: 0.375]\n",
      "157 (5, 1) [D loss: (-9.1)] [D acc: (0.000)] [G loss: -2.8] [G acc: 0.594]\n",
      "158 (5, 1) [D loss: (-7.5)] [D acc: (0.000)] [G loss: 14.7] [G acc: 0.000]\n",
      "159 (5, 1) [D loss: (-11.9)] [D acc: (0.000)] [G loss: -12.2] [G acc: 0.969]\n",
      "160 (5, 1) [D loss: (-10.5)] [D acc: (0.000)] [G loss: 16.9] [G acc: 0.062]\n",
      "161 (5, 1) [D loss: (-8.9)] [D acc: (0.000)] [G loss: 19.3] [G acc: 0.000]\n",
      "162 (5, 1) [D loss: (-11.8)] [D acc: (0.000)] [G loss: 9.8] [G acc: 0.000]\n",
      "163 (5, 1) [D loss: (-9.9)] [D acc: (0.000)] [G loss: 14.1] [G acc: 0.000]\n",
      "164 (5, 1) [D loss: (-10.8)] [D acc: (0.000)] [G loss: -4.0] [G acc: 0.750]\n",
      "165 (5, 1) [D loss: (-9.2)] [D acc: (0.000)] [G loss: 28.8] [G acc: 0.000]\n",
      "166 (5, 1) [D loss: (-9.7)] [D acc: (0.000)] [G loss: 12.9] [G acc: 0.000]\n",
      "167 (5, 1) [D loss: (-11.0)] [D acc: (0.000)] [G loss: 21.8] [G acc: 0.000]\n",
      "168 (5, 1) [D loss: (-10.9)] [D acc: (0.000)] [G loss: -3.3] [G acc: 0.531]\n",
      "169 (5, 1) [D loss: (-10.1)] [D acc: (0.000)] [G loss: 23.4] [G acc: 0.000]\n",
      "170 (5, 1) [D loss: (-8.2)] [D acc: (0.000)] [G loss: 23.3] [G acc: 0.000]\n",
      "171 (5, 1) [D loss: (-11.9)] [D acc: (0.000)] [G loss: 18.3] [G acc: 0.031]\n",
      "172 (5, 1) [D loss: (-11.6)] [D acc: (0.000)] [G loss: 3.9] [G acc: 0.219]\n",
      "173 (5, 1) [D loss: (-10.1)] [D acc: (0.000)] [G loss: 21.2] [G acc: 0.000]\n",
      "174 (5, 1) [D loss: (-7.9)] [D acc: (0.000)] [G loss: 10.9] [G acc: 0.219]\n",
      "175 (5, 1) [D loss: (-9.2)] [D acc: (0.000)] [G loss: -3.4] [G acc: 0.750]\n",
      "176 (5, 1) [D loss: (-11.9)] [D acc: (0.000)] [G loss: 21.8] [G acc: 0.000]\n",
      "177 (5, 1) [D loss: (-8.8)] [D acc: (0.000)] [G loss: 20.7] [G acc: 0.000]\n",
      "178 (5, 1) [D loss: (-8.7)] [D acc: (0.000)] [G loss: -4.2] [G acc: 0.750]\n",
      "179 (5, 1) [D loss: (-11.6)] [D acc: (0.000)] [G loss: 0.3] [G acc: 0.469]\n",
      "180 (5, 1) [D loss: (-11.1)] [D acc: (0.000)] [G loss: 21.0] [G acc: 0.000]\n",
      "181 (5, 1) [D loss: (-6.4)] [D acc: (0.000)] [G loss: 17.3] [G acc: 0.000]\n",
      "182 (5, 1) [D loss: (-10.0)] [D acc: (0.000)] [G loss: 6.8] [G acc: 0.031]\n",
      "183 (5, 1) [D loss: (-10.0)] [D acc: (0.000)] [G loss: 4.3] [G acc: 0.094]\n",
      "184 (5, 1) [D loss: (-7.3)] [D acc: (0.000)] [G loss: 26.9] [G acc: 0.000]\n",
      "185 (5, 1) [D loss: (-9.3)] [D acc: (0.000)] [G loss: 3.7] [G acc: 0.219]\n",
      "186 (5, 1) [D loss: (-11.8)] [D acc: (0.000)] [G loss: 17.8] [G acc: 0.031]\n",
      "187 (5, 1) [D loss: (-12.3)] [D acc: (0.000)] [G loss: 8.0] [G acc: 0.219]\n",
      "188 (5, 1) [D loss: (-10.0)] [D acc: (0.000)] [G loss: 5.8] [G acc: 0.094]\n",
      "189 (5, 1) [D loss: (-8.1)] [D acc: (0.000)] [G loss: 21.3] [G acc: 0.000]\n",
      "190 (5, 1) [D loss: (-9.0)] [D acc: (0.000)] [G loss: 9.3] [G acc: 0.000]\n",
      "191 (5, 1) [D loss: (-10.8)] [D acc: (0.000)] [G loss: 9.8] [G acc: 0.062]\n",
      "192 (5, 1) [D loss: (-9.2)] [D acc: (0.000)] [G loss: 8.6] [G acc: 0.250]\n",
      "193 (5, 1) [D loss: (-9.5)] [D acc: (0.000)] [G loss: 10.1] [G acc: 0.125]\n",
      "194 (5, 1) [D loss: (-9.4)] [D acc: (0.000)] [G loss: 6.6] [G acc: 0.062]\n",
      "195 (5, 1) [D loss: (-7.4)] [D acc: (0.000)] [G loss: 23.2] [G acc: 0.000]\n",
      "196 (5, 1) [D loss: (-7.8)] [D acc: (0.000)] [G loss: 13.9] [G acc: 0.000]\n",
      "197 (5, 1) [D loss: (-9.2)] [D acc: (0.000)] [G loss: 19.3] [G acc: 0.000]\n",
      "198 (5, 1) [D loss: (-10.1)] [D acc: (0.000)] [G loss: -2.2] [G acc: 0.688]\n",
      "199 (5, 1) [D loss: (-9.4)] [D acc: (0.000)] [G loss: 14.3] [G acc: 0.031]\n",
      "200 (5, 1) [D loss: (-10.4)] [D acc: (0.000)] [G loss: 14.6] [G acc: 0.000]\n",
      "201 (5, 1) [D loss: (-11.2)] [D acc: (0.000)] [G loss: 23.7] [G acc: 0.000]\n",
      "202 (5, 1) [D loss: (-7.9)] [D acc: (0.000)] [G loss: 20.9] [G acc: 0.000]\n",
      "203 (5, 1) [D loss: (-8.0)] [D acc: (0.000)] [G loss: 6.9] [G acc: 0.062]\n",
      "204 (5, 1) [D loss: (-8.3)] [D acc: (0.000)] [G loss: 14.6] [G acc: 0.156]\n",
      "205 (5, 1) [D loss: (-9.5)] [D acc: (0.000)] [G loss: 4.5] [G acc: 0.250]\n",
      "206 (5, 1) [D loss: (-7.9)] [D acc: (0.000)] [G loss: 13.4] [G acc: 0.000]\n",
      "207 (5, 1) [D loss: (-11.3)] [D acc: (0.000)] [G loss: 17.1] [G acc: 0.000]\n",
      "208 (5, 1) [D loss: (-9.2)] [D acc: (0.000)] [G loss: 17.3] [G acc: 0.031]\n",
      "209 (5, 1) [D loss: (-7.3)] [D acc: (0.000)] [G loss: 10.7] [G acc: 0.000]\n",
      "210 (5, 1) [D loss: (-7.3)] [D acc: (0.000)] [G loss: 10.4] [G acc: 0.000]\n",
      "211 (5, 1) [D loss: (-9.4)] [D acc: (0.000)] [G loss: 14.4] [G acc: 0.000]\n",
      "212 (5, 1) [D loss: (-8.3)] [D acc: (0.000)] [G loss: 13.2] [G acc: 0.000]\n",
      "213 (5, 1) [D loss: (-8.7)] [D acc: (0.000)] [G loss: 12.4] [G acc: 0.031]\n",
      "214 (5, 1) [D loss: (-7.6)] [D acc: (0.000)] [G loss: 27.7] [G acc: 0.000]\n",
      "215 (5, 1) [D loss: (-7.7)] [D acc: (0.000)] [G loss: -5.3] [G acc: 0.656]\n",
      "216 (5, 1) [D loss: (-8.8)] [D acc: (0.000)] [G loss: 25.4] [G acc: 0.000]\n",
      "217 (5, 1) [D loss: (-12.9)] [D acc: (0.000)] [G loss: 14.7] [G acc: 0.156]\n",
      "218 (5, 1) [D loss: (-7.2)] [D acc: (0.000)] [G loss: 20.2] [G acc: 0.000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "219 (5, 1) [D loss: (-6.7)] [D acc: (0.000)] [G loss: 12.6] [G acc: 0.000]\n",
      "220 (5, 1) [D loss: (-7.3)] [D acc: (0.000)] [G loss: 13.1] [G acc: 0.000]\n",
      "221 (5, 1) [D loss: (-8.9)] [D acc: (0.000)] [G loss: 19.8] [G acc: 0.000]\n",
      "222 (5, 1) [D loss: (-10.3)] [D acc: (0.000)] [G loss: 4.7] [G acc: 0.219]\n",
      "223 (5, 1) [D loss: (-9.8)] [D acc: (0.000)] [G loss: 20.5] [G acc: 0.000]\n",
      "224 (5, 1) [D loss: (-7.8)] [D acc: (0.000)] [G loss: 19.1] [G acc: 0.000]\n",
      "225 (5, 1) [D loss: (-10.0)] [D acc: (0.000)] [G loss: -5.2] [G acc: 0.969]\n",
      "226 (5, 1) [D loss: (-8.9)] [D acc: (0.000)] [G loss: 41.8] [G acc: 0.000]\n",
      "227 (5, 1) [D loss: (-8.6)] [D acc: (0.000)] [G loss: -5.0] [G acc: 0.750]\n",
      "228 (5, 1) [D loss: (-3.6)] [D acc: (0.000)] [G loss: 16.1] [G acc: 0.000]\n",
      "229 (5, 1) [D loss: (-10.7)] [D acc: (0.000)] [G loss: 36.3] [G acc: 0.000]\n",
      "230 (5, 1) [D loss: (-6.0)] [D acc: (0.000)] [G loss: 2.5] [G acc: 0.438]\n",
      "231 (5, 1) [D loss: (-6.8)] [D acc: (0.000)] [G loss: 5.2] [G acc: 0.094]\n",
      "232 (5, 1) [D loss: (-7.5)] [D acc: (0.000)] [G loss: 15.1] [G acc: 0.000]\n",
      "233 (5, 1) [D loss: (-6.3)] [D acc: (0.000)] [G loss: 5.8] [G acc: 0.031]\n",
      "234 (5, 1) [D loss: (-6.9)] [D acc: (0.000)] [G loss: 14.4] [G acc: 0.000]\n",
      "235 (5, 1) [D loss: (-8.9)] [D acc: (0.000)] [G loss: 4.5] [G acc: 0.188]\n",
      "236 (5, 1) [D loss: (-8.6)] [D acc: (0.000)] [G loss: 11.8] [G acc: 0.031]\n",
      "237 (5, 1) [D loss: (-8.0)] [D acc: (0.000)] [G loss: 5.3] [G acc: 0.125]\n",
      "238 (5, 1) [D loss: (-7.3)] [D acc: (0.000)] [G loss: 5.4] [G acc: 0.312]\n",
      "239 (5, 1) [D loss: (-9.9)] [D acc: (0.000)] [G loss: 6.0] [G acc: 0.156]\n",
      "240 (5, 1) [D loss: (-7.4)] [D acc: (0.000)] [G loss: 5.4] [G acc: 0.188]\n",
      "241 (5, 1) [D loss: (-5.8)] [D acc: (0.000)] [G loss: 17.5] [G acc: 0.000]\n",
      "242 (5, 1) [D loss: (-8.7)] [D acc: (0.000)] [G loss: 27.1] [G acc: 0.000]\n",
      "243 (5, 1) [D loss: (-8.9)] [D acc: (0.000)] [G loss: 18.9] [G acc: 0.000]\n",
      "244 (5, 1) [D loss: (-5.0)] [D acc: (0.000)] [G loss: 9.6] [G acc: 0.094]\n",
      "245 (5, 1) [D loss: (-8.8)] [D acc: (0.000)] [G loss: 18.9] [G acc: 0.000]\n",
      "246 (5, 1) [D loss: (-8.6)] [D acc: (0.000)] [G loss: 21.3] [G acc: 0.031]\n",
      "247 (5, 1) [D loss: (-4.3)] [D acc: (0.000)] [G loss: 11.2] [G acc: 0.000]\n",
      "248 (5, 1) [D loss: (-7.7)] [D acc: (0.000)] [G loss: 27.6] [G acc: 0.000]\n",
      "249 (5, 1) [D loss: (-9.2)] [D acc: (0.000)] [G loss: -8.4] [G acc: 0.719]\n",
      "250 (5, 1) [D loss: (-7.3)] [D acc: (0.000)] [G loss: 3.6] [G acc: 0.281]\n",
      "251 (5, 1) [D loss: (-6.9)] [D acc: (0.000)] [G loss: 1.5] [G acc: 0.375]\n",
      "252 (5, 1) [D loss: (-6.0)] [D acc: (0.000)] [G loss: 21.6] [G acc: 0.000]\n",
      "253 (5, 1) [D loss: (-9.7)] [D acc: (0.000)] [G loss: 16.8] [G acc: 0.000]\n",
      "254 (5, 1) [D loss: (-3.4)] [D acc: (0.000)] [G loss: 14.9] [G acc: 0.125]\n",
      "255 (5, 1) [D loss: (-6.0)] [D acc: (0.000)] [G loss: 14.6] [G acc: 0.000]\n",
      "256 (5, 1) [D loss: (-9.0)] [D acc: (0.000)] [G loss: 25.3] [G acc: 0.000]\n",
      "257 (5, 1) [D loss: (-5.8)] [D acc: (0.000)] [G loss: 24.1] [G acc: 0.000]\n",
      "258 (5, 1) [D loss: (-6.1)] [D acc: (0.000)] [G loss: 17.5] [G acc: 0.125]\n",
      "259 (5, 1) [D loss: (-6.3)] [D acc: (0.000)] [G loss: 13.3] [G acc: 0.031]\n",
      "260 (5, 1) [D loss: (-6.1)] [D acc: (0.000)] [G loss: 13.1] [G acc: 0.000]\n",
      "261 (5, 1) [D loss: (-9.7)] [D acc: (0.000)] [G loss: 5.8] [G acc: 0.312]\n",
      "262 (5, 1) [D loss: (-9.8)] [D acc: (0.000)] [G loss: 28.7] [G acc: 0.000]\n",
      "263 (5, 1) [D loss: (-7.7)] [D acc: (0.000)] [G loss: 7.4] [G acc: 0.188]\n",
      "264 (5, 1) [D loss: (-7.4)] [D acc: (0.000)] [G loss: 11.6] [G acc: 0.031]\n",
      "265 (5, 1) [D loss: (-8.5)] [D acc: (0.000)] [G loss: -12.5] [G acc: 1.000]\n",
      "266 (5, 1) [D loss: (-7.8)] [D acc: (0.000)] [G loss: 29.2] [G acc: 0.000]\n",
      "267 (5, 1) [D loss: (-8.6)] [D acc: (0.000)] [G loss: 21.4] [G acc: 0.000]\n",
      "268 (5, 1) [D loss: (-7.0)] [D acc: (0.000)] [G loss: 36.0] [G acc: 0.000]\n",
      "269 (5, 1) [D loss: (-7.4)] [D acc: (0.000)] [G loss: 17.2] [G acc: 0.062]\n",
      "270 (5, 1) [D loss: (-8.3)] [D acc: (0.000)] [G loss: 20.5] [G acc: 0.062]\n",
      "271 (5, 1) [D loss: (-8.0)] [D acc: (0.000)] [G loss: 17.3] [G acc: 0.094]\n",
      "272 (5, 1) [D loss: (-10.2)] [D acc: (0.000)] [G loss: 12.0] [G acc: 0.188]\n",
      "273 (5, 1) [D loss: (-5.3)] [D acc: (0.000)] [G loss: -4.3] [G acc: 0.625]\n",
      "274 (5, 1) [D loss: (-7.4)] [D acc: (0.000)] [G loss: 12.3] [G acc: 0.219]\n",
      "275 (5, 1) [D loss: (-7.6)] [D acc: (0.000)] [G loss: 15.5] [G acc: 0.062]\n",
      "276 (5, 1) [D loss: (-7.8)] [D acc: (0.000)] [G loss: 12.0] [G acc: 0.062]\n",
      "277 (5, 1) [D loss: (-9.8)] [D acc: (0.000)] [G loss: 8.0] [G acc: 0.062]\n",
      "278 (5, 1) [D loss: (-2.6)] [D acc: (0.000)] [G loss: 22.9] [G acc: 0.000]\n",
      "279 (5, 1) [D loss: (-10.0)] [D acc: (0.000)] [G loss: 0.9] [G acc: 0.500]\n",
      "280 (5, 1) [D loss: (-4.3)] [D acc: (0.000)] [G loss: 23.9] [G acc: 0.000]\n",
      "281 (5, 1) [D loss: (-8.9)] [D acc: (0.000)] [G loss: 30.1] [G acc: 0.000]\n",
      "282 (5, 1) [D loss: (-7.9)] [D acc: (0.000)] [G loss: 18.6] [G acc: 0.000]\n",
      "283 (5, 1) [D loss: (-6.9)] [D acc: (0.000)] [G loss: 16.2] [G acc: 0.000]\n",
      "284 (5, 1) [D loss: (-5.4)] [D acc: (0.000)] [G loss: 4.5] [G acc: 0.281]\n",
      "285 (5, 1) [D loss: (-6.9)] [D acc: (0.000)] [G loss: 40.5] [G acc: 0.000]\n",
      "286 (5, 1) [D loss: (-8.6)] [D acc: (0.000)] [G loss: 5.4] [G acc: 0.062]\n",
      "287 (5, 1) [D loss: (-5.9)] [D acc: (0.000)] [G loss: 25.5] [G acc: 0.000]\n",
      "288 (5, 1) [D loss: (-6.8)] [D acc: (0.000)] [G loss: 9.5] [G acc: 0.094]\n",
      "289 (5, 1) [D loss: (-7.2)] [D acc: (0.000)] [G loss: 21.5] [G acc: 0.000]\n",
      "290 (5, 1) [D loss: (-6.3)] [D acc: (0.000)] [G loss: -6.3] [G acc: 0.812]\n",
      "291 (5, 1) [D loss: (-8.0)] [D acc: (0.000)] [G loss: 18.1] [G acc: 0.000]\n",
      "292 (5, 1) [D loss: (-6.6)] [D acc: (0.000)] [G loss: 0.7] [G acc: 0.438]\n",
      "293 (5, 1) [D loss: (-7.0)] [D acc: (0.000)] [G loss: 9.3] [G acc: 0.031]\n",
      "294 (5, 1) [D loss: (-5.9)] [D acc: (0.000)] [G loss: 17.8] [G acc: 0.000]\n",
      "295 (5, 1) [D loss: (-9.2)] [D acc: (0.000)] [G loss: 1.9] [G acc: 0.375]\n",
      "296 (5, 1) [D loss: (-9.0)] [D acc: (0.000)] [G loss: 27.6] [G acc: 0.000]\n",
      "297 (5, 1) [D loss: (-7.9)] [D acc: (0.000)] [G loss: 21.8] [G acc: 0.000]\n",
      "298 (5, 1) [D loss: (-5.5)] [D acc: (0.000)] [G loss: 6.8] [G acc: 0.062]\n",
      "299 (5, 1) [D loss: (-8.7)] [D acc: (0.000)] [G loss: 15.9] [G acc: 0.031]\n",
      "300 (5, 1) [D loss: (-8.2)] [D acc: (0.000)] [G loss: 39.1] [G acc: 0.000]\n",
      "301 (5, 1) [D loss: (-6.6)] [D acc: (0.000)] [G loss: 30.9] [G acc: 0.000]\n",
      "302 (5, 1) [D loss: (-6.2)] [D acc: (0.000)] [G loss: 37.8] [G acc: 0.000]\n",
      "303 (5, 1) [D loss: (-12.1)] [D acc: (0.000)] [G loss: 2.7] [G acc: 0.500]\n",
      "304 (5, 1) [D loss: (-8.5)] [D acc: (0.000)] [G loss: 10.2] [G acc: 0.062]\n",
      "305 (5, 1) [D loss: (-7.4)] [D acc: (0.000)] [G loss: 10.5] [G acc: 0.219]\n",
      "306 (5, 1) [D loss: (-7.5)] [D acc: (0.000)] [G loss: 13.1] [G acc: 0.125]\n",
      "307 (5, 1) [D loss: (-8.5)] [D acc: (0.000)] [G loss: 28.3] [G acc: 0.000]\n",
      "308 (5, 1) [D loss: (-3.7)] [D acc: (0.000)] [G loss: 12.9] [G acc: 0.094]\n",
      "309 (5, 1) [D loss: (-5.9)] [D acc: (0.000)] [G loss: 36.7] [G acc: 0.000]\n",
      "310 (5, 1) [D loss: (-8.6)] [D acc: (0.000)] [G loss: 15.0] [G acc: 0.031]\n",
      "311 (5, 1) [D loss: (-7.1)] [D acc: (0.000)] [G loss: 14.2] [G acc: 0.188]\n",
      "312 (5, 1) [D loss: (-6.5)] [D acc: (0.000)] [G loss: 27.8] [G acc: 0.000]\n",
      "313 (5, 1) [D loss: (-6.8)] [D acc: (0.000)] [G loss: 29.4] [G acc: 0.000]\n",
      "314 (5, 1) [D loss: (-8.8)] [D acc: (0.000)] [G loss: 27.6] [G acc: 0.000]\n",
      "315 (5, 1) [D loss: (-7.5)] [D acc: (0.000)] [G loss: 4.4] [G acc: 0.250]\n",
      "316 (5, 1) [D loss: (-4.0)] [D acc: (0.000)] [G loss: 5.6] [G acc: 0.156]\n",
      "317 (5, 1) [D loss: (-4.2)] [D acc: (0.000)] [G loss: 21.0] [G acc: 0.000]\n",
      "318 (5, 1) [D loss: (-8.8)] [D acc: (0.000)] [G loss: 21.0] [G acc: 0.000]\n",
      "319 (5, 1) [D loss: (-6.4)] [D acc: (0.000)] [G loss: 22.8] [G acc: 0.000]\n",
      "320 (5, 1) [D loss: (-8.2)] [D acc: (0.000)] [G loss: 43.2] [G acc: 0.000]\n",
      "321 (5, 1) [D loss: (-5.2)] [D acc: (0.000)] [G loss: 3.5] [G acc: 0.250]\n",
      "322 (5, 1) [D loss: (-7.9)] [D acc: (0.000)] [G loss: 2.7] [G acc: 0.375]\n",
      "323 (5, 1) [D loss: (-6.8)] [D acc: (0.000)] [G loss: 25.0] [G acc: 0.000]\n",
      "324 (5, 1) [D loss: (-12.1)] [D acc: (0.000)] [G loss: 41.7] [G acc: 0.000]\n",
      "325 (5, 1) [D loss: (-2.0)] [D acc: (0.000)] [G loss: 19.8] [G acc: 0.000]\n",
      "326 (5, 1) [D loss: (-5.5)] [D acc: (0.000)] [G loss: 15.3] [G acc: 0.000]\n",
      "327 (5, 1) [D loss: (-8.9)] [D acc: (0.000)] [G loss: 11.7] [G acc: 0.188]\n",
      "328 (5, 1) [D loss: (-4.6)] [D acc: (0.000)] [G loss: 18.7] [G acc: 0.000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "329 (5, 1) [D loss: (-7.5)] [D acc: (0.000)] [G loss: 14.0] [G acc: 0.000]\n",
      "330 (5, 1) [D loss: (-6.9)] [D acc: (0.000)] [G loss: 26.9] [G acc: 0.000]\n",
      "331 (5, 1) [D loss: (-6.0)] [D acc: (0.000)] [G loss: 17.6] [G acc: 0.000]\n",
      "332 (5, 1) [D loss: (-8.0)] [D acc: (0.000)] [G loss: 18.0] [G acc: 0.156]\n",
      "333 (5, 1) [D loss: (-6.5)] [D acc: (0.000)] [G loss: 20.8] [G acc: 0.000]\n",
      "334 (5, 1) [D loss: (-7.0)] [D acc: (0.000)] [G loss: 59.1] [G acc: 0.000]\n",
      "335 (5, 1) [D loss: (-6.8)] [D acc: (0.000)] [G loss: 2.3] [G acc: 0.438]\n",
      "336 (5, 1) [D loss: (-8.6)] [D acc: (0.000)] [G loss: 26.8] [G acc: 0.000]\n",
      "337 (5, 1) [D loss: (-8.8)] [D acc: (0.000)] [G loss: 25.0] [G acc: 0.000]\n",
      "338 (5, 1) [D loss: (-8.8)] [D acc: (0.000)] [G loss: -7.3] [G acc: 0.844]\n",
      "339 (5, 1) [D loss: (-5.8)] [D acc: (0.000)] [G loss: 12.6] [G acc: 0.156]\n",
      "340 (5, 1) [D loss: (-6.6)] [D acc: (0.000)] [G loss: 7.2] [G acc: 0.156]\n",
      "341 (5, 1) [D loss: (-6.9)] [D acc: (0.000)] [G loss: 9.0] [G acc: 0.188]\n",
      "342 (5, 1) [D loss: (-6.1)] [D acc: (0.000)] [G loss: 24.3] [G acc: 0.000]\n",
      "343 (5, 1) [D loss: (-5.3)] [D acc: (0.000)] [G loss: 15.8] [G acc: 0.000]\n",
      "344 (5, 1) [D loss: (-6.7)] [D acc: (0.000)] [G loss: 3.2] [G acc: 0.312]\n",
      "345 (5, 1) [D loss: (-7.1)] [D acc: (0.000)] [G loss: 26.7] [G acc: 0.000]\n",
      "346 (5, 1) [D loss: (-5.4)] [D acc: (0.000)] [G loss: 19.5] [G acc: 0.000]\n",
      "347 (5, 1) [D loss: (-5.5)] [D acc: (0.000)] [G loss: 43.0] [G acc: 0.000]\n",
      "348 (5, 1) [D loss: (-5.2)] [D acc: (0.000)] [G loss: 29.0] [G acc: 0.000]\n",
      "349 (5, 1) [D loss: (-7.4)] [D acc: (0.000)] [G loss: 21.3] [G acc: 0.094]\n",
      "350 (5, 1) [D loss: (-7.5)] [D acc: (0.000)] [G loss: 36.7] [G acc: 0.000]\n",
      "351 (5, 1) [D loss: (-7.1)] [D acc: (0.000)] [G loss: 14.4] [G acc: 0.000]\n",
      "352 (5, 1) [D loss: (-10.1)] [D acc: (0.000)] [G loss: 17.3] [G acc: 0.156]\n",
      "353 (5, 1) [D loss: (-5.2)] [D acc: (0.000)] [G loss: 22.2] [G acc: 0.000]\n",
      "354 (5, 1) [D loss: (-7.3)] [D acc: (0.000)] [G loss: 10.1] [G acc: 0.219]\n",
      "355 (5, 1) [D loss: (-5.2)] [D acc: (0.000)] [G loss: 0.4] [G acc: 0.469]\n",
      "356 (5, 1) [D loss: (-10.9)] [D acc: (0.000)] [G loss: 24.3] [G acc: 0.031]\n",
      "357 (5, 1) [D loss: (-8.7)] [D acc: (0.000)] [G loss: 9.3] [G acc: 0.188]\n",
      "358 (5, 1) [D loss: (-7.9)] [D acc: (0.000)] [G loss: 36.8] [G acc: 0.000]\n",
      "359 (5, 1) [D loss: (-6.2)] [D acc: (0.000)] [G loss: 16.3] [G acc: 0.094]\n",
      "360 (5, 1) [D loss: (-5.0)] [D acc: (0.000)] [G loss: 19.9] [G acc: 0.000]\n",
      "361 (5, 1) [D loss: (-6.2)] [D acc: (0.000)] [G loss: 25.6] [G acc: 0.000]\n",
      "362 (5, 1) [D loss: (-8.3)] [D acc: (0.000)] [G loss: 30.3] [G acc: 0.031]\n",
      "363 (5, 1) [D loss: (-5.9)] [D acc: (0.000)] [G loss: 29.3] [G acc: 0.000]\n",
      "364 (5, 1) [D loss: (-4.8)] [D acc: (0.000)] [G loss: 9.8] [G acc: 0.062]\n",
      "365 (5, 1) [D loss: (-7.3)] [D acc: (0.000)] [G loss: 32.8] [G acc: 0.000]\n",
      "366 (5, 1) [D loss: (-5.6)] [D acc: (0.000)] [G loss: 8.4] [G acc: 0.281]\n",
      "367 (5, 1) [D loss: (-7.1)] [D acc: (0.000)] [G loss: 26.2] [G acc: 0.000]\n",
      "368 (5, 1) [D loss: (-6.1)] [D acc: (0.000)] [G loss: 7.6] [G acc: 0.156]\n",
      "369 (5, 1) [D loss: (-6.8)] [D acc: (0.000)] [G loss: 20.8] [G acc: 0.000]\n",
      "370 (5, 1) [D loss: (-6.0)] [D acc: (0.000)] [G loss: 20.5] [G acc: 0.000]\n",
      "371 (5, 1) [D loss: (-7.8)] [D acc: (0.000)] [G loss: 16.3] [G acc: 0.250]\n",
      "372 (5, 1) [D loss: (-6.6)] [D acc: (0.000)] [G loss: 28.1] [G acc: 0.000]\n",
      "373 (5, 1) [D loss: (-0.7)] [D acc: (0.000)] [G loss: 19.7] [G acc: 0.000]\n",
      "374 (5, 1) [D loss: (-4.5)] [D acc: (0.000)] [G loss: 29.8] [G acc: 0.000]\n",
      "375 (5, 1) [D loss: (-2.2)] [D acc: (0.000)] [G loss: 6.1] [G acc: 0.219]\n",
      "376 (5, 1) [D loss: (-4.2)] [D acc: (0.000)] [G loss: 2.1] [G acc: 0.344]\n",
      "377 (5, 1) [D loss: (-5.9)] [D acc: (0.000)] [G loss: 25.7] [G acc: 0.000]\n",
      "378 (5, 1) [D loss: (-5.4)] [D acc: (0.000)] [G loss: 35.8] [G acc: 0.000]\n",
      "379 (5, 1) [D loss: (-7.3)] [D acc: (0.000)] [G loss: 2.7] [G acc: 0.438]\n",
      "380 (5, 1) [D loss: (-2.8)] [D acc: (0.000)] [G loss: 12.8] [G acc: 0.000]\n",
      "381 (5, 1) [D loss: (-7.2)] [D acc: (0.000)] [G loss: 8.2] [G acc: 0.156]\n",
      "382 (5, 1) [D loss: (-5.7)] [D acc: (0.000)] [G loss: 0.7] [G acc: 0.469]\n",
      "383 (5, 1) [D loss: (-6.6)] [D acc: (0.000)] [G loss: 11.5] [G acc: 0.125]\n",
      "384 (5, 1) [D loss: (-7.9)] [D acc: (0.000)] [G loss: 17.7] [G acc: 0.094]\n",
      "385 (5, 1) [D loss: (-3.9)] [D acc: (0.000)] [G loss: 33.6] [G acc: 0.000]\n",
      "386 (5, 1) [D loss: (-6.1)] [D acc: (0.000)] [G loss: 38.2] [G acc: 0.000]\n",
      "387 (5, 1) [D loss: (-7.2)] [D acc: (0.000)] [G loss: 37.8] [G acc: 0.000]\n",
      "388 (5, 1) [D loss: (-7.0)] [D acc: (0.000)] [G loss: -2.0] [G acc: 0.688]\n",
      "389 (5, 1) [D loss: (-9.7)] [D acc: (0.000)] [G loss: 21.1] [G acc: 0.094]\n",
      "390 (5, 1) [D loss: (-7.9)] [D acc: (0.000)] [G loss: 16.4] [G acc: 0.062]\n",
      "391 (5, 1) [D loss: (-7.9)] [D acc: (0.000)] [G loss: 0.8] [G acc: 0.375]\n",
      "392 (5, 1) [D loss: (-9.9)] [D acc: (0.000)] [G loss: 19.8] [G acc: 0.125]\n",
      "393 (5, 1) [D loss: (-3.6)] [D acc: (0.000)] [G loss: 30.0] [G acc: 0.000]\n",
      "394 (5, 1) [D loss: (-5.2)] [D acc: (0.000)] [G loss: 11.7] [G acc: 0.156]\n",
      "395 (5, 1) [D loss: (-6.1)] [D acc: (0.000)] [G loss: 26.7] [G acc: 0.000]\n",
      "396 (5, 1) [D loss: (-6.6)] [D acc: (0.000)] [G loss: 10.1] [G acc: 0.281]\n",
      "397 (5, 1) [D loss: (-5.6)] [D acc: (0.000)] [G loss: 40.2] [G acc: 0.000]\n",
      "398 (5, 1) [D loss: (-6.2)] [D acc: (0.000)] [G loss: 34.0] [G acc: 0.000]\n",
      "399 (5, 1) [D loss: (-6.0)] [D acc: (0.000)] [G loss: 2.2] [G acc: 0.312]\n",
      "400 (5, 1) [D loss: (-3.6)] [D acc: (0.000)] [G loss: 33.5] [G acc: 0.000]\n",
      "401 (5, 1) [D loss: (-6.2)] [D acc: (0.000)] [G loss: 5.2] [G acc: 0.188]\n",
      "402 (5, 1) [D loss: (-6.4)] [D acc: (0.000)] [G loss: 9.3] [G acc: 0.062]\n",
      "403 (5, 1) [D loss: (-5.3)] [D acc: (0.000)] [G loss: 8.4] [G acc: 0.250]\n",
      "404 (5, 1) [D loss: (-6.9)] [D acc: (0.000)] [G loss: 11.1] [G acc: 0.156]\n",
      "405 (5, 1) [D loss: (-7.0)] [D acc: (0.000)] [G loss: 28.7] [G acc: 0.000]\n",
      "406 (5, 1) [D loss: (-7.4)] [D acc: (0.000)] [G loss: 21.1] [G acc: 0.000]\n",
      "407 (5, 1) [D loss: (-7.6)] [D acc: (0.000)] [G loss: 3.7] [G acc: 0.312]\n",
      "408 (5, 1) [D loss: (-8.5)] [D acc: (0.000)] [G loss: -12.8] [G acc: 0.750]\n",
      "409 (5, 1) [D loss: (-5.1)] [D acc: (0.000)] [G loss: -3.7] [G acc: 0.656]\n",
      "410 (5, 1) [D loss: (-5.9)] [D acc: (0.000)] [G loss: 32.4] [G acc: 0.000]\n",
      "411 (5, 1) [D loss: (-5.4)] [D acc: (0.000)] [G loss: 20.1] [G acc: 0.000]\n",
      "412 (5, 1) [D loss: (-6.0)] [D acc: (0.000)] [G loss: 36.9] [G acc: 0.000]\n",
      "413 (5, 1) [D loss: (-5.7)] [D acc: (0.000)] [G loss: 20.8] [G acc: 0.000]\n",
      "414 (5, 1) [D loss: (-7.2)] [D acc: (0.000)] [G loss: 18.3] [G acc: 0.000]\n",
      "415 (5, 1) [D loss: (-7.3)] [D acc: (0.000)] [G loss: 16.9] [G acc: 0.000]\n",
      "416 (5, 1) [D loss: (-3.9)] [D acc: (0.000)] [G loss: 26.7] [G acc: 0.000]\n",
      "417 (5, 1) [D loss: (-4.1)] [D acc: (0.000)] [G loss: 10.8] [G acc: 0.031]\n",
      "418 (5, 1) [D loss: (-7.0)] [D acc: (0.000)] [G loss: 7.5] [G acc: 0.219]\n",
      "419 (5, 1) [D loss: (-3.4)] [D acc: (0.000)] [G loss: 15.1] [G acc: 0.031]\n",
      "420 (5, 1) [D loss: (-8.5)] [D acc: (0.000)] [G loss: 12.2] [G acc: 0.281]\n",
      "421 (5, 1) [D loss: (-4.5)] [D acc: (0.000)] [G loss: 20.2] [G acc: 0.000]\n",
      "422 (5, 1) [D loss: (-9.6)] [D acc: (0.000)] [G loss: 6.5] [G acc: 0.438]\n",
      "423 (5, 1) [D loss: (-5.0)] [D acc: (0.000)] [G loss: 16.7] [G acc: 0.125]\n",
      "424 (5, 1) [D loss: (-6.7)] [D acc: (0.000)] [G loss: 30.3] [G acc: 0.000]\n",
      "425 (5, 1) [D loss: (-2.7)] [D acc: (0.000)] [G loss: 15.0] [G acc: 0.094]\n",
      "426 (5, 1) [D loss: (-5.9)] [D acc: (0.000)] [G loss: 29.9] [G acc: 0.000]\n",
      "427 (5, 1) [D loss: (-5.3)] [D acc: (0.000)] [G loss: -5.5] [G acc: 0.719]\n",
      "428 (5, 1) [D loss: (-6.2)] [D acc: (0.000)] [G loss: 5.3] [G acc: 0.219]\n",
      "429 (5, 1) [D loss: (-7.1)] [D acc: (0.000)] [G loss: 29.8] [G acc: 0.000]\n",
      "430 (5, 1) [D loss: (-3.9)] [D acc: (0.000)] [G loss: 9.1] [G acc: 0.125]\n",
      "431 (5, 1) [D loss: (-3.9)] [D acc: (0.000)] [G loss: 29.2] [G acc: 0.000]\n",
      "432 (5, 1) [D loss: (-6.2)] [D acc: (0.000)] [G loss: 7.9] [G acc: 0.219]\n",
      "433 (5, 1) [D loss: (-4.5)] [D acc: (0.000)] [G loss: 19.6] [G acc: 0.000]\n",
      "434 (5, 1) [D loss: (-6.5)] [D acc: (0.000)] [G loss: 5.1] [G acc: 0.344]\n",
      "435 (5, 1) [D loss: (-4.4)] [D acc: (0.000)] [G loss: 13.4] [G acc: 0.031]\n",
      "436 (5, 1) [D loss: (-6.3)] [D acc: (0.000)] [G loss: 33.2] [G acc: 0.000]\n",
      "437 (5, 1) [D loss: (-5.9)] [D acc: (0.000)] [G loss: 17.3] [G acc: 0.156]\n",
      "438 (5, 1) [D loss: (-4.6)] [D acc: (0.000)] [G loss: 12.3] [G acc: 0.094]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "439 (5, 1) [D loss: (-6.2)] [D acc: (0.000)] [G loss: 27.5] [G acc: 0.000]\n",
      "440 (5, 1) [D loss: (-6.0)] [D acc: (0.000)] [G loss: 4.1] [G acc: 0.344]\n",
      "441 (5, 1) [D loss: (-5.9)] [D acc: (0.000)] [G loss: 12.0] [G acc: 0.188]\n",
      "442 (5, 1) [D loss: (-5.6)] [D acc: (0.000)] [G loss: 16.5] [G acc: 0.000]\n",
      "443 (5, 1) [D loss: (-7.5)] [D acc: (0.000)] [G loss: 27.1] [G acc: 0.000]\n",
      "444 (5, 1) [D loss: (-4.0)] [D acc: (0.000)] [G loss: 17.0] [G acc: 0.000]\n",
      "445 (5, 1) [D loss: (-6.2)] [D acc: (0.000)] [G loss: 24.9] [G acc: 0.000]\n",
      "446 (5, 1) [D loss: (-8.6)] [D acc: (0.000)] [G loss: 12.0] [G acc: 0.156]\n",
      "447 (5, 1) [D loss: (-6.1)] [D acc: (0.000)] [G loss: 11.4] [G acc: 0.188]\n",
      "448 (5, 1) [D loss: (-5.1)] [D acc: (0.000)] [G loss: 1.6] [G acc: 0.406]\n",
      "449 (5, 1) [D loss: (-6.9)] [D acc: (0.000)] [G loss: 14.1] [G acc: 0.031]\n",
      "450 (5, 1) [D loss: (-3.7)] [D acc: (0.000)] [G loss: 20.1] [G acc: 0.000]\n",
      "451 (5, 1) [D loss: (-9.1)] [D acc: (0.000)] [G loss: 4.1] [G acc: 0.375]\n",
      "452 (5, 1) [D loss: (-5.8)] [D acc: (0.000)] [G loss: 21.3] [G acc: 0.000]\n",
      "453 (5, 1) [D loss: (-3.9)] [D acc: (0.000)] [G loss: 3.8] [G acc: 0.250]\n",
      "454 (5, 1) [D loss: (-6.6)] [D acc: (0.000)] [G loss: 11.4] [G acc: 0.000]\n",
      "455 (5, 1) [D loss: (-3.1)] [D acc: (0.000)] [G loss: 23.8] [G acc: 0.000]\n",
      "456 (5, 1) [D loss: (-7.2)] [D acc: (0.000)] [G loss: 28.6] [G acc: 0.000]\n",
      "457 (5, 1) [D loss: (-7.1)] [D acc: (0.000)] [G loss: 13.8] [G acc: 0.188]\n",
      "458 (5, 1) [D loss: (-8.4)] [D acc: (0.000)] [G loss: 15.9] [G acc: 0.250]\n",
      "459 (5, 1) [D loss: (-4.7)] [D acc: (0.000)] [G loss: 15.7] [G acc: 0.000]\n",
      "460 (5, 1) [D loss: (-5.7)] [D acc: (0.000)] [G loss: 14.4] [G acc: 0.000]\n",
      "461 (5, 1) [D loss: (-7.4)] [D acc: (0.000)] [G loss: 16.5] [G acc: 0.062]\n",
      "462 (5, 1) [D loss: (-11.2)] [D acc: (0.000)] [G loss: 9.1] [G acc: 0.344]\n",
      "463 (5, 1) [D loss: (-6.9)] [D acc: (0.000)] [G loss: 28.5] [G acc: 0.000]\n",
      "464 (5, 1) [D loss: (-6.8)] [D acc: (0.000)] [G loss: 0.4] [G acc: 0.469]\n",
      "465 (5, 1) [D loss: (-6.1)] [D acc: (0.000)] [G loss: 23.7] [G acc: 0.000]\n",
      "466 (5, 1) [D loss: (-5.3)] [D acc: (0.000)] [G loss: 13.0] [G acc: 0.000]\n",
      "467 (5, 1) [D loss: (-2.2)] [D acc: (0.000)] [G loss: 3.0] [G acc: 0.375]\n",
      "468 (5, 1) [D loss: (-6.5)] [D acc: (0.000)] [G loss: 17.8] [G acc: 0.156]\n",
      "469 (5, 1) [D loss: (-6.7)] [D acc: (0.000)] [G loss: 11.8] [G acc: 0.031]\n",
      "470 (5, 1) [D loss: (-4.5)] [D acc: (0.000)] [G loss: 24.2] [G acc: 0.000]\n",
      "471 (5, 1) [D loss: (-6.4)] [D acc: (0.000)] [G loss: 34.5] [G acc: 0.000]\n",
      "472 (5, 1) [D loss: (-6.6)] [D acc: (0.000)] [G loss: 8.6] [G acc: 0.125]\n",
      "473 (5, 1) [D loss: (-6.0)] [D acc: (0.000)] [G loss: 5.3] [G acc: 0.312]\n",
      "474 (5, 1) [D loss: (-5.8)] [D acc: (0.000)] [G loss: -4.2] [G acc: 0.500]\n",
      "475 (5, 1) [D loss: (-7.0)] [D acc: (0.000)] [G loss: 9.3] [G acc: 0.344]\n",
      "476 (5, 1) [D loss: (-4.9)] [D acc: (0.000)] [G loss: 19.4] [G acc: 0.000]\n",
      "477 (5, 1) [D loss: (-5.0)] [D acc: (0.000)] [G loss: 23.5] [G acc: 0.000]\n",
      "478 (5, 1) [D loss: (-6.0)] [D acc: (0.000)] [G loss: 23.1] [G acc: 0.000]\n",
      "479 (5, 1) [D loss: (-6.3)] [D acc: (0.000)] [G loss: 28.3] [G acc: 0.000]\n",
      "480 (5, 1) [D loss: (-6.5)] [D acc: (0.000)] [G loss: 13.5] [G acc: 0.062]\n",
      "481 (5, 1) [D loss: (-6.1)] [D acc: (0.000)] [G loss: -10.2] [G acc: 0.906]\n",
      "482 (5, 1) [D loss: (-7.4)] [D acc: (0.000)] [G loss: 1.5] [G acc: 0.562]\n",
      "483 (5, 1) [D loss: (-6.9)] [D acc: (0.000)] [G loss: 27.5] [G acc: 0.000]\n",
      "484 (5, 1) [D loss: (-5.4)] [D acc: (0.000)] [G loss: 12.4] [G acc: 0.000]\n",
      "485 (5, 1) [D loss: (-4.8)] [D acc: (0.000)] [G loss: 15.6] [G acc: 0.031]\n",
      "486 (5, 1) [D loss: (-9.3)] [D acc: (0.000)] [G loss: -14.8] [G acc: 0.719]\n",
      "487 (5, 1) [D loss: (-9.5)] [D acc: (0.000)] [G loss: 9.3] [G acc: 0.219]\n",
      "488 (5, 1) [D loss: (-6.5)] [D acc: (0.000)] [G loss: 30.6] [G acc: 0.000]\n",
      "489 (5, 1) [D loss: (-6.9)] [D acc: (0.000)] [G loss: 31.6] [G acc: 0.000]\n",
      "490 (5, 1) [D loss: (-8.5)] [D acc: (0.000)] [G loss: 29.3] [G acc: 0.000]\n",
      "491 (5, 1) [D loss: (-4.9)] [D acc: (0.000)] [G loss: 41.3] [G acc: 0.000]\n",
      "492 (5, 1) [D loss: (-6.6)] [D acc: (0.000)] [G loss: 26.3] [G acc: 0.000]\n",
      "493 (5, 1) [D loss: (-6.3)] [D acc: (0.000)] [G loss: -5.0] [G acc: 0.812]\n",
      "494 (5, 1) [D loss: (-4.0)] [D acc: (0.000)] [G loss: 15.8] [G acc: 0.000]\n",
      "495 (5, 1) [D loss: (-7.2)] [D acc: (0.000)] [G loss: 10.1] [G acc: 0.250]\n",
      "496 (5, 1) [D loss: (-6.5)] [D acc: (0.000)] [G loss: 21.3] [G acc: 0.000]\n",
      "497 (5, 1) [D loss: (-6.1)] [D acc: (0.000)] [G loss: 10.1] [G acc: 0.031]\n",
      "498 (5, 1) [D loss: (-5.2)] [D acc: (0.000)] [G loss: 12.7] [G acc: 0.156]\n",
      "499 (5, 1) [D loss: (-3.4)] [D acc: (0.000)] [G loss: 18.6] [G acc: 0.000]\n",
      "500 (5, 1) [D loss: (-4.9)] [D acc: (0.000)] [G loss: 13.7] [G acc: 0.000]\n",
      "501 (5, 1) [D loss: (-5.9)] [D acc: (0.000)] [G loss: 15.7] [G acc: 0.000]\n",
      "502 (5, 1) [D loss: (-9.5)] [D acc: (0.000)] [G loss: 16.7] [G acc: 0.250]\n",
      "503 (5, 1) [D loss: (-4.2)] [D acc: (0.000)] [G loss: 0.5] [G acc: 0.656]\n",
      "504 (5, 1) [D loss: (-6.1)] [D acc: (0.000)] [G loss: 6.1] [G acc: 0.031]\n",
      "505 (5, 1) [D loss: (-3.4)] [D acc: (0.000)] [G loss: 16.0] [G acc: 0.125]\n",
      "506 (5, 1) [D loss: (-2.5)] [D acc: (0.000)] [G loss: 10.2] [G acc: 0.000]\n",
      "507 (5, 1) [D loss: (-5.4)] [D acc: (0.000)] [G loss: 12.3] [G acc: 0.000]\n",
      "508 (5, 1) [D loss: (-4.1)] [D acc: (0.000)] [G loss: 39.4] [G acc: 0.000]\n",
      "509 (5, 1) [D loss: (-5.6)] [D acc: (0.000)] [G loss: 12.4] [G acc: 0.188]\n",
      "510 (5, 1) [D loss: (-6.3)] [D acc: (0.000)] [G loss: -8.0] [G acc: 0.875]\n",
      "511 (5, 1) [D loss: (-7.5)] [D acc: (0.000)] [G loss: 8.7] [G acc: 0.219]\n",
      "512 (5, 1) [D loss: (-4.6)] [D acc: (0.000)] [G loss: 23.8] [G acc: 0.000]\n",
      "513 (5, 1) [D loss: (-7.4)] [D acc: (0.000)] [G loss: 10.3] [G acc: 0.062]\n",
      "514 (5, 1) [D loss: (-2.9)] [D acc: (0.000)] [G loss: 15.3] [G acc: 0.000]\n",
      "515 (5, 1) [D loss: (-5.3)] [D acc: (0.000)] [G loss: 24.1] [G acc: 0.000]\n",
      "516 (5, 1) [D loss: (-6.6)] [D acc: (0.000)] [G loss: 2.8] [G acc: 0.281]\n",
      "517 (5, 1) [D loss: (-4.5)] [D acc: (0.000)] [G loss: 17.1] [G acc: 0.000]\n",
      "518 (5, 1) [D loss: (-6.8)] [D acc: (0.000)] [G loss: -3.9] [G acc: 0.719]\n",
      "519 (5, 1) [D loss: (-5.9)] [D acc: (0.000)] [G loss: -0.8] [G acc: 0.562]\n",
      "520 (5, 1) [D loss: (-5.2)] [D acc: (0.000)] [G loss: 18.3] [G acc: 0.000]\n",
      "521 (5, 1) [D loss: (-5.8)] [D acc: (0.000)] [G loss: 30.3] [G acc: 0.000]\n",
      "522 (5, 1) [D loss: (-5.1)] [D acc: (0.000)] [G loss: 18.7] [G acc: 0.000]\n",
      "523 (5, 1) [D loss: (-5.4)] [D acc: (0.000)] [G loss: 18.7] [G acc: 0.000]\n",
      "524 (5, 1) [D loss: (-5.6)] [D acc: (0.000)] [G loss: 5.6] [G acc: 0.094]\n",
      "525 (5, 1) [D loss: (-4.2)] [D acc: (0.000)] [G loss: 17.1] [G acc: 0.062]\n",
      "526 (5, 1) [D loss: (-5.3)] [D acc: (0.000)] [G loss: 6.9] [G acc: 0.125]\n",
      "527 (5, 1) [D loss: (-2.7)] [D acc: (0.000)] [G loss: 12.4] [G acc: 0.125]\n",
      "528 (5, 1) [D loss: (-4.7)] [D acc: (0.000)] [G loss: 22.1] [G acc: 0.000]\n",
      "529 (5, 1) [D loss: (-5.4)] [D acc: (0.000)] [G loss: 16.8] [G acc: 0.000]\n",
      "530 (5, 1) [D loss: (-7.5)] [D acc: (0.000)] [G loss: 27.7] [G acc: 0.000]\n",
      "531 (5, 1) [D loss: (-4.3)] [D acc: (0.000)] [G loss: 8.6] [G acc: 0.062]\n",
      "532 (5, 1) [D loss: (-5.8)] [D acc: (0.000)] [G loss: -3.4] [G acc: 0.719]\n",
      "533 (5, 1) [D loss: (-4.9)] [D acc: (0.000)] [G loss: 21.0] [G acc: 0.000]\n",
      "534 (5, 1) [D loss: (-4.8)] [D acc: (0.000)] [G loss: 22.7] [G acc: 0.000]\n",
      "535 (5, 1) [D loss: (-7.4)] [D acc: (0.000)] [G loss: 13.5] [G acc: 0.000]\n",
      "536 (5, 1) [D loss: (-6.0)] [D acc: (0.000)] [G loss: 11.4] [G acc: 0.156]\n",
      "537 (5, 1) [D loss: (-4.8)] [D acc: (0.000)] [G loss: 11.5] [G acc: 0.000]\n",
      "538 (5, 1) [D loss: (-2.4)] [D acc: (0.000)] [G loss: 5.4] [G acc: 0.250]\n",
      "539 (5, 1) [D loss: (-6.4)] [D acc: (0.000)] [G loss: 30.9] [G acc: 0.000]\n",
      "540 (5, 1) [D loss: (-6.4)] [D acc: (0.000)] [G loss: 2.7] [G acc: 0.281]\n",
      "541 (5, 1) [D loss: (-5.4)] [D acc: (0.000)] [G loss: 13.8] [G acc: 0.000]\n",
      "542 (5, 1) [D loss: (-5.3)] [D acc: (0.000)] [G loss: 4.7] [G acc: 0.031]\n",
      "543 (5, 1) [D loss: (-5.5)] [D acc: (0.000)] [G loss: 11.6] [G acc: 0.000]\n",
      "544 (5, 1) [D loss: (-6.3)] [D acc: (0.000)] [G loss: 8.8] [G acc: 0.000]\n",
      "545 (5, 1) [D loss: (-4.2)] [D acc: (0.000)] [G loss: 9.2] [G acc: 0.188]\n",
      "546 (5, 1) [D loss: (-6.6)] [D acc: (0.000)] [G loss: 36.2] [G acc: 0.000]\n",
      "547 (5, 1) [D loss: (-5.4)] [D acc: (0.000)] [G loss: 15.6] [G acc: 0.000]\n",
      "548 (5, 1) [D loss: (-5.7)] [D acc: (0.000)] [G loss: 12.0] [G acc: 0.000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "549 (5, 1) [D loss: (-7.8)] [D acc: (0.000)] [G loss: 14.0] [G acc: 0.000]\n",
      "550 (5, 1) [D loss: (-5.0)] [D acc: (0.000)] [G loss: 6.8] [G acc: 0.250]\n",
      "551 (5, 1) [D loss: (-4.3)] [D acc: (0.000)] [G loss: 15.0] [G acc: 0.000]\n",
      "552 (5, 1) [D loss: (-5.0)] [D acc: (0.000)] [G loss: 12.5] [G acc: 0.062]\n",
      "553 (5, 1) [D loss: (-6.0)] [D acc: (0.000)] [G loss: -1.8] [G acc: 0.688]\n",
      "554 (5, 1) [D loss: (-4.7)] [D acc: (0.000)] [G loss: 32.8] [G acc: 0.000]\n",
      "555 (5, 1) [D loss: (-7.2)] [D acc: (0.000)] [G loss: -7.0] [G acc: 0.719]\n",
      "556 (5, 1) [D loss: (-7.4)] [D acc: (0.000)] [G loss: 17.4] [G acc: 0.156]\n",
      "557 (5, 1) [D loss: (-6.0)] [D acc: (0.000)] [G loss: 12.2] [G acc: 0.000]\n",
      "558 (5, 1) [D loss: (-5.6)] [D acc: (0.000)] [G loss: 7.3] [G acc: 0.188]\n",
      "559 (5, 1) [D loss: (-6.5)] [D acc: (0.000)] [G loss: 13.9] [G acc: 0.188]\n",
      "560 (5, 1) [D loss: (-4.3)] [D acc: (0.000)] [G loss: 21.8] [G acc: 0.000]\n",
      "561 (5, 1) [D loss: (-5.9)] [D acc: (0.000)] [G loss: 22.3] [G acc: 0.000]\n",
      "562 (5, 1) [D loss: (-7.3)] [D acc: (0.000)] [G loss: 7.3] [G acc: 0.312]\n",
      "563 (5, 1) [D loss: (-5.1)] [D acc: (0.000)] [G loss: 12.8] [G acc: 0.094]\n",
      "564 (5, 1) [D loss: (-5.8)] [D acc: (0.000)] [G loss: 2.6] [G acc: 0.188]\n",
      "565 (5, 1) [D loss: (-6.2)] [D acc: (0.000)] [G loss: -6.9] [G acc: 0.906]\n",
      "566 (5, 1) [D loss: (-5.0)] [D acc: (0.000)] [G loss: 23.7] [G acc: 0.000]\n",
      "567 (5, 1) [D loss: (-6.4)] [D acc: (0.000)] [G loss: 20.1] [G acc: 0.000]\n",
      "568 (5, 1) [D loss: (-7.7)] [D acc: (0.000)] [G loss: 26.7] [G acc: 0.000]\n",
      "569 (5, 1) [D loss: (-3.7)] [D acc: (0.000)] [G loss: 11.1] [G acc: 0.000]\n",
      "570 (5, 1) [D loss: (-6.7)] [D acc: (0.000)] [G loss: 3.8] [G acc: 0.219]\n",
      "571 (5, 1) [D loss: (-6.4)] [D acc: (0.000)] [G loss: -9.1] [G acc: 0.906]\n",
      "572 (5, 1) [D loss: (-5.9)] [D acc: (0.000)] [G loss: 12.9] [G acc: 0.000]\n",
      "573 (5, 1) [D loss: (-2.9)] [D acc: (0.000)] [G loss: -3.5] [G acc: 0.875]\n",
      "574 (5, 1) [D loss: (-6.8)] [D acc: (0.000)] [G loss: 39.4] [G acc: 0.000]\n",
      "575 (5, 1) [D loss: (-9.1)] [D acc: (0.000)] [G loss: 13.6] [G acc: 0.281]\n",
      "576 (5, 1) [D loss: (-5.3)] [D acc: (0.000)] [G loss: 17.8] [G acc: 0.000]\n",
      "577 (5, 1) [D loss: (-7.2)] [D acc: (0.000)] [G loss: 29.1] [G acc: 0.000]\n",
      "578 (5, 1) [D loss: (-6.0)] [D acc: (0.000)] [G loss: 17.0] [G acc: 0.000]\n",
      "579 (5, 1) [D loss: (-7.5)] [D acc: (0.000)] [G loss: 1.7] [G acc: 0.375]\n",
      "580 (5, 1) [D loss: (-5.9)] [D acc: (0.000)] [G loss: -13.6] [G acc: 0.969]\n",
      "581 (5, 1) [D loss: (-5.0)] [D acc: (0.000)] [G loss: 27.7] [G acc: 0.000]\n",
      "582 (5, 1) [D loss: (-8.0)] [D acc: (0.000)] [G loss: 24.4] [G acc: 0.000]\n",
      "583 (5, 1) [D loss: (-5.0)] [D acc: (0.000)] [G loss: 26.4] [G acc: 0.000]\n",
      "584 (5, 1) [D loss: (-7.8)] [D acc: (0.000)] [G loss: 10.4] [G acc: 0.250]\n",
      "585 (5, 1) [D loss: (-6.9)] [D acc: (0.000)] [G loss: 12.8] [G acc: 0.000]\n",
      "586 (5, 1) [D loss: (-2.8)] [D acc: (0.000)] [G loss: 9.4] [G acc: 0.188]\n",
      "587 (5, 1) [D loss: (-7.4)] [D acc: (0.000)] [G loss: -2.2] [G acc: 0.594]\n",
      "588 (5, 1) [D loss: (-5.8)] [D acc: (0.000)] [G loss: 15.5] [G acc: 0.000]\n",
      "589 (5, 1) [D loss: (-5.9)] [D acc: (0.000)] [G loss: 0.7] [G acc: 0.469]\n",
      "590 (5, 1) [D loss: (-8.0)] [D acc: (0.000)] [G loss: 24.0] [G acc: 0.156]\n",
      "591 (5, 1) [D loss: (-10.1)] [D acc: (0.000)] [G loss: 5.9] [G acc: 0.469]\n",
      "592 (5, 1) [D loss: (-5.3)] [D acc: (0.000)] [G loss: 12.8] [G acc: 0.031]\n",
      "593 (5, 1) [D loss: (-11.8)] [D acc: (0.000)] [G loss: 38.7] [G acc: 0.000]\n",
      "594 (5, 1) [D loss: (-11.7)] [D acc: (0.000)] [G loss: 6.9] [G acc: 0.500]\n",
      "595 (5, 1) [D loss: (-9.4)] [D acc: (0.000)] [G loss: 10.0] [G acc: 0.406]\n",
      "596 (5, 1) [D loss: (-7.5)] [D acc: (0.000)] [G loss: 4.4] [G acc: 0.281]\n",
      "597 (5, 1) [D loss: (-7.5)] [D acc: (0.000)] [G loss: -2.1] [G acc: 0.406]\n",
      "598 (5, 1) [D loss: (-5.3)] [D acc: (0.000)] [G loss: 5.4] [G acc: 0.375]\n",
      "599 (5, 1) [D loss: (-5.9)] [D acc: (0.000)] [G loss: 5.1] [G acc: 0.250]\n",
      "600 (5, 1) [D loss: (-8.6)] [D acc: (0.000)] [G loss: 15.5] [G acc: 0.156]\n",
      "601 (5, 1) [D loss: (-6.4)] [D acc: (0.000)] [G loss: 13.9] [G acc: 0.031]\n",
      "602 (5, 1) [D loss: (-6.3)] [D acc: (0.000)] [G loss: 25.6] [G acc: 0.000]\n",
      "603 (5, 1) [D loss: (-5.2)] [D acc: (0.000)] [G loss: 1.7] [G acc: 0.469]\n",
      "604 (5, 1) [D loss: (-5.1)] [D acc: (0.000)] [G loss: 24.8] [G acc: 0.000]\n",
      "605 (5, 1) [D loss: (-6.9)] [D acc: (0.000)] [G loss: -0.4] [G acc: 0.500]\n",
      "606 (5, 1) [D loss: (-2.6)] [D acc: (0.000)] [G loss: 10.2] [G acc: 0.094]\n",
      "607 (5, 1) [D loss: (-6.7)] [D acc: (0.000)] [G loss: -2.2] [G acc: 0.531]\n",
      "608 (5, 1) [D loss: (-6.9)] [D acc: (0.000)] [G loss: -14.9] [G acc: 0.906]\n",
      "609 (5, 1) [D loss: (-7.7)] [D acc: (0.000)] [G loss: 23.8] [G acc: 0.000]\n",
      "610 (5, 1) [D loss: (-6.7)] [D acc: (0.000)] [G loss: 24.6] [G acc: 0.000]\n",
      "611 (5, 1) [D loss: (-5.0)] [D acc: (0.000)] [G loss: 23.5] [G acc: 0.000]\n",
      "612 (5, 1) [D loss: (-6.6)] [D acc: (0.000)] [G loss: 22.3] [G acc: 0.000]\n",
      "613 (5, 1) [D loss: (-3.9)] [D acc: (0.000)] [G loss: -0.3] [G acc: 0.375]\n",
      "614 (5, 1) [D loss: (-3.6)] [D acc: (0.000)] [G loss: -5.6] [G acc: 0.594]\n",
      "615 (5, 1) [D loss: (-5.1)] [D acc: (0.000)] [G loss: -10.6] [G acc: 1.000]\n",
      "616 (5, 1) [D loss: (-7.0)] [D acc: (0.000)] [G loss: 14.9] [G acc: 0.219]\n",
      "617 (5, 1) [D loss: (-5.9)] [D acc: (0.000)] [G loss: 8.8] [G acc: 0.000]\n",
      "618 (5, 1) [D loss: (-5.6)] [D acc: (0.000)] [G loss: 20.2] [G acc: 0.000]\n",
      "619 (5, 1) [D loss: (-6.5)] [D acc: (0.000)] [G loss: 26.7] [G acc: 0.000]\n",
      "620 (5, 1) [D loss: (-5.8)] [D acc: (0.000)] [G loss: 3.4] [G acc: 0.188]\n",
      "621 (5, 1) [D loss: (-5.7)] [D acc: (0.000)] [G loss: -1.6] [G acc: 0.469]\n",
      "622 (5, 1) [D loss: (-4.0)] [D acc: (0.000)] [G loss: -3.9] [G acc: 0.750]\n",
      "623 (5, 1) [D loss: (-6.4)] [D acc: (0.000)] [G loss: -0.4] [G acc: 0.438]\n",
      "624 (5, 1) [D loss: (-7.7)] [D acc: (0.000)] [G loss: 7.8] [G acc: 0.469]\n",
      "625 (5, 1) [D loss: (-1.4)] [D acc: (0.000)] [G loss: 15.4] [G acc: 0.000]\n",
      "626 (5, 1) [D loss: (-3.4)] [D acc: (0.000)] [G loss: 14.4] [G acc: 0.062]\n",
      "627 (5, 1) [D loss: (-5.2)] [D acc: (0.000)] [G loss: 25.6] [G acc: 0.000]\n",
      "628 (5, 1) [D loss: (-7.4)] [D acc: (0.000)] [G loss: 22.8] [G acc: 0.000]\n",
      "629 (5, 1) [D loss: (-9.7)] [D acc: (0.000)] [G loss: -4.6] [G acc: 0.594]\n",
      "630 (5, 1) [D loss: (-7.0)] [D acc: (0.000)] [G loss: -1.0] [G acc: 0.594]\n",
      "631 (5, 1) [D loss: (-6.6)] [D acc: (0.000)] [G loss: -3.3] [G acc: 0.781]\n",
      "632 (5, 1) [D loss: (-7.7)] [D acc: (0.000)] [G loss: 24.9] [G acc: 0.000]\n",
      "633 (5, 1) [D loss: (-3.0)] [D acc: (0.000)] [G loss: 14.4] [G acc: 0.000]\n",
      "634 (5, 1) [D loss: (-7.2)] [D acc: (0.000)] [G loss: 29.4] [G acc: 0.000]\n",
      "635 (5, 1) [D loss: (-9.6)] [D acc: (0.000)] [G loss: 6.0] [G acc: 0.406]\n",
      "636 (5, 1) [D loss: (-7.7)] [D acc: (0.000)] [G loss: -19.0] [G acc: 1.000]\n",
      "637 (5, 1) [D loss: (-9.0)] [D acc: (0.000)] [G loss: 4.8] [G acc: 0.406]\n",
      "638 (5, 1) [D loss: (-5.0)] [D acc: (0.000)] [G loss: 16.2] [G acc: 0.000]\n",
      "639 (5, 1) [D loss: (-7.5)] [D acc: (0.000)] [G loss: 26.7] [G acc: 0.000]\n",
      "640 (5, 1) [D loss: (-6.0)] [D acc: (0.000)] [G loss: 12.8] [G acc: 0.062]\n",
      "641 (5, 1) [D loss: (-5.8)] [D acc: (0.000)] [G loss: 4.8] [G acc: 0.375]\n",
      "642 (5, 1) [D loss: (-5.8)] [D acc: (0.000)] [G loss: -12.4] [G acc: 1.000]\n",
      "643 (5, 1) [D loss: (-5.2)] [D acc: (0.000)] [G loss: 2.6] [G acc: 0.344]\n",
      "644 (5, 1) [D loss: (-5.9)] [D acc: (0.000)] [G loss: 24.3] [G acc: 0.000]\n",
      "645 (5, 1) [D loss: (-6.8)] [D acc: (0.000)] [G loss: 30.4] [G acc: 0.000]\n",
      "646 (5, 1) [D loss: (-9.3)] [D acc: (0.000)] [G loss: 18.2] [G acc: 0.062]\n",
      "647 (5, 1) [D loss: (-6.6)] [D acc: (0.000)] [G loss: 3.8] [G acc: 0.375]\n",
      "648 (5, 1) [D loss: (-5.9)] [D acc: (0.000)] [G loss: 10.4] [G acc: 0.000]\n",
      "649 (5, 1) [D loss: (-8.2)] [D acc: (0.000)] [G loss: 13.0] [G acc: 0.188]\n",
      "650 (5, 1) [D loss: (-5.7)] [D acc: (0.000)] [G loss: -4.6] [G acc: 0.750]\n",
      "651 (5, 1) [D loss: (-8.4)] [D acc: (0.000)] [G loss: 6.0] [G acc: 0.406]\n",
      "652 (5, 1) [D loss: (-4.9)] [D acc: (0.000)] [G loss: 8.8] [G acc: 0.031]\n",
      "653 (5, 1) [D loss: (-5.6)] [D acc: (0.000)] [G loss: 5.4] [G acc: 0.031]\n",
      "654 (5, 1) [D loss: (-9.1)] [D acc: (0.000)] [G loss: -6.9] [G acc: 0.688]\n",
      "655 (5, 1) [D loss: (-8.5)] [D acc: (0.000)] [G loss: 40.8] [G acc: 0.000]\n",
      "656 (5, 1) [D loss: (-4.4)] [D acc: (0.000)] [G loss: 12.1] [G acc: 0.000]\n",
      "657 (5, 1) [D loss: (-4.0)] [D acc: (0.000)] [G loss: 3.8] [G acc: 0.312]\n",
      "658 (5, 1) [D loss: (-6.5)] [D acc: (0.000)] [G loss: -1.8] [G acc: 0.594]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "659 (5, 1) [D loss: (-7.1)] [D acc: (0.000)] [G loss: 19.4] [G acc: 0.000]\n",
      "660 (5, 1) [D loss: (-4.7)] [D acc: (0.000)] [G loss: 2.0] [G acc: 0.500]\n",
      "661 (5, 1) [D loss: (-7.2)] [D acc: (0.000)] [G loss: 7.4] [G acc: 0.188]\n",
      "662 (5, 1) [D loss: (-5.0)] [D acc: (0.000)] [G loss: -1.0] [G acc: 0.500]\n",
      "663 (5, 1) [D loss: (-5.9)] [D acc: (0.000)] [G loss: 15.6] [G acc: 0.000]\n",
      "664 (5, 1) [D loss: (-5.7)] [D acc: (0.000)] [G loss: 11.7] [G acc: 0.125]\n",
      "665 (5, 1) [D loss: (-5.0)] [D acc: (0.000)] [G loss: 12.0] [G acc: 0.000]\n",
      "666 (5, 1) [D loss: (-5.1)] [D acc: (0.000)] [G loss: 13.7] [G acc: 0.000]\n",
      "667 (5, 1) [D loss: (-6.2)] [D acc: (0.000)] [G loss: 9.8] [G acc: 0.094]\n",
      "668 (5, 1) [D loss: (-5.1)] [D acc: (0.000)] [G loss: -0.0] [G acc: 0.500]\n",
      "669 (5, 1) [D loss: (-6.0)] [D acc: (0.000)] [G loss: 16.0] [G acc: 0.156]\n",
      "670 (5, 1) [D loss: (-9.3)] [D acc: (0.000)] [G loss: 2.5] [G acc: 0.375]\n",
      "671 (5, 1) [D loss: (-9.7)] [D acc: (0.000)] [G loss: 6.2] [G acc: 0.438]\n",
      "672 (5, 1) [D loss: (-1.2)] [D acc: (0.000)] [G loss: 5.0] [G acc: 0.219]\n",
      "673 (5, 1) [D loss: (-7.5)] [D acc: (0.000)] [G loss: -10.8] [G acc: 1.000]\n",
      "674 (5, 1) [D loss: (-6.1)] [D acc: (0.000)] [G loss: 5.4] [G acc: 0.250]\n",
      "675 (5, 1) [D loss: (-5.6)] [D acc: (0.000)] [G loss: 2.1] [G acc: 0.188]\n",
      "676 (5, 1) [D loss: (-6.0)] [D acc: (0.000)] [G loss: 4.6] [G acc: 0.125]\n",
      "677 (5, 1) [D loss: (-6.2)] [D acc: (0.000)] [G loss: 21.6] [G acc: 0.000]\n",
      "678 (5, 1) [D loss: (-3.5)] [D acc: (0.000)] [G loss: 21.3] [G acc: 0.000]\n",
      "679 (5, 1) [D loss: (-4.7)] [D acc: (0.000)] [G loss: -3.3] [G acc: 0.625]\n",
      "680 (5, 1) [D loss: (-5.5)] [D acc: (0.000)] [G loss: 21.1] [G acc: 0.000]\n",
      "681 (5, 1) [D loss: (-6.4)] [D acc: (0.000)] [G loss: -1.7] [G acc: 0.594]\n",
      "682 (5, 1) [D loss: (-7.0)] [D acc: (0.000)] [G loss: 1.4] [G acc: 0.406]\n",
      "683 (5, 1) [D loss: (-8.5)] [D acc: (0.000)] [G loss: 27.0] [G acc: 0.000]\n",
      "684 (5, 1) [D loss: (-8.0)] [D acc: (0.000)] [G loss: 1.6] [G acc: 0.344]\n",
      "685 (5, 1) [D loss: (-3.5)] [D acc: (0.000)] [G loss: 0.1] [G acc: 0.531]\n",
      "686 (5, 1) [D loss: (-5.8)] [D acc: (0.000)] [G loss: 22.5] [G acc: 0.000]\n",
      "687 (5, 1) [D loss: (-6.5)] [D acc: (0.000)] [G loss: -2.6] [G acc: 0.562]\n",
      "688 (5, 1) [D loss: (-8.2)] [D acc: (0.000)] [G loss: -3.0] [G acc: 0.656]\n",
      "689 (5, 1) [D loss: (-6.5)] [D acc: (0.000)] [G loss: 12.5] [G acc: 0.000]\n",
      "690 (5, 1) [D loss: (-6.4)] [D acc: (0.000)] [G loss: -10.0] [G acc: 1.000]\n",
      "691 (5, 1) [D loss: (-4.2)] [D acc: (0.000)] [G loss: -12.3] [G acc: 1.000]\n",
      "692 (5, 1) [D loss: (-6.4)] [D acc: (0.000)] [G loss: 29.8] [G acc: 0.000]\n",
      "693 (5, 1) [D loss: (-1.5)] [D acc: (0.000)] [G loss: 31.1] [G acc: 0.000]\n",
      "694 (5, 1) [D loss: (-6.1)] [D acc: (0.000)] [G loss: 8.4] [G acc: 0.281]\n",
      "695 (5, 1) [D loss: (-5.3)] [D acc: (0.000)] [G loss: -8.1] [G acc: 0.906]\n",
      "696 (5, 1) [D loss: (-6.2)] [D acc: (0.000)] [G loss: -2.2] [G acc: 0.469]\n",
      "697 (5, 1) [D loss: (3.3)] [D acc: (0.000)] [G loss: -9.4] [G acc: 0.938]\n",
      "698 (5, 1) [D loss: (-4.8)] [D acc: (0.000)] [G loss: 1.8] [G acc: 0.438]\n",
      "699 (5, 1) [D loss: (-4.8)] [D acc: (0.000)] [G loss: 21.6] [G acc: 0.000]\n",
      "700 (5, 1) [D loss: (-6.8)] [D acc: (0.000)] [G loss: 0.0] [G acc: 0.531]\n",
      "701 (5, 1) [D loss: (-8.3)] [D acc: (0.000)] [G loss: 18.0] [G acc: 0.188]\n",
      "702 (5, 1) [D loss: (-1.5)] [D acc: (0.000)] [G loss: 8.8] [G acc: 0.312]\n",
      "703 (5, 1) [D loss: (-8.2)] [D acc: (0.000)] [G loss: -7.4] [G acc: 0.719]\n",
      "704 (5, 1) [D loss: (-4.6)] [D acc: (0.000)] [G loss: 17.5] [G acc: 0.000]\n",
      "705 (5, 1) [D loss: (-11.1)] [D acc: (0.000)] [G loss: 14.5] [G acc: 0.344]\n",
      "706 (5, 1) [D loss: (-5.8)] [D acc: (0.000)] [G loss: 3.8] [G acc: 0.375]\n",
      "707 (5, 1) [D loss: (-8.9)] [D acc: (0.000)] [G loss: 0.9] [G acc: 0.500]\n",
      "708 (5, 1) [D loss: (-6.7)] [D acc: (0.000)] [G loss: 11.4] [G acc: 0.031]\n",
      "709 (5, 1) [D loss: (0.2)] [D acc: (0.000)] [G loss: -5.8] [G acc: 0.906]\n",
      "710 (5, 1) [D loss: (-6.7)] [D acc: (0.000)] [G loss: 9.5] [G acc: 0.125]\n",
      "711 (5, 1) [D loss: (-5.3)] [D acc: (0.000)] [G loss: -17.1] [G acc: 1.000]\n",
      "712 (5, 1) [D loss: (-4.4)] [D acc: (0.000)] [G loss: 11.0] [G acc: 0.094]\n",
      "713 (5, 1) [D loss: (-6.1)] [D acc: (0.000)] [G loss: 7.6] [G acc: 0.094]\n",
      "714 (5, 1) [D loss: (-5.1)] [D acc: (0.000)] [G loss: -15.2] [G acc: 1.000]\n",
      "715 (5, 1) [D loss: (-6.5)] [D acc: (0.000)] [G loss: 25.3] [G acc: 0.000]\n",
      "716 (5, 1) [D loss: (-4.7)] [D acc: (0.000)] [G loss: 22.0] [G acc: 0.000]\n",
      "717 (5, 1) [D loss: (-5.8)] [D acc: (0.000)] [G loss: -4.8] [G acc: 0.969]\n",
      "718 (5, 1) [D loss: (-7.9)] [D acc: (0.000)] [G loss: 22.4] [G acc: 0.062]\n",
      "719 (5, 1) [D loss: (-6.6)] [D acc: (0.000)] [G loss: 7.0] [G acc: 0.125]\n",
      "720 (5, 1) [D loss: (-5.5)] [D acc: (0.000)] [G loss: -11.2] [G acc: 0.906]\n",
      "721 (5, 1) [D loss: (-6.0)] [D acc: (0.000)] [G loss: -1.6] [G acc: 0.562]\n",
      "722 (5, 1) [D loss: (-12.1)] [D acc: (0.000)] [G loss: -15.3] [G acc: 0.781]\n",
      "723 (5, 1) [D loss: (-4.1)] [D acc: (0.000)] [G loss: -9.2] [G acc: 0.750]\n",
      "724 (5, 1) [D loss: (-5.4)] [D acc: (0.000)] [G loss: -10.9] [G acc: 1.000]\n",
      "725 (5, 1) [D loss: (-7.1)] [D acc: (0.000)] [G loss: 6.0] [G acc: 0.219]\n",
      "726 (5, 1) [D loss: (-6.7)] [D acc: (0.000)] [G loss: 10.4] [G acc: 0.094]\n",
      "727 (5, 1) [D loss: (-8.9)] [D acc: (0.000)] [G loss: 20.4] [G acc: 0.000]\n",
      "728 (5, 1) [D loss: (-7.3)] [D acc: (0.000)] [G loss: 26.4] [G acc: 0.000]\n",
      "729 (5, 1) [D loss: (-7.2)] [D acc: (0.000)] [G loss: 8.6] [G acc: 0.000]\n",
      "730 (5, 1) [D loss: (-6.7)] [D acc: (0.000)] [G loss: -25.5] [G acc: 0.875]\n",
      "731 (5, 1) [D loss: (-8.8)] [D acc: (0.000)] [G loss: -16.7] [G acc: 0.906]\n",
      "732 (5, 1) [D loss: (-7.8)] [D acc: (0.000)] [G loss: 4.6] [G acc: 0.375]\n",
      "733 (5, 1) [D loss: (-6.3)] [D acc: (0.000)] [G loss: 15.2] [G acc: 0.000]\n",
      "734 (5, 1) [D loss: (-4.5)] [D acc: (0.000)] [G loss: 10.6] [G acc: 0.000]\n",
      "735 (5, 1) [D loss: (-5.7)] [D acc: (0.000)] [G loss: 11.2] [G acc: 0.094]\n",
      "736 (5, 1) [D loss: (-5.6)] [D acc: (0.000)] [G loss: -13.6] [G acc: 1.000]\n",
      "737 (5, 1) [D loss: (-5.8)] [D acc: (0.000)] [G loss: -6.1] [G acc: 0.781]\n",
      "738 (5, 1) [D loss: (-8.3)] [D acc: (0.000)] [G loss: -2.1] [G acc: 0.500]\n",
      "739 (5, 1) [D loss: (-8.4)] [D acc: (0.000)] [G loss: 13.3] [G acc: 0.219]\n",
      "740 (5, 1) [D loss: (-7.4)] [D acc: (0.000)] [G loss: 29.3] [G acc: 0.000]\n",
      "741 (5, 1) [D loss: (-7.2)] [D acc: (0.000)] [G loss: 13.1] [G acc: 0.125]\n",
      "742 (5, 1) [D loss: (-6.7)] [D acc: (0.000)] [G loss: 14.5] [G acc: 0.000]\n",
      "743 (5, 1) [D loss: (-7.6)] [D acc: (0.000)] [G loss: -11.5] [G acc: 0.719]\n",
      "744 (5, 1) [D loss: (-6.8)] [D acc: (0.000)] [G loss: -9.2] [G acc: 0.969]\n",
      "745 (5, 1) [D loss: (-4.4)] [D acc: (0.000)] [G loss: -0.5] [G acc: 0.594]\n",
      "746 (5, 1) [D loss: (-5.1)] [D acc: (0.000)] [G loss: 7.4] [G acc: 0.344]\n",
      "747 (5, 1) [D loss: (-6.7)] [D acc: (0.000)] [G loss: 2.5] [G acc: 0.500]\n",
      "748 (5, 1) [D loss: (-7.5)] [D acc: (0.000)] [G loss: 5.6] [G acc: 0.094]\n",
      "749 (5, 1) [D loss: (-6.5)] [D acc: (0.000)] [G loss: -11.3] [G acc: 0.969]\n",
      "750 (5, 1) [D loss: (-5.4)] [D acc: (0.000)] [G loss: -3.5] [G acc: 0.781]\n",
      "751 (5, 1) [D loss: (-5.3)] [D acc: (0.000)] [G loss: -7.9] [G acc: 1.000]\n",
      "752 (5, 1) [D loss: (-6.3)] [D acc: (0.000)] [G loss: 6.3] [G acc: 0.156]\n",
      "753 (5, 1) [D loss: (-9.4)] [D acc: (0.000)] [G loss: 9.3] [G acc: 0.469]\n",
      "754 (5, 1) [D loss: (-0.1)] [D acc: (0.000)] [G loss: -8.1] [G acc: 0.969]\n",
      "755 (5, 1) [D loss: (-6.7)] [D acc: (0.000)] [G loss: 4.4] [G acc: 0.125]\n",
      "756 (5, 1) [D loss: (-4.8)] [D acc: (0.000)] [G loss: 5.6] [G acc: 0.000]\n",
      "757 (5, 1) [D loss: (-6.7)] [D acc: (0.000)] [G loss: 1.9] [G acc: 0.375]\n",
      "758 (5, 1) [D loss: (-11.2)] [D acc: (0.000)] [G loss: -0.0] [G acc: 0.594]\n",
      "759 (5, 1) [D loss: (-7.2)] [D acc: (0.000)] [G loss: -8.8] [G acc: 0.875]\n",
      "760 (5, 1) [D loss: (-8.2)] [D acc: (0.000)] [G loss: 1.5] [G acc: 0.500]\n",
      "761 (5, 1) [D loss: (-7.3)] [D acc: (0.000)] [G loss: -6.5] [G acc: 0.688]\n",
      "762 (5, 1) [D loss: (-6.9)] [D acc: (0.000)] [G loss: -4.8] [G acc: 0.688]\n",
      "763 (5, 1) [D loss: (-6.1)] [D acc: (0.000)] [G loss: -6.5] [G acc: 0.688]\n",
      "764 (5, 1) [D loss: (-7.7)] [D acc: (0.000)] [G loss: -7.4] [G acc: 0.844]\n",
      "765 (5, 1) [D loss: (-6.8)] [D acc: (0.000)] [G loss: 21.5] [G acc: 0.000]\n",
      "766 (5, 1) [D loss: (-6.1)] [D acc: (0.000)] [G loss: 12.4] [G acc: 0.000]\n",
      "767 (5, 1) [D loss: (-8.1)] [D acc: (0.000)] [G loss: -8.6] [G acc: 0.969]\n",
      "768 (5, 1) [D loss: (-7.2)] [D acc: (0.000)] [G loss: 7.2] [G acc: 0.094]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "769 (5, 1) [D loss: (-6.8)] [D acc: (0.000)] [G loss: -10.4] [G acc: 0.875]\n",
      "770 (5, 1) [D loss: (-6.7)] [D acc: (0.000)] [G loss: -1.3] [G acc: 0.594]\n",
      "771 (5, 1) [D loss: (-6.6)] [D acc: (0.000)] [G loss: -12.4] [G acc: 1.000]\n",
      "772 (5, 1) [D loss: (-8.7)] [D acc: (0.000)] [G loss: 0.3] [G acc: 0.531]\n",
      "773 (5, 1) [D loss: (-6.9)] [D acc: (0.000)] [G loss: 5.5] [G acc: 0.438]\n",
      "774 (5, 1) [D loss: (-3.8)] [D acc: (0.000)] [G loss: 10.0] [G acc: 0.000]\n",
      "775 (5, 1) [D loss: (-3.4)] [D acc: (0.000)] [G loss: 2.7] [G acc: 0.531]\n",
      "776 (5, 1) [D loss: (-8.0)] [D acc: (0.000)] [G loss: -3.4] [G acc: 0.656]\n",
      "777 (5, 1) [D loss: (-3.7)] [D acc: (0.000)] [G loss: -0.9] [G acc: 0.656]\n",
      "778 (5, 1) [D loss: (-7.5)] [D acc: (0.000)] [G loss: -11.3] [G acc: 0.844]\n",
      "779 (5, 1) [D loss: (-3.3)] [D acc: (0.000)] [G loss: -2.3] [G acc: 0.656]\n",
      "780 (5, 1) [D loss: (-7.5)] [D acc: (0.000)] [G loss: -6.1] [G acc: 0.719]\n",
      "781 (5, 1) [D loss: (-2.5)] [D acc: (0.000)] [G loss: 6.1] [G acc: 0.312]\n",
      "782 (5, 1) [D loss: (-4.5)] [D acc: (0.000)] [G loss: 24.0] [G acc: 0.000]\n",
      "783 (5, 1) [D loss: (-6.2)] [D acc: (0.000)] [G loss: 0.8] [G acc: 0.500]\n",
      "784 (5, 1) [D loss: (-6.5)] [D acc: (0.000)] [G loss: -15.9] [G acc: 1.000]\n",
      "785 (5, 1) [D loss: (-8.1)] [D acc: (0.000)] [G loss: 5.9] [G acc: 0.094]\n",
      "786 (5, 1) [D loss: (-5.3)] [D acc: (0.000)] [G loss: 9.7] [G acc: 0.000]\n",
      "787 (5, 1) [D loss: (-8.2)] [D acc: (0.000)] [G loss: -1.1] [G acc: 0.594]\n",
      "788 (5, 1) [D loss: (-7.0)] [D acc: (0.000)] [G loss: 2.4] [G acc: 0.500]\n",
      "789 (5, 1) [D loss: (-6.3)] [D acc: (0.000)] [G loss: -23.1] [G acc: 1.000]\n",
      "790 (5, 1) [D loss: (-5.5)] [D acc: (0.000)] [G loss: -0.2] [G acc: 0.500]\n",
      "791 (5, 1) [D loss: (-5.4)] [D acc: (0.000)] [G loss: -0.6] [G acc: 0.531]\n",
      "792 (5, 1) [D loss: (-4.8)] [D acc: (0.000)] [G loss: 4.1] [G acc: 0.406]\n",
      "793 (5, 1) [D loss: (-4.2)] [D acc: (0.000)] [G loss: -1.6] [G acc: 0.531]\n",
      "794 (5, 1) [D loss: (-5.0)] [D acc: (0.000)] [G loss: -7.6] [G acc: 0.531]\n",
      "795 (5, 1) [D loss: (-7.0)] [D acc: (0.000)] [G loss: 9.2] [G acc: 0.000]\n",
      "796 (5, 1) [D loss: (-5.0)] [D acc: (0.000)] [G loss: 13.0] [G acc: 0.000]\n",
      "797 (5, 1) [D loss: (-6.6)] [D acc: (0.000)] [G loss: -20.8] [G acc: 1.000]\n",
      "798 (5, 1) [D loss: (-6.8)] [D acc: (0.000)] [G loss: -6.6] [G acc: 0.812]\n",
      "799 (5, 1) [D loss: (-3.9)] [D acc: (0.000)] [G loss: -19.6] [G acc: 1.000]\n",
      "800 (5, 1) [D loss: (-6.8)] [D acc: (0.000)] [G loss: -1.5] [G acc: 0.656]\n",
      "801 (5, 1) [D loss: (-6.3)] [D acc: (0.000)] [G loss: 2.7] [G acc: 0.281]\n",
      "802 (5, 1) [D loss: (-7.3)] [D acc: (0.000)] [G loss: 10.0] [G acc: 0.000]\n",
      "803 (5, 1) [D loss: (-6.9)] [D acc: (0.000)] [G loss: 4.9] [G acc: 0.062]\n",
      "804 (5, 1) [D loss: (-5.9)] [D acc: (0.000)] [G loss: -23.8] [G acc: 1.000]\n",
      "805 (5, 1) [D loss: (-5.9)] [D acc: (0.000)] [G loss: -20.1] [G acc: 0.875]\n",
      "806 (5, 1) [D loss: (-5.6)] [D acc: (0.000)] [G loss: -14.3] [G acc: 1.000]\n",
      "807 (5, 1) [D loss: (-7.4)] [D acc: (0.000)] [G loss: 6.7] [G acc: 0.312]\n",
      "808 (5, 1) [D loss: (-5.7)] [D acc: (0.000)] [G loss: 1.6] [G acc: 0.438]\n",
      "809 (5, 1) [D loss: (-8.0)] [D acc: (0.000)] [G loss: 30.7] [G acc: 0.000]\n",
      "810 (5, 1) [D loss: (-4.4)] [D acc: (0.000)] [G loss: 14.5] [G acc: 0.000]\n",
      "811 (5, 1) [D loss: (-5.7)] [D acc: (0.000)] [G loss: -3.8] [G acc: 1.000]\n",
      "812 (5, 1) [D loss: (-6.5)] [D acc: (0.000)] [G loss: -22.9] [G acc: 1.000]\n",
      "813 (5, 1) [D loss: (-5.9)] [D acc: (0.000)] [G loss: -22.1] [G acc: 1.000]\n",
      "814 (5, 1) [D loss: (-6.5)] [D acc: (0.000)] [G loss: -1.1] [G acc: 0.531]\n",
      "815 (5, 1) [D loss: (-6.2)] [D acc: (0.000)] [G loss: 10.7] [G acc: 0.125]\n",
      "816 (5, 1) [D loss: (-6.0)] [D acc: (0.000)] [G loss: -13.5] [G acc: 1.000]\n",
      "817 (5, 1) [D loss: (-7.8)] [D acc: (0.000)] [G loss: -1.3] [G acc: 0.406]\n",
      "818 (5, 1) [D loss: (-5.0)] [D acc: (0.000)] [G loss: -4.9] [G acc: 0.625]\n",
      "819 (5, 1) [D loss: (-6.7)] [D acc: (0.000)] [G loss: -2.9] [G acc: 0.594]\n",
      "820 (5, 1) [D loss: (-7.0)] [D acc: (0.000)] [G loss: 15.2] [G acc: 0.000]\n",
      "821 (5, 1) [D loss: (-8.0)] [D acc: (0.000)] [G loss: -11.1] [G acc: 0.750]\n",
      "822 (5, 1) [D loss: (-5.3)] [D acc: (0.000)] [G loss: -26.3] [G acc: 1.000]\n",
      "823 (5, 1) [D loss: (-6.9)] [D acc: (0.000)] [G loss: -6.2] [G acc: 0.906]\n",
      "824 (5, 1) [D loss: (-6.4)] [D acc: (0.000)] [G loss: 3.9] [G acc: 0.406]\n",
      "825 (5, 1) [D loss: (-4.7)] [D acc: (0.000)] [G loss: 0.8] [G acc: 0.406]\n",
      "826 (5, 1) [D loss: (-6.3)] [D acc: (0.000)] [G loss: 8.0] [G acc: 0.281]\n",
      "827 (5, 1) [D loss: (-7.4)] [D acc: (0.000)] [G loss: 12.4] [G acc: 0.062]\n",
      "828 (5, 1) [D loss: (-8.3)] [D acc: (0.000)] [G loss: -15.7] [G acc: 0.844]\n",
      "829 (5, 1) [D loss: (-6.1)] [D acc: (0.000)] [G loss: -14.0] [G acc: 1.000]\n",
      "830 (5, 1) [D loss: (-7.9)] [D acc: (0.000)] [G loss: -6.0] [G acc: 0.625]\n",
      "831 (5, 1) [D loss: (-7.1)] [D acc: (0.000)] [G loss: -1.9] [G acc: 0.531]\n",
      "832 (5, 1) [D loss: (-5.2)] [D acc: (0.000)] [G loss: -1.7] [G acc: 0.656]\n",
      "833 (5, 1) [D loss: (-7.2)] [D acc: (0.000)] [G loss: 4.2] [G acc: 0.406]\n",
      "834 (5, 1) [D loss: (-8.2)] [D acc: (0.000)] [G loss: -28.8] [G acc: 0.969]\n",
      "835 (5, 1) [D loss: (-9.4)] [D acc: (0.000)] [G loss: -19.9] [G acc: 1.000]\n",
      "836 (5, 1) [D loss: (-9.5)] [D acc: (0.000)] [G loss: -11.7] [G acc: 0.656]\n",
      "837 (5, 1) [D loss: (-7.7)] [D acc: (0.000)] [G loss: 11.4] [G acc: 0.031]\n",
      "838 (5, 1) [D loss: (-6.6)] [D acc: (0.000)] [G loss: -2.4] [G acc: 0.781]\n",
      "839 (5, 1) [D loss: (-9.9)] [D acc: (0.000)] [G loss: -14.4] [G acc: 0.750]\n",
      "840 (5, 1) [D loss: (-8.9)] [D acc: (0.000)] [G loss: -0.8] [G acc: 0.562]\n",
      "841 (5, 1) [D loss: (-5.2)] [D acc: (0.000)] [G loss: -4.2] [G acc: 0.844]\n",
      "842 (5, 1) [D loss: (-5.9)] [D acc: (0.000)] [G loss: -8.5] [G acc: 0.938]\n",
      "843 (5, 1) [D loss: (-8.4)] [D acc: (0.000)] [G loss: -6.5] [G acc: 0.781]\n",
      "844 (5, 1) [D loss: (-6.6)] [D acc: (0.000)] [G loss: -25.2] [G acc: 1.000]\n",
      "845 (5, 1) [D loss: (-6.4)] [D acc: (0.000)] [G loss: -12.7] [G acc: 1.000]\n",
      "846 (5, 1) [D loss: (-5.2)] [D acc: (0.000)] [G loss: -28.9] [G acc: 1.000]\n",
      "847 (5, 1) [D loss: (-3.9)] [D acc: (0.000)] [G loss: -20.5] [G acc: 1.000]\n",
      "848 (5, 1) [D loss: (-5.6)] [D acc: (0.000)] [G loss: 18.0] [G acc: 0.000]\n",
      "849 (5, 1) [D loss: (-6.8)] [D acc: (0.000)] [G loss: 12.5] [G acc: 0.188]\n",
      "850 (5, 1) [D loss: (-7.4)] [D acc: (0.000)] [G loss: 14.8] [G acc: 0.031]\n",
      "851 (5, 1) [D loss: (-5.4)] [D acc: (0.000)] [G loss: 4.4] [G acc: 0.125]\n",
      "852 (5, 1) [D loss: (-9.4)] [D acc: (0.000)] [G loss: -11.3] [G acc: 0.750]\n",
      "853 (5, 1) [D loss: (-4.5)] [D acc: (0.000)] [G loss: -23.6] [G acc: 1.000]\n",
      "854 (5, 1) [D loss: (-6.8)] [D acc: (0.000)] [G loss: -27.8] [G acc: 1.000]\n",
      "855 (5, 1) [D loss: (-4.9)] [D acc: (0.000)] [G loss: -9.8] [G acc: 0.656]\n",
      "856 (5, 1) [D loss: (-5.4)] [D acc: (0.000)] [G loss: 16.9] [G acc: 0.000]\n",
      "857 (5, 1) [D loss: (-3.0)] [D acc: (0.000)] [G loss: -5.8] [G acc: 0.781]\n",
      "858 (5, 1) [D loss: (-7.9)] [D acc: (0.000)] [G loss: 3.0] [G acc: 0.469]\n",
      "859 (5, 1) [D loss: (-6.6)] [D acc: (0.000)] [G loss: -12.9] [G acc: 1.000]\n",
      "860 (5, 1) [D loss: (-9.7)] [D acc: (0.000)] [G loss: -16.5] [G acc: 0.781]\n",
      "861 (5, 1) [D loss: (-5.5)] [D acc: (0.000)] [G loss: -11.8] [G acc: 0.906]\n",
      "862 (5, 1) [D loss: (-3.4)] [D acc: (0.000)] [G loss: -15.3] [G acc: 1.000]\n",
      "863 (5, 1) [D loss: (-6.3)] [D acc: (0.000)] [G loss: -2.4] [G acc: 0.750]\n",
      "864 (5, 1) [D loss: (-6.6)] [D acc: (0.000)] [G loss: -2.1] [G acc: 0.625]\n",
      "865 (5, 1) [D loss: (-8.7)] [D acc: (0.000)] [G loss: 3.3] [G acc: 0.469]\n",
      "866 (5, 1) [D loss: (-5.8)] [D acc: (0.000)] [G loss: -12.5] [G acc: 1.000]\n",
      "867 (5, 1) [D loss: (-5.4)] [D acc: (0.000)] [G loss: -13.8] [G acc: 1.000]\n",
      "868 (5, 1) [D loss: (-8.2)] [D acc: (0.000)] [G loss: -22.1] [G acc: 1.000]\n",
      "869 (5, 1) [D loss: (-5.0)] [D acc: (0.000)] [G loss: -13.1] [G acc: 0.938]\n",
      "870 (5, 1) [D loss: (-8.4)] [D acc: (0.000)] [G loss: -2.4] [G acc: 0.625]\n",
      "871 (5, 1) [D loss: (-5.9)] [D acc: (0.000)] [G loss: 0.1] [G acc: 0.469]\n",
      "872 (5, 1) [D loss: (-5.3)] [D acc: (0.000)] [G loss: -14.5] [G acc: 1.000]\n",
      "873 (5, 1) [D loss: (-7.1)] [D acc: (0.000)] [G loss: -27.2] [G acc: 1.000]\n",
      "874 (5, 1) [D loss: (-6.6)] [D acc: (0.000)] [G loss: -29.1] [G acc: 1.000]\n",
      "875 (5, 1) [D loss: (-5.6)] [D acc: (0.000)] [G loss: -22.8] [G acc: 1.000]\n",
      "876 (5, 1) [D loss: (-5.9)] [D acc: (0.000)] [G loss: 0.5] [G acc: 0.375]\n",
      "877 (5, 1) [D loss: (-8.9)] [D acc: (0.000)] [G loss: 20.4] [G acc: 0.000]\n",
      "878 (5, 1) [D loss: (-4.2)] [D acc: (0.000)] [G loss: -0.6] [G acc: 0.500]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "879 (5, 1) [D loss: (-7.0)] [D acc: (0.000)] [G loss: -13.0] [G acc: 0.844]\n",
      "880 (5, 1) [D loss: (-8.2)] [D acc: (0.000)] [G loss: -34.3] [G acc: 1.000]\n",
      "881 (5, 1) [D loss: (-7.2)] [D acc: (0.000)] [G loss: -16.7] [G acc: 1.000]\n",
      "882 (5, 1) [D loss: (-4.3)] [D acc: (0.000)] [G loss: -17.8] [G acc: 1.000]\n",
      "883 (5, 1) [D loss: (-6.5)] [D acc: (0.000)] [G loss: 6.8] [G acc: 0.188]\n",
      "884 (5, 1) [D loss: (-7.0)] [D acc: (0.000)] [G loss: 1.2] [G acc: 0.438]\n",
      "885 (5, 1) [D loss: (-4.9)] [D acc: (0.000)] [G loss: 4.5] [G acc: 0.344]\n",
      "886 (5, 1) [D loss: (-5.5)] [D acc: (0.000)] [G loss: -2.9] [G acc: 0.781]\n",
      "887 (5, 1) [D loss: (-3.3)] [D acc: (0.000)] [G loss: -19.0] [G acc: 1.000]\n",
      "888 (5, 1) [D loss: (-8.4)] [D acc: (0.000)] [G loss: -13.7] [G acc: 1.000]\n",
      "889 (5, 1) [D loss: (-5.7)] [D acc: (0.000)] [G loss: -33.8] [G acc: 1.000]\n",
      "890 (5, 1) [D loss: (-7.5)] [D acc: (0.000)] [G loss: -29.6] [G acc: 1.000]\n",
      "891 (5, 1) [D loss: (-5.9)] [D acc: (0.000)] [G loss: -27.1] [G acc: 1.000]\n",
      "892 (5, 1) [D loss: (-6.2)] [D acc: (0.000)] [G loss: 13.8] [G acc: 0.000]\n",
      "893 (5, 1) [D loss: (-3.6)] [D acc: (0.000)] [G loss: 10.6] [G acc: 0.031]\n",
      "894 (5, 1) [D loss: (-8.3)] [D acc: (0.000)] [G loss: 17.1] [G acc: 0.000]\n",
      "895 (5, 1) [D loss: (-5.6)] [D acc: (0.000)] [G loss: -24.4] [G acc: 1.000]\n",
      "896 (5, 1) [D loss: (-8.4)] [D acc: (0.000)] [G loss: -42.4] [G acc: 1.000]\n",
      "897 (5, 1) [D loss: (-5.1)] [D acc: (0.000)] [G loss: -32.2] [G acc: 1.000]\n",
      "898 (5, 1) [D loss: (-6.3)] [D acc: (0.000)] [G loss: -34.6] [G acc: 1.000]\n",
      "899 (5, 1) [D loss: (-7.3)] [D acc: (0.000)] [G loss: -13.5] [G acc: 0.750]\n",
      "900 (5, 1) [D loss: (-6.8)] [D acc: (0.000)] [G loss: 15.8] [G acc: 0.000]\n",
      "901 (5, 1) [D loss: (-6.3)] [D acc: (0.000)] [G loss: 11.0] [G acc: 0.125]\n",
      "902 (5, 1) [D loss: (-5.9)] [D acc: (0.000)] [G loss: -9.2] [G acc: 0.906]\n",
      "903 (5, 1) [D loss: (-4.2)] [D acc: (0.000)] [G loss: -26.5] [G acc: 1.000]\n",
      "904 (5, 1) [D loss: (-4.6)] [D acc: (0.000)] [G loss: -14.0] [G acc: 1.000]\n",
      "905 (5, 1) [D loss: (-4.9)] [D acc: (0.000)] [G loss: -28.3] [G acc: 1.000]\n",
      "906 (5, 1) [D loss: (-6.4)] [D acc: (0.000)] [G loss: -29.5] [G acc: 1.000]\n",
      "907 (5, 1) [D loss: (-3.8)] [D acc: (0.000)] [G loss: 13.2] [G acc: 0.000]\n",
      "908 (5, 1) [D loss: (-6.8)] [D acc: (0.000)] [G loss: -13.7] [G acc: 0.969]\n",
      "909 (5, 1) [D loss: (-7.4)] [D acc: (0.000)] [G loss: 2.2] [G acc: 0.469]\n",
      "910 (5, 1) [D loss: (-5.6)] [D acc: (0.000)] [G loss: -20.9] [G acc: 1.000]\n",
      "911 (5, 1) [D loss: (-6.6)] [D acc: (0.000)] [G loss: -29.7] [G acc: 1.000]\n",
      "912 (5, 1) [D loss: (-7.1)] [D acc: (0.000)] [G loss: -27.8] [G acc: 1.000]\n",
      "913 (5, 1) [D loss: (-7.4)] [D acc: (0.000)] [G loss: -18.3] [G acc: 1.000]\n",
      "914 (5, 1) [D loss: (-10.9)] [D acc: (0.000)] [G loss: 3.0] [G acc: 0.531]\n",
      "915 (5, 1) [D loss: (-7.2)] [D acc: (0.000)] [G loss: 3.9] [G acc: 0.406]\n",
      "916 (5, 1) [D loss: (-7.6)] [D acc: (0.000)] [G loss: -7.7] [G acc: 0.656]\n",
      "917 (5, 1) [D loss: (-3.4)] [D acc: (0.000)] [G loss: -26.4] [G acc: 1.000]\n",
      "918 (5, 1) [D loss: (-5.3)] [D acc: (0.000)] [G loss: -11.2] [G acc: 1.000]\n",
      "919 (5, 1) [D loss: (-6.7)] [D acc: (0.000)] [G loss: -15.9] [G acc: 0.969]\n",
      "920 (5, 1) [D loss: (-7.4)] [D acc: (0.000)] [G loss: -3.4] [G acc: 0.750]\n",
      "921 (5, 1) [D loss: (-6.7)] [D acc: (0.000)] [G loss: -28.5] [G acc: 1.000]\n",
      "922 (5, 1) [D loss: (-6.4)] [D acc: (0.000)] [G loss: -15.2] [G acc: 0.875]\n",
      "923 (5, 1) [D loss: (-5.5)] [D acc: (0.000)] [G loss: -6.2] [G acc: 0.969]\n",
      "924 (5, 1) [D loss: (-4.9)] [D acc: (0.000)] [G loss: -33.5] [G acc: 1.000]\n",
      "925 (5, 1) [D loss: (-5.6)] [D acc: (0.000)] [G loss: -20.4] [G acc: 1.000]\n",
      "926 (5, 1) [D loss: (-4.4)] [D acc: (0.000)] [G loss: -12.1] [G acc: 0.812]\n",
      "927 (5, 1) [D loss: (-6.6)] [D acc: (0.000)] [G loss: -10.4] [G acc: 0.812]\n",
      "928 (5, 1) [D loss: (-5.4)] [D acc: (0.000)] [G loss: -43.8] [G acc: 1.000]\n",
      "929 (5, 1) [D loss: (-7.2)] [D acc: (0.000)] [G loss: -23.0] [G acc: 1.000]\n",
      "930 (5, 1) [D loss: (-10.2)] [D acc: (0.000)] [G loss: -33.1] [G acc: 0.969]\n",
      "931 (5, 1) [D loss: (-6.9)] [D acc: (0.000)] [G loss: -6.6] [G acc: 1.000]\n",
      "932 (5, 1) [D loss: (-7.2)] [D acc: (0.000)] [G loss: -0.2] [G acc: 0.594]\n",
      "933 (5, 1) [D loss: (-7.2)] [D acc: (0.000)] [G loss: 9.3] [G acc: 0.219]\n",
      "934 (5, 1) [D loss: (-5.8)] [D acc: (0.000)] [G loss: -28.0] [G acc: 1.000]\n",
      "935 (5, 1) [D loss: (-5.1)] [D acc: (0.000)] [G loss: -32.9] [G acc: 1.000]\n",
      "936 (5, 1) [D loss: (-7.8)] [D acc: (0.000)] [G loss: -32.1] [G acc: 1.000]\n",
      "937 (5, 1) [D loss: (-3.9)] [D acc: (0.000)] [G loss: -17.6] [G acc: 1.000]\n",
      "938 (5, 1) [D loss: (-5.8)] [D acc: (0.000)] [G loss: -1.4] [G acc: 0.719]\n",
      "939 (5, 1) [D loss: (-9.0)] [D acc: (0.000)] [G loss: -2.5] [G acc: 0.562]\n",
      "940 (5, 1) [D loss: (-5.6)] [D acc: (0.000)] [G loss: -0.2] [G acc: 0.562]\n",
      "941 (5, 1) [D loss: (-7.8)] [D acc: (0.000)] [G loss: -38.4] [G acc: 1.000]\n",
      "942 (5, 1) [D loss: (-7.1)] [D acc: (0.000)] [G loss: -37.1] [G acc: 1.000]\n",
      "943 (5, 1) [D loss: (-5.4)] [D acc: (0.000)] [G loss: -19.4] [G acc: 1.000]\n",
      "944 (5, 1) [D loss: (-9.2)] [D acc: (0.000)] [G loss: -29.0] [G acc: 0.906]\n",
      "945 (5, 1) [D loss: (-4.1)] [D acc: (0.000)] [G loss: -7.3] [G acc: 1.000]\n",
      "946 (5, 1) [D loss: (-5.2)] [D acc: (0.000)] [G loss: 6.1] [G acc: 0.062]\n",
      "947 (5, 1) [D loss: (-8.5)] [D acc: (0.000)] [G loss: 0.5] [G acc: 0.469]\n",
      "948 (5, 1) [D loss: (-7.5)] [D acc: (0.000)] [G loss: -18.7] [G acc: 1.000]\n",
      "949 (5, 1) [D loss: (-7.4)] [D acc: (0.000)] [G loss: -24.2] [G acc: 1.000]\n",
      "950 (5, 1) [D loss: (-6.5)] [D acc: (0.000)] [G loss: -28.9] [G acc: 1.000]\n",
      "951 (5, 1) [D loss: (-6.5)] [D acc: (0.000)] [G loss: -40.6] [G acc: 1.000]\n",
      "952 (5, 1) [D loss: (0.8)] [D acc: (0.000)] [G loss: -26.7] [G acc: 1.000]\n",
      "953 (5, 1) [D loss: (-6.6)] [D acc: (0.000)] [G loss: -15.0] [G acc: 1.000]\n",
      "954 (5, 1) [D loss: (-4.3)] [D acc: (0.000)] [G loss: -20.7] [G acc: 1.000]\n",
      "955 (5, 1) [D loss: (-7.3)] [D acc: (0.000)] [G loss: 3.0] [G acc: 0.375]\n",
      "956 (5, 1) [D loss: (-7.4)] [D acc: (0.000)] [G loss: -7.7] [G acc: 0.812]\n",
      "957 (5, 1) [D loss: (-7.5)] [D acc: (0.000)] [G loss: -19.5] [G acc: 1.000]\n",
      "958 (5, 1) [D loss: (-2.7)] [D acc: (0.000)] [G loss: -35.9] [G acc: 1.000]\n",
      "959 (5, 1) [D loss: (-5.7)] [D acc: (0.000)] [G loss: -35.9] [G acc: 1.000]\n",
      "960 (5, 1) [D loss: (-6.7)] [D acc: (0.000)] [G loss: -23.7] [G acc: 1.000]\n",
      "961 (5, 1) [D loss: (-6.7)] [D acc: (0.000)] [G loss: -22.7] [G acc: 1.000]\n",
      "962 (5, 1) [D loss: (-6.8)] [D acc: (0.000)] [G loss: -20.0] [G acc: 1.000]\n",
      "963 (5, 1) [D loss: (-10.9)] [D acc: (0.000)] [G loss: -15.8] [G acc: 0.812]\n",
      "964 (5, 1) [D loss: (-3.8)] [D acc: (0.000)] [G loss: -18.8] [G acc: 1.000]\n",
      "965 (5, 1) [D loss: (-6.5)] [D acc: (0.000)] [G loss: -19.3] [G acc: 1.000]\n",
      "966 (5, 1) [D loss: (-6.3)] [D acc: (0.000)] [G loss: -11.7] [G acc: 0.719]\n",
      "967 (5, 1) [D loss: (-7.5)] [D acc: (0.000)] [G loss: -14.9] [G acc: 0.844]\n",
      "968 (5, 1) [D loss: (-6.5)] [D acc: (0.000)] [G loss: -25.4] [G acc: 1.000]\n",
      "969 (5, 1) [D loss: (-1.5)] [D acc: (0.000)] [G loss: -35.7] [G acc: 1.000]\n",
      "970 (5, 1) [D loss: (-9.0)] [D acc: (0.000)] [G loss: -38.0] [G acc: 1.000]\n",
      "971 (5, 1) [D loss: (-5.8)] [D acc: (0.000)] [G loss: -15.6] [G acc: 0.969]\n",
      "972 (5, 1) [D loss: (-3.7)] [D acc: (0.000)] [G loss: -14.9] [G acc: 1.000]\n",
      "973 (5, 1) [D loss: (-7.1)] [D acc: (0.000)] [G loss: -7.7] [G acc: 0.688]\n",
      "974 (5, 1) [D loss: (-5.3)] [D acc: (0.000)] [G loss: -11.6] [G acc: 0.844]\n",
      "975 (5, 1) [D loss: (-6.8)] [D acc: (0.000)] [G loss: -33.2] [G acc: 1.000]\n",
      "976 (5, 1) [D loss: (-8.0)] [D acc: (0.000)] [G loss: -41.9] [G acc: 1.000]\n",
      "977 (5, 1) [D loss: (-6.1)] [D acc: (0.000)] [G loss: -34.7] [G acc: 1.000]\n",
      "978 (5, 1) [D loss: (-6.6)] [D acc: (0.000)] [G loss: -23.2] [G acc: 1.000]\n",
      "979 (5, 1) [D loss: (-2.1)] [D acc: (0.000)] [G loss: -20.6] [G acc: 1.000]\n",
      "980 (5, 1) [D loss: (-5.4)] [D acc: (0.000)] [G loss: -23.3] [G acc: 1.000]\n",
      "981 (5, 1) [D loss: (-5.9)] [D acc: (0.000)] [G loss: -23.5] [G acc: 1.000]\n",
      "982 (5, 1) [D loss: (-6.0)] [D acc: (0.000)] [G loss: -35.3] [G acc: 1.000]\n",
      "983 (5, 1) [D loss: (-5.3)] [D acc: (0.000)] [G loss: -34.8] [G acc: 1.000]\n",
      "984 (5, 1) [D loss: (-5.8)] [D acc: (0.000)] [G loss: -13.2] [G acc: 1.000]\n",
      "985 (5, 1) [D loss: (-7.0)] [D acc: (0.000)] [G loss: -14.0] [G acc: 1.000]\n",
      "986 (5, 1) [D loss: (-3.3)] [D acc: (0.000)] [G loss: -40.1] [G acc: 1.000]\n",
      "987 (5, 1) [D loss: (-9.0)] [D acc: (0.000)] [G loss: -40.1] [G acc: 1.000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "988 (5, 1) [D loss: (-6.6)] [D acc: (0.000)] [G loss: -16.8] [G acc: 0.906]\n",
      "989 (5, 1) [D loss: (-7.8)] [D acc: (0.000)] [G loss: -27.8] [G acc: 0.969]\n",
      "990 (5, 1) [D loss: (-6.1)] [D acc: (0.000)] [G loss: -21.6] [G acc: 1.000]\n",
      "991 (5, 1) [D loss: (-5.9)] [D acc: (0.000)] [G loss: -30.3] [G acc: 1.000]\n",
      "992 (5, 1) [D loss: (-9.3)] [D acc: (0.000)] [G loss: -28.6] [G acc: 0.969]\n",
      "993 (5, 1) [D loss: (-5.6)] [D acc: (0.000)] [G loss: -30.2] [G acc: 1.000]\n",
      "994 (5, 1) [D loss: (-3.2)] [D acc: (0.000)] [G loss: -40.9] [G acc: 1.000]\n",
      "995 (5, 1) [D loss: (-5.9)] [D acc: (0.000)] [G loss: -43.8] [G acc: 1.000]\n",
      "996 (5, 1) [D loss: (-5.4)] [D acc: (0.000)] [G loss: -34.9] [G acc: 1.000]\n",
      "997 (5, 1) [D loss: (-2.6)] [D acc: (0.000)] [G loss: -20.5] [G acc: 0.812]\n",
      "998 (5, 1) [D loss: (-7.8)] [D acc: (0.000)] [G loss: 6.8] [G acc: 0.000]\n",
      "999 (5, 1) [D loss: (-10.9)] [D acc: (0.000)] [G loss: -3.2] [G acc: 0.656]\n",
      "1000 (5, 1) [D loss: (-6.1)] [D acc: (0.000)] [G loss: -36.2] [G acc: 1.000]\n",
      "1001 (5, 1) [D loss: (-6.7)] [D acc: (0.000)] [G loss: -59.0] [G acc: 1.000]\n",
      "1002 (5, 1) [D loss: (-8.0)] [D acc: (0.000)] [G loss: -48.5] [G acc: 1.000]\n",
      "1003 (5, 1) [D loss: (-7.2)] [D acc: (0.000)] [G loss: -32.1] [G acc: 1.000]\n",
      "1004 (5, 1) [D loss: (-3.6)] [D acc: (0.000)] [G loss: -20.0] [G acc: 0.938]\n",
      "1005 (5, 1) [D loss: (-9.3)] [D acc: (0.000)] [G loss: -1.9] [G acc: 0.500]\n",
      "1006 (5, 1) [D loss: (3.7)] [D acc: (0.000)] [G loss: -23.9] [G acc: 1.000]\n",
      "1007 (5, 1) [D loss: (-6.5)] [D acc: (0.000)] [G loss: -38.3] [G acc: 1.000]\n",
      "1008 (5, 1) [D loss: (-4.9)] [D acc: (0.000)] [G loss: -41.2] [G acc: 1.000]\n",
      "1009 (5, 1) [D loss: (-5.3)] [D acc: (0.000)] [G loss: -32.0] [G acc: 1.000]\n",
      "1010 (5, 1) [D loss: (-7.2)] [D acc: (0.000)] [G loss: -32.1] [G acc: 1.000]\n",
      "1011 (5, 1) [D loss: (-2.0)] [D acc: (0.000)] [G loss: -15.6] [G acc: 0.906]\n",
      "1012 (5, 1) [D loss: (-2.6)] [D acc: (0.000)] [G loss: -28.4] [G acc: 0.969]\n",
      "1013 (5, 1) [D loss: (-5.9)] [D acc: (0.000)] [G loss: -57.5] [G acc: 1.000]\n",
      "1014 (5, 1) [D loss: (-6.6)] [D acc: (0.000)] [G loss: -37.2] [G acc: 1.000]\n",
      "1015 (5, 1) [D loss: (-5.5)] [D acc: (0.000)] [G loss: -30.8] [G acc: 1.000]\n",
      "1016 (5, 1) [D loss: (-3.3)] [D acc: (0.000)] [G loss: -17.3] [G acc: 1.000]\n",
      "1017 (5, 1) [D loss: (-5.7)] [D acc: (0.000)] [G loss: -20.8] [G acc: 1.000]\n",
      "1018 (5, 1) [D loss: (-3.5)] [D acc: (0.000)] [G loss: -25.0] [G acc: 1.000]\n",
      "1019 (5, 1) [D loss: (-5.8)] [D acc: (0.000)] [G loss: -45.8] [G acc: 1.000]\n",
      "1020 (5, 1) [D loss: (-7.0)] [D acc: (0.000)] [G loss: -43.0] [G acc: 1.000]\n",
      "1021 (5, 1) [D loss: (-5.1)] [D acc: (0.000)] [G loss: -19.6] [G acc: 1.000]\n",
      "1022 (5, 1) [D loss: (-5.8)] [D acc: (0.000)] [G loss: -27.2] [G acc: 1.000]\n",
      "1023 (5, 1) [D loss: (-6.0)] [D acc: (0.000)] [G loss: -20.5] [G acc: 0.906]\n",
      "1024 (5, 1) [D loss: (-6.7)] [D acc: (0.000)] [G loss: -50.1] [G acc: 1.000]\n",
      "1025 (5, 1) [D loss: (-7.9)] [D acc: (0.000)] [G loss: -31.5] [G acc: 1.000]\n",
      "1026 (5, 1) [D loss: (-6.9)] [D acc: (0.000)] [G loss: -38.0] [G acc: 1.000]\n",
      "1027 (5, 1) [D loss: (-7.8)] [D acc: (0.000)] [G loss: -56.7] [G acc: 1.000]\n",
      "1028 (5, 1) [D loss: (-7.5)] [D acc: (0.000)] [G loss: -50.0] [G acc: 1.000]\n",
      "1029 (5, 1) [D loss: (-8.9)] [D acc: (0.000)] [G loss: -22.1] [G acc: 0.969]\n",
      "1030 (5, 1) [D loss: (-6.4)] [D acc: (0.000)] [G loss: -20.6] [G acc: 1.000]\n",
      "1031 (5, 1) [D loss: (-6.1)] [D acc: (0.000)] [G loss: -23.6] [G acc: 1.000]\n",
      "1032 (5, 1) [D loss: (-10.8)] [D acc: (0.000)] [G loss: -34.4] [G acc: 0.969]\n",
      "1033 (5, 1) [D loss: (-5.9)] [D acc: (0.000)] [G loss: -40.9] [G acc: 1.000]\n",
      "1034 (5, 1) [D loss: (-6.5)] [D acc: (0.000)] [G loss: -31.0] [G acc: 1.000]\n",
      "1035 (5, 1) [D loss: (-5.3)] [D acc: (0.000)] [G loss: -22.2] [G acc: 1.000]\n",
      "1036 (5, 1) [D loss: (-2.4)] [D acc: (0.000)] [G loss: -44.2] [G acc: 1.000]\n",
      "1037 (5, 1) [D loss: (-6.1)] [D acc: (0.000)] [G loss: -69.9] [G acc: 1.000]\n",
      "1038 (5, 1) [D loss: (-6.6)] [D acc: (0.000)] [G loss: -45.1] [G acc: 1.000]\n",
      "1039 (5, 1) [D loss: (-5.7)] [D acc: (0.000)] [G loss: -46.6] [G acc: 1.000]\n",
      "1040 (5, 1) [D loss: (-4.9)] [D acc: (0.000)] [G loss: -20.6] [G acc: 1.000]\n",
      "1041 (5, 1) [D loss: (-3.5)] [D acc: (0.000)] [G loss: -30.8] [G acc: 1.000]\n",
      "1042 (5, 1) [D loss: (-6.9)] [D acc: (0.000)] [G loss: -16.7] [G acc: 1.000]\n",
      "1043 (5, 1) [D loss: (-6.7)] [D acc: (0.000)] [G loss: -42.1] [G acc: 1.000]\n",
      "1044 (5, 1) [D loss: (-6.5)] [D acc: (0.000)] [G loss: -55.3] [G acc: 1.000]\n",
      "1045 (5, 1) [D loss: (-4.4)] [D acc: (0.000)] [G loss: -61.3] [G acc: 1.000]\n",
      "1046 (5, 1) [D loss: (-5.1)] [D acc: (0.000)] [G loss: -37.0] [G acc: 1.000]\n",
      "1047 (5, 1) [D loss: (-11.0)] [D acc: (0.000)] [G loss: -28.9] [G acc: 0.875]\n",
      "1048 (5, 1) [D loss: (-9.8)] [D acc: (0.000)] [G loss: -19.5] [G acc: 0.875]\n",
      "1049 (5, 1) [D loss: (-6.4)] [D acc: (0.000)] [G loss: -11.8] [G acc: 0.781]\n",
      "1050 (5, 1) [D loss: (-7.5)] [D acc: (0.000)] [G loss: -53.1] [G acc: 1.000]\n",
      "1051 (5, 1) [D loss: (-6.9)] [D acc: (0.000)] [G loss: -46.1] [G acc: 1.000]\n",
      "1052 (5, 1) [D loss: (-6.8)] [D acc: (0.000)] [G loss: -52.0] [G acc: 1.000]\n",
      "1053 (5, 1) [D loss: (-7.3)] [D acc: (0.000)] [G loss: -58.7] [G acc: 1.000]\n",
      "1054 (5, 1) [D loss: (-7.5)] [D acc: (0.000)] [G loss: -34.1] [G acc: 1.000]\n",
      "1055 (5, 1) [D loss: (-6.7)] [D acc: (0.000)] [G loss: -37.4] [G acc: 1.000]\n",
      "1056 (5, 1) [D loss: (-3.6)] [D acc: (0.000)] [G loss: -28.1] [G acc: 1.000]\n",
      "1057 (5, 1) [D loss: (-6.3)] [D acc: (0.000)] [G loss: -21.4] [G acc: 1.000]\n",
      "1058 (5, 1) [D loss: (-6.0)] [D acc: (0.000)] [G loss: -24.1] [G acc: 1.000]\n",
      "1059 (5, 1) [D loss: (-6.0)] [D acc: (0.000)] [G loss: -54.5] [G acc: 1.000]\n",
      "1060 (5, 1) [D loss: (-7.1)] [D acc: (0.000)] [G loss: -55.6] [G acc: 1.000]\n",
      "1061 (5, 1) [D loss: (-5.2)] [D acc: (0.000)] [G loss: -58.2] [G acc: 1.000]\n",
      "1062 (5, 1) [D loss: (-6.5)] [D acc: (0.000)] [G loss: -58.5] [G acc: 1.000]\n",
      "1063 (5, 1) [D loss: (-1.3)] [D acc: (0.000)] [G loss: -39.6] [G acc: 1.000]\n",
      "1064 (5, 1) [D loss: (-4.4)] [D acc: (0.000)] [G loss: -31.2] [G acc: 1.000]\n",
      "1065 (5, 1) [D loss: (-7.0)] [D acc: (0.000)] [G loss: -39.1] [G acc: 1.000]\n",
      "1066 (5, 1) [D loss: (-4.7)] [D acc: (0.000)] [G loss: -42.5] [G acc: 1.000]\n",
      "1067 (5, 1) [D loss: (-4.7)] [D acc: (0.000)] [G loss: -28.9] [G acc: 1.000]\n",
      "1068 (5, 1) [D loss: (-9.2)] [D acc: (0.000)] [G loss: -33.2] [G acc: 1.000]\n",
      "1069 (5, 1) [D loss: (-9.7)] [D acc: (0.000)] [G loss: -24.7] [G acc: 0.969]\n",
      "1070 (5, 1) [D loss: (-6.6)] [D acc: (0.000)] [G loss: -39.0] [G acc: 1.000]\n",
      "1071 (5, 1) [D loss: (-5.8)] [D acc: (0.000)] [G loss: -45.0] [G acc: 1.000]\n",
      "1072 (5, 1) [D loss: (-6.0)] [D acc: (0.000)] [G loss: -55.2] [G acc: 1.000]\n",
      "1073 (5, 1) [D loss: (-5.7)] [D acc: (0.000)] [G loss: -43.6] [G acc: 1.000]\n",
      "1074 (5, 1) [D loss: (-5.3)] [D acc: (0.000)] [G loss: -47.4] [G acc: 1.000]\n",
      "1075 (5, 1) [D loss: (-10.4)] [D acc: (0.000)] [G loss: -51.0] [G acc: 1.000]\n",
      "1076 (5, 1) [D loss: (-6.3)] [D acc: (0.000)] [G loss: -58.4] [G acc: 1.000]\n",
      "1077 (5, 1) [D loss: (-8.7)] [D acc: (0.000)] [G loss: -42.5] [G acc: 1.000]\n",
      "1078 (5, 1) [D loss: (-5.2)] [D acc: (0.000)] [G loss: -26.1] [G acc: 1.000]\n",
      "1079 (5, 1) [D loss: (-7.0)] [D acc: (0.000)] [G loss: -30.6] [G acc: 1.000]\n",
      "1080 (5, 1) [D loss: (-2.4)] [D acc: (0.000)] [G loss: -21.5] [G acc: 1.000]\n",
      "1081 (5, 1) [D loss: (-4.9)] [D acc: (0.000)] [G loss: -39.4] [G acc: 1.000]\n",
      "1082 (5, 1) [D loss: (-5.0)] [D acc: (0.000)] [G loss: -57.6] [G acc: 1.000]\n",
      "1083 (5, 1) [D loss: (-6.0)] [D acc: (0.000)] [G loss: -41.9] [G acc: 1.000]\n",
      "1084 (5, 1) [D loss: (-5.2)] [D acc: (0.000)] [G loss: -33.9] [G acc: 1.000]\n",
      "1085 (5, 1) [D loss: (-7.3)] [D acc: (0.000)] [G loss: -54.1] [G acc: 1.000]\n",
      "1086 (5, 1) [D loss: (-6.1)] [D acc: (0.000)] [G loss: -33.8] [G acc: 1.000]\n",
      "1087 (5, 1) [D loss: (-4.1)] [D acc: (0.000)] [G loss: -35.6] [G acc: 1.000]\n",
      "1088 (5, 1) [D loss: (-6.6)] [D acc: (0.000)] [G loss: -24.5] [G acc: 1.000]\n",
      "1089 (5, 1) [D loss: (-7.6)] [D acc: (0.000)] [G loss: -39.1] [G acc: 1.000]\n",
      "1090 (5, 1) [D loss: (-5.0)] [D acc: (0.000)] [G loss: -49.6] [G acc: 1.000]\n",
      "1091 (5, 1) [D loss: (-5.1)] [D acc: (0.000)] [G loss: -56.9] [G acc: 1.000]\n",
      "1092 (5, 1) [D loss: (-5.5)] [D acc: (0.000)] [G loss: -53.6] [G acc: 1.000]\n",
      "1093 (5, 1) [D loss: (-7.3)] [D acc: (0.000)] [G loss: -34.3] [G acc: 1.000]\n",
      "1094 (5, 1) [D loss: (-6.3)] [D acc: (0.000)] [G loss: -25.7] [G acc: 1.000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1095 (5, 1) [D loss: (-5.9)] [D acc: (0.000)] [G loss: -31.5] [G acc: 1.000]\n",
      "1096 (5, 1) [D loss: (-0.5)] [D acc: (0.000)] [G loss: -40.3] [G acc: 1.000]\n",
      "1097 (5, 1) [D loss: (-9.4)] [D acc: (0.000)] [G loss: -53.1] [G acc: 1.000]\n",
      "1098 (5, 1) [D loss: (-6.2)] [D acc: (0.000)] [G loss: -56.8] [G acc: 1.000]\n",
      "1099 (5, 1) [D loss: (-6.3)] [D acc: (0.000)] [G loss: -57.3] [G acc: 1.000]\n",
      "1100 (5, 1) [D loss: (-6.3)] [D acc: (0.000)] [G loss: -54.9] [G acc: 1.000]\n",
      "1101 (5, 1) [D loss: (-9.2)] [D acc: (0.000)] [G loss: -41.5] [G acc: 1.000]\n",
      "1102 (5, 1) [D loss: (-7.3)] [D acc: (0.000)] [G loss: -27.4] [G acc: 1.000]\n",
      "1103 (5, 1) [D loss: (-6.0)] [D acc: (0.000)] [G loss: -31.0] [G acc: 1.000]\n",
      "1104 (5, 1) [D loss: (-6.3)] [D acc: (0.000)] [G loss: -18.4] [G acc: 1.000]\n",
      "1105 (5, 1) [D loss: (-6.3)] [D acc: (0.000)] [G loss: -47.2] [G acc: 1.000]\n",
      "1106 (5, 1) [D loss: (-8.8)] [D acc: (0.000)] [G loss: -77.0] [G acc: 1.000]\n",
      "1107 (5, 1) [D loss: (-5.8)] [D acc: (0.000)] [G loss: -73.4] [G acc: 1.000]\n",
      "1108 (5, 1) [D loss: (-7.3)] [D acc: (0.000)] [G loss: -69.1] [G acc: 1.000]\n",
      "1109 (5, 1) [D loss: (-7.4)] [D acc: (0.000)] [G loss: -48.8] [G acc: 1.000]\n",
      "1110 (5, 1) [D loss: (-6.3)] [D acc: (0.000)] [G loss: -26.6] [G acc: 1.000]\n",
      "1111 (5, 1) [D loss: (-6.8)] [D acc: (0.000)] [G loss: -20.8] [G acc: 1.000]\n",
      "1112 (5, 1) [D loss: (-5.6)] [D acc: (0.000)] [G loss: -14.4] [G acc: 1.000]\n",
      "1113 (5, 1) [D loss: (-3.3)] [D acc: (0.000)] [G loss: -52.1] [G acc: 1.000]\n",
      "1114 (5, 1) [D loss: (-9.5)] [D acc: (0.000)] [G loss: -67.0] [G acc: 1.000]\n",
      "1115 (5, 1) [D loss: (-4.4)] [D acc: (0.000)] [G loss: -56.8] [G acc: 1.000]\n",
      "1116 (5, 1) [D loss: (-8.5)] [D acc: (0.000)] [G loss: -55.6] [G acc: 1.000]\n",
      "1117 (5, 1) [D loss: (-6.2)] [D acc: (0.000)] [G loss: -37.3] [G acc: 1.000]\n",
      "1118 (5, 1) [D loss: (-4.2)] [D acc: (0.000)] [G loss: -20.7] [G acc: 0.969]\n",
      "1119 (5, 1) [D loss: (-5.1)] [D acc: (0.000)] [G loss: -30.4] [G acc: 1.000]\n",
      "1120 (5, 1) [D loss: (-4.0)] [D acc: (0.000)] [G loss: -44.4] [G acc: 1.000]\n",
      "1121 (5, 1) [D loss: (-5.2)] [D acc: (0.000)] [G loss: -51.3] [G acc: 1.000]\n",
      "1122 (5, 1) [D loss: (-6.1)] [D acc: (0.000)] [G loss: -54.0] [G acc: 1.000]\n",
      "1123 (5, 1) [D loss: (-6.5)] [D acc: (0.000)] [G loss: -61.4] [G acc: 1.000]\n",
      "1124 (5, 1) [D loss: (-5.2)] [D acc: (0.000)] [G loss: -58.7] [G acc: 1.000]\n",
      "1125 (5, 1) [D loss: (-5.9)] [D acc: (0.000)] [G loss: -28.4] [G acc: 1.000]\n",
      "1126 (5, 1) [D loss: (-3.7)] [D acc: (0.000)] [G loss: -46.5] [G acc: 1.000]\n",
      "1127 (5, 1) [D loss: (-6.2)] [D acc: (0.000)] [G loss: -44.9] [G acc: 1.000]\n",
      "1128 (5, 1) [D loss: (-6.4)] [D acc: (0.000)] [G loss: -27.8] [G acc: 1.000]\n",
      "1129 (5, 1) [D loss: (-3.6)] [D acc: (0.000)] [G loss: -62.3] [G acc: 1.000]\n",
      "1130 (5, 1) [D loss: (-4.5)] [D acc: (0.000)] [G loss: -61.2] [G acc: 1.000]\n",
      "1131 (5, 1) [D loss: (-6.1)] [D acc: (0.000)] [G loss: -61.4] [G acc: 1.000]\n",
      "1132 (5, 1) [D loss: (-3.6)] [D acc: (0.000)] [G loss: -41.5] [G acc: 1.000]\n",
      "1133 (5, 1) [D loss: (-4.1)] [D acc: (0.000)] [G loss: -43.2] [G acc: 1.000]\n",
      "1134 (5, 1) [D loss: (-5.7)] [D acc: (0.000)] [G loss: -23.3] [G acc: 0.938]\n",
      "1135 (5, 1) [D loss: (-5.6)] [D acc: (0.000)] [G loss: -56.3] [G acc: 1.000]\n",
      "1136 (5, 1) [D loss: (-9.8)] [D acc: (0.000)] [G loss: -59.2] [G acc: 1.000]\n",
      "1137 (5, 1) [D loss: (-7.1)] [D acc: (0.000)] [G loss: -61.1] [G acc: 1.000]\n",
      "1138 (5, 1) [D loss: (-13.5)] [D acc: (0.000)] [G loss: -50.4] [G acc: 1.000]\n",
      "1139 (5, 1) [D loss: (-2.6)] [D acc: (0.000)] [G loss: -22.2] [G acc: 1.000]\n",
      "1140 (5, 1) [D loss: (-7.5)] [D acc: (0.000)] [G loss: -14.9] [G acc: 0.875]\n",
      "1141 (5, 1) [D loss: (1.8)] [D acc: (0.000)] [G loss: -32.4] [G acc: 1.000]\n",
      "1142 (5, 1) [D loss: (-6.4)] [D acc: (0.000)] [G loss: -32.8] [G acc: 1.000]\n",
      "1143 (5, 1) [D loss: (-8.0)] [D acc: (0.000)] [G loss: -57.0] [G acc: 1.000]\n",
      "1144 (5, 1) [D loss: (-6.1)] [D acc: (0.000)] [G loss: -65.5] [G acc: 1.000]\n",
      "1145 (5, 1) [D loss: (-7.2)] [D acc: (0.000)] [G loss: -70.8] [G acc: 1.000]\n",
      "1146 (5, 1) [D loss: (-3.0)] [D acc: (0.000)] [G loss: -60.2] [G acc: 1.000]\n",
      "1147 (5, 1) [D loss: (-6.1)] [D acc: (0.000)] [G loss: -47.4] [G acc: 1.000]\n",
      "1148 (5, 1) [D loss: (-5.4)] [D acc: (0.000)] [G loss: -40.2] [G acc: 1.000]\n",
      "1149 (5, 1) [D loss: (-6.7)] [D acc: (0.000)] [G loss: -29.2] [G acc: 1.000]\n",
      "1150 (5, 1) [D loss: (-6.1)] [D acc: (0.000)] [G loss: -51.1] [G acc: 1.000]\n",
      "1151 (5, 1) [D loss: (-5.6)] [D acc: (0.000)] [G loss: -55.1] [G acc: 1.000]\n",
      "1152 (5, 1) [D loss: (-5.1)] [D acc: (0.000)] [G loss: -74.2] [G acc: 1.000]\n",
      "1153 (5, 1) [D loss: (-4.2)] [D acc: (0.000)] [G loss: -68.4] [G acc: 1.000]\n",
      "1154 (5, 1) [D loss: (-6.0)] [D acc: (0.000)] [G loss: -39.6] [G acc: 1.000]\n",
      "1155 (5, 1) [D loss: (-6.5)] [D acc: (0.000)] [G loss: -36.2] [G acc: 1.000]\n",
      "1156 (5, 1) [D loss: (-6.7)] [D acc: (0.000)] [G loss: -27.7] [G acc: 0.906]\n",
      "1157 (5, 1) [D loss: (-5.4)] [D acc: (0.000)] [G loss: -20.0] [G acc: 1.000]\n",
      "1158 (5, 1) [D loss: (-5.8)] [D acc: (0.000)] [G loss: -23.0] [G acc: 1.000]\n",
      "1159 (5, 1) [D loss: (-5.4)] [D acc: (0.000)] [G loss: -49.0] [G acc: 1.000]\n",
      "1160 (5, 1) [D loss: (-7.7)] [D acc: (0.000)] [G loss: -64.2] [G acc: 1.000]\n",
      "1161 (5, 1) [D loss: (-6.1)] [D acc: (0.000)] [G loss: -68.6] [G acc: 1.000]\n",
      "1162 (5, 1) [D loss: (-6.6)] [D acc: (0.000)] [G loss: -59.4] [G acc: 1.000]\n",
      "1163 (5, 1) [D loss: (-6.3)] [D acc: (0.000)] [G loss: -43.8] [G acc: 1.000]\n",
      "1164 (5, 1) [D loss: (-3.4)] [D acc: (0.000)] [G loss: -34.3] [G acc: 1.000]\n",
      "1165 (5, 1) [D loss: (-5.7)] [D acc: (0.000)] [G loss: -22.8] [G acc: 1.000]\n",
      "1166 (5, 1) [D loss: (-4.8)] [D acc: (0.000)] [G loss: -24.5] [G acc: 1.000]\n",
      "1167 (5, 1) [D loss: (-4.4)] [D acc: (0.000)] [G loss: -49.7] [G acc: 1.000]\n",
      "1168 (5, 1) [D loss: (-6.5)] [D acc: (0.000)] [G loss: -66.4] [G acc: 1.000]\n",
      "1169 (5, 1) [D loss: (-4.6)] [D acc: (0.000)] [G loss: -79.0] [G acc: 1.000]\n",
      "1170 (5, 1) [D loss: (-7.2)] [D acc: (0.000)] [G loss: -50.4] [G acc: 1.000]\n",
      "1171 (5, 1) [D loss: (-6.0)] [D acc: (0.000)] [G loss: -19.6] [G acc: 1.000]\n",
      "1172 (5, 1) [D loss: (-4.5)] [D acc: (0.000)] [G loss: 0.7] [G acc: 0.500]\n",
      "1173 (5, 1) [D loss: (-6.2)] [D acc: (0.000)] [G loss: -19.7] [G acc: 1.000]\n",
      "1174 (5, 1) [D loss: (-6.2)] [D acc: (0.000)] [G loss: -46.3] [G acc: 1.000]\n",
      "1175 (5, 1) [D loss: (-8.5)] [D acc: (0.000)] [G loss: -50.6] [G acc: 1.000]\n",
      "1176 (5, 1) [D loss: (-4.6)] [D acc: (0.000)] [G loss: -76.2] [G acc: 1.000]\n",
      "1177 (5, 1) [D loss: (-4.8)] [D acc: (0.000)] [G loss: -74.8] [G acc: 1.000]\n",
      "1178 (5, 1) [D loss: (-5.7)] [D acc: (0.000)] [G loss: -40.5] [G acc: 1.000]\n",
      "1179 (5, 1) [D loss: (-5.7)] [D acc: (0.000)] [G loss: -49.0] [G acc: 1.000]\n",
      "1180 (5, 1) [D loss: (-5.9)] [D acc: (0.000)] [G loss: -46.4] [G acc: 1.000]\n",
      "1181 (5, 1) [D loss: (-7.2)] [D acc: (0.000)] [G loss: -32.7] [G acc: 1.000]\n",
      "1182 (5, 1) [D loss: (-7.1)] [D acc: (0.000)] [G loss: -27.8] [G acc: 0.938]\n",
      "1183 (5, 1) [D loss: (-6.5)] [D acc: (0.000)] [G loss: -30.8] [G acc: 1.000]\n",
      "1184 (5, 1) [D loss: (-7.0)] [D acc: (0.000)] [G loss: -36.7] [G acc: 1.000]\n",
      "1185 (5, 1) [D loss: (-9.2)] [D acc: (0.000)] [G loss: -83.8] [G acc: 1.000]\n",
      "1186 (5, 1) [D loss: (-6.3)] [D acc: (0.000)] [G loss: -75.9] [G acc: 1.000]\n",
      "1187 (5, 1) [D loss: (-0.3)] [D acc: (0.000)] [G loss: -73.6] [G acc: 1.000]\n",
      "1188 (5, 1) [D loss: (-4.7)] [D acc: (0.000)] [G loss: -50.6] [G acc: 1.000]\n",
      "1189 (5, 1) [D loss: (-5.8)] [D acc: (0.000)] [G loss: -47.6] [G acc: 1.000]\n",
      "1190 (5, 1) [D loss: (-4.0)] [D acc: (0.000)] [G loss: -30.7] [G acc: 1.000]\n",
      "1191 (5, 1) [D loss: (-7.1)] [D acc: (0.000)] [G loss: -29.3] [G acc: 1.000]\n",
      "1192 (5, 1) [D loss: (-7.0)] [D acc: (0.000)] [G loss: -41.6] [G acc: 1.000]\n",
      "1193 (5, 1) [D loss: (-2.4)] [D acc: (0.000)] [G loss: -36.8] [G acc: 1.000]\n",
      "1194 (5, 1) [D loss: (-6.1)] [D acc: (0.000)] [G loss: -54.8] [G acc: 1.000]\n",
      "1195 (5, 1) [D loss: (-6.8)] [D acc: (0.000)] [G loss: -51.1] [G acc: 1.000]\n",
      "1196 (5, 1) [D loss: (-9.0)] [D acc: (0.000)] [G loss: -60.9] [G acc: 1.000]\n",
      "1197 (5, 1) [D loss: (-5.1)] [D acc: (0.000)] [G loss: -36.6] [G acc: 1.000]\n",
      "1198 (5, 1) [D loss: (-9.8)] [D acc: (0.000)] [G loss: -58.5] [G acc: 1.000]\n",
      "1199 (5, 1) [D loss: (-7.1)] [D acc: (0.000)] [G loss: -45.0] [G acc: 1.000]\n",
      "1200 (5, 1) [D loss: (-6.1)] [D acc: (0.000)] [G loss: -35.6] [G acc: 1.000]\n",
      "1201 (5, 1) [D loss: (-5.5)] [D acc: (0.000)] [G loss: -53.9] [G acc: 1.000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1202 (5, 1) [D loss: (-7.2)] [D acc: (0.000)] [G loss: -63.0] [G acc: 1.000]\n",
      "1203 (5, 1) [D loss: (-5.5)] [D acc: (0.000)] [G loss: -51.8] [G acc: 1.000]\n",
      "1204 (5, 1) [D loss: (-2.3)] [D acc: (0.000)] [G loss: -42.4] [G acc: 1.000]\n",
      "1205 (5, 1) [D loss: (-8.5)] [D acc: (0.000)] [G loss: -20.3] [G acc: 0.969]\n",
      "1206 (5, 1) [D loss: (-8.3)] [D acc: (0.000)] [G loss: -33.1] [G acc: 1.000]\n",
      "1207 (5, 1) [D loss: (-5.0)] [D acc: (0.000)] [G loss: -62.2] [G acc: 1.000]\n",
      "1208 (5, 1) [D loss: (-7.1)] [D acc: (0.000)] [G loss: -62.5] [G acc: 1.000]\n",
      "1209 (5, 1) [D loss: (-8.1)] [D acc: (0.000)] [G loss: -65.3] [G acc: 1.000]\n",
      "1210 (5, 1) [D loss: (-5.8)] [D acc: (0.000)] [G loss: -37.9] [G acc: 1.000]\n",
      "1211 (5, 1) [D loss: (-4.6)] [D acc: (0.000)] [G loss: -36.8] [G acc: 1.000]\n",
      "1212 (5, 1) [D loss: (-5.6)] [D acc: (0.000)] [G loss: -50.5] [G acc: 1.000]\n",
      "1213 (5, 1) [D loss: (-4.6)] [D acc: (0.000)] [G loss: -40.8] [G acc: 1.000]\n",
      "1214 (5, 1) [D loss: (-6.1)] [D acc: (0.000)] [G loss: -54.3] [G acc: 1.000]\n",
      "1215 (5, 1) [D loss: (-6.8)] [D acc: (0.000)] [G loss: -50.9] [G acc: 1.000]\n",
      "1216 (5, 1) [D loss: (-8.1)] [D acc: (0.000)] [G loss: -47.2] [G acc: 1.000]\n",
      "1217 (5, 1) [D loss: (-4.8)] [D acc: (0.000)] [G loss: -36.9] [G acc: 1.000]\n",
      "1218 (5, 1) [D loss: (-7.9)] [D acc: (0.000)] [G loss: -17.4] [G acc: 0.938]\n",
      "1219 (5, 1) [D loss: (-9.1)] [D acc: (0.000)] [G loss: -52.1] [G acc: 1.000]\n",
      "1220 (5, 1) [D loss: (-5.8)] [D acc: (0.000)] [G loss: -84.0] [G acc: 1.000]\n",
      "1221 (5, 1) [D loss: (-5.3)] [D acc: (0.000)] [G loss: -70.5] [G acc: 1.000]\n",
      "1222 (5, 1) [D loss: (-6.8)] [D acc: (0.000)] [G loss: -66.6] [G acc: 1.000]\n",
      "1223 (5, 1) [D loss: (-5.1)] [D acc: (0.000)] [G loss: -30.3] [G acc: 1.000]\n",
      "1224 (5, 1) [D loss: (-4.7)] [D acc: (0.000)] [G loss: -39.3] [G acc: 1.000]\n",
      "1225 (5, 1) [D loss: (-6.3)] [D acc: (0.000)] [G loss: -72.0] [G acc: 1.000]\n",
      "1226 (5, 1) [D loss: (-4.6)] [D acc: (0.000)] [G loss: -50.8] [G acc: 1.000]\n",
      "1227 (5, 1) [D loss: (-7.1)] [D acc: (0.000)] [G loss: -39.7] [G acc: 1.000]\n",
      "1228 (5, 1) [D loss: (-7.2)] [D acc: (0.000)] [G loss: -26.0] [G acc: 1.000]\n",
      "1229 (5, 1) [D loss: (-5.7)] [D acc: (0.000)] [G loss: -35.6] [G acc: 1.000]\n",
      "1230 (5, 1) [D loss: (-5.2)] [D acc: (0.000)] [G loss: -54.5] [G acc: 1.000]\n",
      "1231 (5, 1) [D loss: (-4.5)] [D acc: (0.000)] [G loss: -66.1] [G acc: 1.000]\n",
      "1232 (5, 1) [D loss: (-2.4)] [D acc: (0.000)] [G loss: -78.0] [G acc: 1.000]\n",
      "1233 (5, 1) [D loss: (-6.0)] [D acc: (0.000)] [G loss: -41.7] [G acc: 1.000]\n",
      "1234 (5, 1) [D loss: (-5.1)] [D acc: (0.000)] [G loss: -39.2] [G acc: 1.000]\n",
      "1235 (5, 1) [D loss: (-7.1)] [D acc: (0.000)] [G loss: -44.1] [G acc: 1.000]\n",
      "1236 (5, 1) [D loss: (-3.7)] [D acc: (0.000)] [G loss: -40.3] [G acc: 1.000]\n",
      "1237 (5, 1) [D loss: (-10.6)] [D acc: (0.000)] [G loss: -51.1] [G acc: 1.000]\n",
      "1238 (5, 1) [D loss: (-7.2)] [D acc: (0.000)] [G loss: -40.4] [G acc: 1.000]\n",
      "1239 (5, 1) [D loss: (-6.2)] [D acc: (0.000)] [G loss: -61.6] [G acc: 1.000]\n",
      "1240 (5, 1) [D loss: (-8.5)] [D acc: (0.000)] [G loss: -67.0] [G acc: 1.000]\n",
      "1241 (5, 1) [D loss: (-7.4)] [D acc: (0.000)] [G loss: -53.6] [G acc: 1.000]\n",
      "1242 (5, 1) [D loss: (-5.5)] [D acc: (0.000)] [G loss: -81.7] [G acc: 1.000]\n",
      "1243 (5, 1) [D loss: (-5.7)] [D acc: (0.000)] [G loss: -49.8] [G acc: 1.000]\n",
      "1244 (5, 1) [D loss: (-6.3)] [D acc: (0.000)] [G loss: -47.7] [G acc: 1.000]\n",
      "1245 (5, 1) [D loss: (-4.4)] [D acc: (0.000)] [G loss: -34.2] [G acc: 1.000]\n",
      "1246 (5, 1) [D loss: (-10.8)] [D acc: (0.000)] [G loss: -52.1] [G acc: 1.000]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-3de37ac9f029>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;34m,\u001b[0m \u001b[0mprint_every_n_batches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;34m,\u001b[0m \u001b[0minitial_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0;34m,\u001b[0m \u001b[0musing_generator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m )\n",
      "\u001b[0;32m~/Git/Personal/GDL/generative_deep_learning_code/models/WGANGP.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, x_train, batch_size, epochs, run_folder, print_every_n_batches, initial_epoch, n_critic, using_generator)\u001b[0m\n\u001b[1;32m    342\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_critic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 344\u001b[0;31m                 \u001b[0md_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_critic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0musing_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    345\u001b[0m                 \u001b[0md_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Git/Personal/GDL/generative_deep_learning_code/models/WGANGP.py\u001b[0m in \u001b[0;36mtrain_critic\u001b[0;34m(self, x_train, batch_size, using_generator)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m         d_loss = self.critic_model.train_on_batch([true_imgs, noise],\n\u001b[0;32m--> 320\u001b[0;31m                                                                 [valid, fake, dummy])\n\u001b[0m\u001b[1;32m    321\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0md_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/gdl/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1217\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/gdl/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/gdl/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/gdl/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1380\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1381\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1382\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1383\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1384\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "d_losses, g_losses, d_accs, g_accs = gan.train(     \n",
    "    x_train\n",
    "    , batch_size = 32\n",
    "    , epochs = 2000\n",
    "    , run_folder = RUN_FOLDER\n",
    "    , print_every_n_batches = 10\n",
    "    , initial_epoch = 0\n",
    "    , using_generator = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DirectoryIterator' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-4693ac38344d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mgan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiscriminator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DirectoryIterator' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "idx = np.random.randint(0, x_train.shape[0], 1)[0]\n",
    "gan.discriminator.predict(np.array([x_train[idx]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = np.random.normal(0, 1, (1, gan.z_dim))\n",
    "gen_imgs = gan.generator.predict(noise)\n",
    "gan.discriminator.predict(np.array([gen_imgs[0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan.train_discriminator(x_train, batch_size = 32, clip_threshold = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake = np.ones((128,1))\n",
    "noise = np.random.normal(0, 1, (128, 100))\n",
    "gen_imgs = gan.generator.predict(noise)\n",
    "gan.discriminator.train_on_batch(gen_imgs, fake)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[(np.min(x), np.max(x)) for x in gan.discriminator.get_weights()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan.train_generator(batch_size = 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[np.round((np.min(x), np.max(x)), 4) for x in gan.generator.get_weights()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(np.clip((x[200]+1)*0.5,0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan.discriminator.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(g_losses, color='orange', linewidth=1)\n",
    "plt.plot([x[0] for x in d_losses], color='green', linewidth=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(100):\n",
    "    print(gan.discriminator.predict(np.array([x_train[i]]))[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([74.30898], dtype=float32)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "noise = np.random.normal(0, 1, 100)\n",
    "img = gan.generator.predict(np.array([noise]))[0]\n",
    "\n",
    "plt.imshow(np.clip((img+1)*0.5,0,1))\n",
    "\n",
    "gan.critic.predict(np.array([img]))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(gan.discriminator.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan.generator.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan.discriminator.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pointer = 0\n",
    "for x, y in enumerate(gan.discriminator.layers):\n",
    "    \n",
    "    print(y)\n",
    "    print(y.trainable)\n",
    "    for i in gan.discriminator.layers[x].get_weights():\n",
    "        \n",
    "        print(pointer)\n",
    "        print(i.shape)\n",
    "        pointer+=1\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(gan.discriminator.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan.discriminator.get_weights()[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan.discriminator.get_weights()[22]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train[0][16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan.model.save_weights(os.path.join(RUN_FOLDER, 'weights/weights.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gdl",
   "language": "python",
   "name": "gdl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
